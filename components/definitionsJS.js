const def = 
[{"Category":"AI","Definition":"<p>[[Artificial Intelligence]] systems in which there is no #Uncertainty.</p>\n<p>[[Generalization]]</p>","Words":"Absence of generalization"},{"Category":"AI","Definition":"<p>Type of [[Input Representation]].</p>\n<p><strong>Slot-attention</strong> is a mask and object representation that allows to extract certain parts of the image. Allows to discover objects, orientation, placement, … on objects of an image and they are extremely popular.</p>\n<p>![[Pasted image 20211209092158.png]]</p>","Words":"Attention-based Representation"},{"Category":"AI","Definition":"<p>[[Symbolic AI]] working example. Commercially available.</p>\n<ul>\n<li>25 Million rules of common sense</li>\n<li>Tens of millions other rules and assertions</li>\n<li>Hand-axiomatized by ontologists over 35 years</li>\n</ul>\n<p><a href=\"www.cyc.com\">CYC Website</a></p>\n<p>![[Pasted image 20211206170520.png]]</p>","Words":"CYC"},{"Category":"AI","Definition":"<p>The size of search space grows exponentially with the number of parameters.</p>\n<p>This is true for [[Machine Learning]] problems with inputs of large dimensions (like images) but also for hperparameter exploration.</p>\n<p>e.g. For $G$ parameter value in each of $D$ dimension, the total search space is $G^D$. </p>","Words":"Curse of Dimensionality"},{"Category":"AI","Definition":"<p>Some dimensionality reduction methods, such as [[Principale component Analysis (PCA)]], can return explained variance on a feature basis.</p>\n<p>For others such as [[Factor Analysis]], it can be derived from other outputs. \nExplained variance can be used to rank features. </p>\n<p>Methods : </p>\n<ul>\n<li><p>[[t-SNE]]</p></li>\n<li><p>[[Variationnal Autoencoder (VAE)]]</p></li>\n<li><p><em>DIP-VAE</em></p></li>\n<li><p>[[Chapter 3 - Interpretation Challenges]]</p></li>\n<li><p>[[Chapter 10 - Feature Selection and Engineering for Interpretability]]</p></li>\n</ul>","Words":"Dimensionality Reduction"},{"Category":"AI","Definition":"<p>A vector representation is called a disentangled representation with respect to a particular decomposition of a [[Symmetry Group]] into subgroups, if it decomposes into indep</p>","Words":"Disentanglement Representation"},{"Category":"AI","Definition":"<p>[[Feature Selection]] methods within #Models themselves by naturally selecting features uring training.</p>\n<p>Some examples : </p>\n<ul>\n<li><strong>Tree-Based  models</strong> : Feature importance naturally occuring in the learning process of [[Decision Tree]]</li>\n<li><strong>Regularized models with coefficients</strong> : Many model classes can incorporate penalty-based regularization, such as #L1<em>distance , #L2</em>distance and [[Naive Elastic Net]].</li>\n</ul>","Words":"Embedded methods"},{"Category":"AI","Definition":"<p>Mechanism for learning is inspired by biological evolution, \"such as reproduction algorithm, recombination, and selection\"</p>\n<p>[[Model]] [[Biology]] [[Algorithme]] [[Learning]] [[Evolution]]</p>","Words":"Evolutionary Algorithm"},{"Category":"AI","Definition":"<p>The idea of solving a [[Problem]] by creating populations with random parameters (a generation), and the offsprings that have the best score are kept, and a new population is based on their parameters.</p>\n<p>The process continues until the generations don't improve the score.</p>","Words":"Evolutionary Computation"},{"Category":"AI","Definition":"<p>[[Stochastic]] global optimization technique inspired by [[Natural Selection]]. \nAlthough they have ieration but generations, which include populations of chromosomes. Each chromosome is a binary representation of your feature space where 1 means to selecto a feature and 0 to not. </p>\n<p>Each generation is produced with the following operations: </p>\n<ul>\n<li><strong>Selection</strong>: Partially random (exploration) and partially based on what has already worked (exploitation). What has worked is its fitness. Fitness is assessed with a <em>scorer</em> much like [[Wrapper feature selection methods]]. Poor fitness chromosomes are removed, whereas good ones get to reproduce through <em>crossover</em>.</li>\n<li><strong>Crossover</strong>: Randomly some good bits (or features) of each parent go to a child.</li>\n<li><strong>Mutation</strong>: Even when a chomosome has proved effective, given a low mutation rate, it will occasionally mutate or flip one of its bits, in other words, features.</li>\n</ul>\n<p>[[Evolutionary Algorithm]]</p>","Words":"Genetic Algorithms (GA)"},{"Category":"AI","Definition":"<p>Example of a [[Symbolic AI]] where all members of the tree are related by [[Rule]]. It infers relationship between data members.</p>\n<p>![[Pasted image 20211209074928.png]]</p>\n<p>[[Data Tree]] [[Data Structure]]</p>","Words":"Family Tree"},{"Category":"AI","Definition":"<p>Systems that lack solid ways of generalizing beyond a space of training examples cannot be trusted in open-</p>","Words":"Idiosyncrasy"},{"Category":"AI","Definition":"<p>Type of [[Input Representation]].</p>\n<p><strong>Transporter</strong> is a type of key-point detection model that detects and represents key points (x, y) coordinates in an images.</p>\n<p>![[Pasted image 20211209091908.png]]</p>\n<p>A very general approach that can be applied to many video and types of data. </p>","Words":"Key-point Representation"},{"Category":"AI","Definition":"<p>-&gt; <strong>Objects</strong> \n    (Block, ball, pyramide, hand)\n-&gt; <strong>Relations</strong> \n    (Above, below, between, in front)\n-&gt; <strong>Properties</strong> \n    (Colour, shape, size, position)</p>\n<p>Can be concrete or abstract.\n[[Abstract Concepts]] [[Concrete Concepts]]</p>\n<p>![[Pasted image 20211206182527.png]]</p>\n<p>Paper : <a href=\"https://dspace.mit.edu/handle/1721.1/7095\">Procedures as a representation for data in a computer program for understanding Natural Language</a> ([[Winograd]])</p>\n<p>[[Winograd Schema Challenge]]</p>","Words":"Grounded Symbols"},{"Category":"AI","Definition":"<p>Knowledge Graph : ![[Pasted image 20211206170124.png]]</p>\n<p>[[Bayesian Graph]] : ![[Pasted image 20211206170003.png]]</p>\n<p>[[Knowledge]] [[Data Structure]]</p>","Words":"Knowledge Graph"},{"Category":"AI","Definition":"<p>A partial, imperfect descriptions of the universe, developed by science for our understanding of the universe that is otherwise too complex to grasp by the limits of the human mind. (Rosenblueth &amp; Wiener, 1945)</p>\n<p>They allow for <strong>understanding</strong> and <strong>control</strong>, requiring validations through experiments. (Rosenblueth &amp; Wiener, 1945)</p>\n<p>In other words =&gt; A [[Hypothesis]]!</p>\n<p>Diversity of modeling goals : </p>\n<ol>\n<li><strong>Useful</strong> : Good at solving real-world problems?</li>\n<li><strong>Normative</strong> : Provides the optimal solutions to problems that exist in the real world?</li>\n<li><strong>Clinically Relevant</strong> : Produce insights relevant for developing or evaluating clinical interventions?</li>\n<li><strong>Inspire Experiements</strong> : Change the way we think about a problem, raising interesting new hypothesis &amp; experiments?</li>\n<li><strong>Microscopic Realism</strong> : Describe the microscopic properties of the brain?</li>\n<li><strong>Macroscopic Realism</strong> : Describe properties of brain areas and networks?</li>\n<li><strong>Behavioral Realism</strong> : Can faithfully describe and explain behavioral phenomena?</li>\n<li><strong>Representational</strong> : Use representations of info that are simialr to representaitons in the brain? </li>\n<li><strong>Compact</strong> : Can be succinctly expressed in math or code, making them easy for humans to understand?</li>\n<li><strong>Analytically Tractable</strong> : Understandable through equations instead of numerical simulations therefor generalizable?</li>\n<li><strong>Interpretable</strong> : [[Interpretation]] [[Interpretability]]</li>\n<li><strong>Beauty</strong> : Symmetricalm, balanced, or resonate well with the way we think?</li>\n</ol>","Words":"Model"},{"Category":"AI","Definition":"<p>Field that aims to accumulate and represent abstract knowledge.</p>\n<p>[[Knowledge]] [[Abstract Concepts]]</p>","Words":"Knowledge Representation"},{"Category":"AI","Definition":"<p>Measures the statistical dependence of 2 random variables.\nDerived version of the [[Kullback-Leibler Divergence (KL)]] because it's the KL for feature $X$ and the target $Y$. </p>\n<p>Derived from [[Information Theory]] rather than [[Statistics]].</p>\n<p>The python implementation in <code>Scikit-learn</code> uses a numerically stable and symmetric offshoot of KL called [[Jensen-Shannon Divergence (JS)]] instead and leverages [[k-Nearest Neighbors]] to compute distances.</p>\n<p>![[Mutual Information - Venn Diagrams.png]]</p>\n<p>ENDFLASH</p>","Words":"Mutual Information (MI)"},{"Category":"AI","Definition":"<p>Systems that perform a single narrow goal extremely well but often in ways that are extremely centered around a single task and not robust and <strong>transferable</strong> to even modestly different circumstances without extensive retraining.</p>\n<p>[[Transfer Learning]] [[Task]] [[Robust AI]]</p>","Words":"Narrow AI"},{"Category":"AI","Definition":"<p>plop</p>","Words":"Neural Network"},{"Category":"AI","Definition":"<p>Intelligence that, while not necessarily superhuman or self-improving (AGI), can be counted on to apply what it knows to a wide range of problems in a <strong>Systematic</strong> and <strong>Reliable</strong> way, synthesizing knowledge from a variety of sources such that it can reason <strong>Flexibly</strong> and <strong>Dynamically</strong> about the world, <strong>transferring</strong> what it learns in one context to another, in a way that we would expect of an ordinary adult.</p>\n<p>[[Intelligence]] [[Reliability]] [[Trasnfer Learning]] [[G Factor]]\nRelated to [[Narrow AI]]</p>","Words":"Robust AI"},{"Category":"AI","Definition":"<p>Codify expert human knowledge into an explicit set of rules and facts, and use them for complex decision making.</p>\n<p>The rules and facts are to be encoded in a symbolic structure, and stored in a knowledge base. </p>\n<p>E.g. [[Knowledge Graph]]\nE.g. Is(Socrates, man), Is(man, mortal) -&gt; If man, then mortal</p>\n<h2 id=\"scores\">Scores :</h2>\n<ul>\n<li><strong>Interpratibility</strong> \n-&gt; <strong>5/5</strong>\nSimilar to decision tree interpretability</li>\n<li><strong>Data Efficiency</strong>\n-&gt; <strong>5/5</strong>\nRelies on highly human-crafted data\nA bit too strict on decisions, we have to hand craft all exceptions. </li>\n<li><strong>Transfer</strong>\n-&gt; <strong>4/5</strong>\nRules are defined for all X. Therefor the algorithm is designed for all examples but it dep</li>\n</ul>","Words":"Symbolic AI"},{"Category":"AI","Definition":"<p>A [[NeuroSymbolic AI]] trained to answer visual reasoning questions about natural images. </p>\n<blockquote>\n  <p>Learning by abstraction</p>\n</blockquote>\n<p>Using highly structured input and more weakly structured learnable operations on that input. Extracted data from the images is put in the form of a graph via [[Supervised Learning]]. Accompanying each object node is a set of attributes also learned in supervised training.</p>\n<p>![[Pasted image 20211209085158.png]]</p>\n<p>It converts questions using the graph : \n\"What is the tall object to the left of the bed made of?\" =&gt; \"bed -&gt; left -&gt; tall -&gt; made =&gt; <strong>wood</strong>\"</p>\n<h2 id=\"scores\">Scores :</h2>\n<ul>\n<li><strong>Interpratibility</strong> \n-&gt; <strong>4/5</strong>\nIt defines and assembles python functions based on the question and applies them to the structured scene. Super clear reasonning.</li>\n<li><strong>Data Efficiency</strong>\n-&gt; <strong>3/5</strong>\nNot bad compared to </li>\n</ul>","Words":"The Neural State Machine"},{"Category":"AI","Definition":"<p>A [[NeuroSymbolic AI]] designed to answer complex multi-step questions based on an image. Similar to [[NeuroSymbolic VQA]]</p>\n<blockquote>\n  <p>Interpreting Scenes, Words, and Sentences from Natural Supervision</p>\n</blockquote>\n<p>Instead of extracting objects from a scene using [[Supervised Learning]], they are mapped to a shared visual semantic space and the object representaiton is assigned to the concept is sits closest to.</p>\n<p>![[Pasted image 20211209082544.png]]</p>\n<p>![[Pasted image 20211209082652.png]]</p>\n<h2 id=\"scores\">Scores :</h2>\n<ul>\n<li><p><strong>Interpratibility</strong> \n-&gt; <strong>4/5</strong>\nIt defines and assembles python functions based on the question and applies them to the structured scene. Super clear reasonning.</p></li>\n<li><p><strong>Data Efficiency</strong>\n-&gt; <strong>3/5</strong>\nTrained using a data [[Curriculum Learning]]. First learning <em>object-based</em> questions, then <em>relational</em> questions, then more <em>complex</em> questions. 5000 images with 20 questions per image. Curriculum helps to learn different visual concepts.</p></li>\n<li><p><strong>Transfer</strong>\n-&gt; <strong>4/5</strong>\nIt performs well if you increase difficulty.</p></li>\n<li><p><strong>Universality</strong>\n-&gt; <strong>3/5</strong>\nMust easier to apply to new data domains. No need to include any task specific object representation. Because it learns without direct supervision.</p>\n<p>Scores slightly less than [[Symbolic AI]] on all fields except <strong>universality</strong>, but this model can learn directly from data !</p></li>\n</ul>","Words":"The Neuro-Symbolic Concept Learner"},{"Category":"AI","Definition":"<p>Type of [[Input Representation]].</p>\n<p>A <strong>What</strong> that describes visual features.\nA <strong>Where</strong>, usually a outline crop that defines where the object is in the image.</p>\n<p>![[Pasted image 20211209091709.png]]</p>","Words":"What and Where Representation"},{"Category":"Machine Learning","Definition":"<p>They can be divided in four components : </p>\n<ul>\n<li><strong>Outcome</strong> ($Y$): The outcome variables of the causal model.</li>\n<li><strong>Treatment</strong> ($T$): The treatment variables that influences the outcome.</li>\n<li><strong>Effect Modifiers</strong> ($X$): The variable that influences the effects #Heterogeneity  conditioning it. It sits in between the treatment and the outcome. </li>\n<li><strong>Controls</strong> ($W$): Also known as <strong>common causes</strong> or <strong>confounders</strong>. They are the features that influence both the outcome and the treatment.</li>\n</ul>\n<p>Usually Causal models have a method called <code>identify_effect</code> that derives the probability expression for the effect to be estimated (the <em>identified estimand</em>).\nThen another method called <code>estimate_effect</code> takes this expression and the models it's supposed to tie together (regression and propensity).</p>","Words":"Causal Models"},{"Category":"Machine Learning","Definition":"<p>Explaining [[Machine Learning]] models by finding leveraging conditions which would change input classification.</p>\n<p>Most sophisticated counterfactual finding algorithm do : </p>\n<ul>\n<li><strong>Loss</strong> : Leveraging a #loss_function that helps optimize to find the counterfactuals closest to our <em>instance of interest</em>. </li>\n<li><strong>Pertubation</strong> : These t</li>\n</ul>","Words":"Counterfactual Algorithms"},{"Category":"Machine Learning","Definition":"<p>Very large [[Neural Network]] with specific restrictions in how the weights are allowed to change. Optimized for images, using [[Convolution]]s/Feature maps allowing the network the respect the input structure.</p>\n<p>Inspired by how the [[Visual Fields]] in the [[Brain]] (mostly the eyes) work ([[Attention Theory]]).</p>\n<p>![[Slide33.jpeg]]</p>","Words":"Convolutional Neural Network (CNN)"},{"Category":"Machine Learning","Definition":"<p>The higher the number of connections, the harder a network can adapt to simple mathematical models. </p>\n<p>[[Model]] [[Neuron]] [[Neural Network]] [[Adaptability]]</p>","Words":"Curse of Conspiracy"},{"Category":"Machine Learning","Definition":"<p>Uses a mix of both L1 and L2 norms as penalties.</p>","Words":"Elastic Net regression"},{"Category":"Machine Learning","Definition":"<p>Similar to [[Double Machine Learning]], is a method for estimating [[Heterogenous]] treatment effects when the treatment is categorical and all potential confounders/controls are observed.</p>\n<p>It is called \"doubly\" because it leverages two #Models, as follows: </p>\n<ul>\n<li>It predicts the outcome with a [[Regression Model]], as illustrated here : \n$$\nY \\textasciitilde \\  W + X\n$$</li>\n<li>It predicts the treatment with a [[Propensity Model]], as illustrated here: \n$$\nY \\textasciitilde \\  W + X\n$$\nIt is <em>robust</em> because of the final stage which combines both models while maintaining many desirable statistical properties such as confidence intervals and symptotic normality. \nMore formally, the estimation leverages regression model $g$ and propensity model $p$ conditional on treatment $t$, like this: </li>\n</ul>\n<p>$$\nY<em>t = g</em>t(W, X) + \\epsilon<em>t\n$$\nIt also does this : \n$$\nPr[T = t|X, W] = p</em>t(W, X)\n$$</p>\n<p>Code example : </p>\n<pre><code class=\"py language-py\">drlearner = LinearDRLearner(\n                model_regression=xgb.XGBRegressor(learning_rate=0.1),\n                model_propensity=xgb.XGBClassifier(learning_rate=0.1, max_depth=2, objective=\"multi:softmax\"),\n                random_state=rand,\n)\n</code></pre>\n<p>[[Robust AI]]</p>","Words":"Doubly Robust Learning (DRL)"},{"Category":"Machine Learning","Definition":"<p>The different tools available to a system to input/infuse/induce knowledge (aka learn)</p>\n<p>[[Learning]] [[Knowledge]]</p>","Words":"Degrees of Learning"},{"Category":"Machine Learning","Definition":"<p><strong>EBM</strong> is part of Microsoft's InterpretML Framework, which includes many of the model-agnostic methods we will use later in the book. It is a [[Glass-box Model]]. [[Model]] </p>\n<p>EBM leverages the <strong>GAMs</strong> we mentionned earlier, which are like linear models but look like this : </p>\n<p>$$\n\\widehat y = g(E[y])= \\beta<em>0 + f</em>1(x<em>1) + f</em>2(x<em>2) + \\dots + f</em>j(x_j)\n$$</p>\n<p>Each $f_i$ are individual functions fitted to each features using #Spline functions. Then a link function $g$ adapts the GAM to perform different tasks such as the classification or regression, or adjust predictions to different statistical distributions.</p>","Words":"Explainable Boosting Machine"},{"Category":"Machine Learning","Definition":"<p>Sets of technics with the mean to extract the most out of data, its structure and features to optimize  specific machine learning problems.</p>\n<ul>\n<li>[[Chapter 10 - Feature Selection and Engineering for Interpretability]]</li>\n<li>Chapter 12</li>\n</ul>","Words":"Feature Engineering"},{"Category":"Machine Learning","Definition":"<p>Similar to [[Gradient Descent]] but where the algorithms seeks maximums of the [[Energy Function]].</p>","Words":"Gradient Ascent"},{"Category":"Machine Learning","Definition":"<p>In <a href=\"https://en.wikipedia.org/wiki/Machine_learning\" title=\"Machine learning\">machine learning</a>, <strong>kernel machines</strong> are a class of algorithms for <a href=\"https://en.wikipedia.org/wiki/Pattern_analysis\" title=\"Pattern analysis\">pattern analysis</a>, whose best known member is the <a href=\"https://en.wikipedia.org/wiki/Support-vector_machine\" title=\"Support-vector machine\">support-vector machine</a> (SVM). The general task of <a href=\"https://en.wikipedia.org/wiki/Pattern_analysis\" title=\"Pattern analysis\">pattern analysis</a> is to find and study general types of relations (for example <a href=\"https://en.wikipedia.org/wiki/Cluster_analysis\" title=\"Cluster analysis\">clusters</a>, <a href=\"https://en.wikipedia.org/wiki/Ranking\" title=\"Ranking\">rankings</a>, <a href=\"https://en.wikipedia.org/wiki/Principal_components\" title=\"Principal components\">principal components</a>, <a href=\"https://en.wikipedia.org/wiki/Correlation\" title=\"Correlation\">correlations</a>, <a href=\"https://en.wikipedia.org/wiki/Statistical_classification\" title=\"Statistical classification\">classifications</a>) in datasets. For many algorithms that solve these tasks, the data in raw representation have to be explicitly transformed into <a href=\"https://en.wikipedia.org/wiki/Feature_vector\" title=\"Feature vector\">feature vector</a> representations via a user-specified <em>feature map</em>: in contrast, kernel methods require only a user-specified <em>kernel</em>, i.e., a <a href=\"https://en.wikipedia.org/wiki/Similarity_function\" title=\"Similarity function\">similarity function</a> over pairs of data points in raw representation.</p>\n<hr />\n<p>Can be thought of as generalized [[Support Vector Machine (SVM)]].</p>\n<ul>\n<li>The space of models contains functions $\\sum<em>i{\\gamma</em>i \\langle \\phi (x), \\phi (x^i ) \\rangle }$ pour $\\gamma_i \\in \\mathbb{R}$ , where $x^i \\in \\mathcal{X}$ is from the data domain.</li>\n<li>The models that minimise the empirical risk are functions $\\sum<em>m{ a</em>m \\langle \\phi(x), \\phi(x^m)\\rangle}$ for $(a_m \\in \\mathbb{R})$, where $x^m \\in \\mathcal{D}$ is from the training data. </li>\n<li>Instead of training the weight vector of the linear model, we can train the $a_m$ . \n ![[Pasted image 20220101134651.png]]</li>\n</ul>\n<hr />\n<p>![[Pasted image 20220101133528.png]]</p>\n<p><a href=\"https://link.springer.com/book/10.1007/978-0-387-77242-4\">Book on SVM</a></p>\n<p>[[Machine Learning]] [[Support Vector Machine (SVM)]] #Pattern [[Model]] #High_Dimension</p>","Words":"Kernel Methods"},{"Category":"Machine Learning","Definition":"<p>Calculating the high dimensional relationships without actually transforming the data to the higher dimension.\nIt reduces the amount of computation required for [[Support Vector Machines (SVM)]] by avoiding the math that transforms the data from low to high dimensions.</p>","Words":"Kernel Trick"},{"Category":"Machine Learning","Definition":"<p>An algorithm often used in [[Hyperparameter Tuning]] for [[Neural Network]]. One divides the parameter space in a grid of points and loops over all the points of the grid. The parameter value with the best value is retained and is considered the best estimate. </p>\n<p>Optionally, the area around the best point can be affined to a new set of points and the algorithm can be restarted on this new set of parameters.</p>","Words":"Grid Search"},{"Category":"Machine Learning","Definition":"<p>A type of [[Learning]] in which you first start out with only easy examples of a task and then gradually increase the task difficulty.</p>\n<p>[[Learning]] [[Task]]</p>\n<p><a href=\"https://arxiv.org/pdf/1904.03626.pdf\">On The Power of Curriculum Learning in Training Deep Networks</a></p>","Words":"Curriculum Learning"},{"Category":"Machine Learning","Definition":"<p>Similar to [[Least absolute shrinkage and selection operator (LASSO)]] but is vector-based and is more suitable to #High_Dimension data. It is also fairer toward equally correlated features.</p>","Words":"Least-angle regression (LARS)"},{"Category":"Machine Learning","Definition":"<p>En [[Probability Distribution]] et en [[Information Theory]], aussi connu sous le nom d'<strong>entropie relative</strong>, est une <a href=\"https://fr.wikipedia.org/wiki/Divergence_(statistiques)\" title=\"Divergence (statistiques)\">mesure de dissimilarité</a> entre deux <a href=\"https://fr.wikipedia.org/wiki/Loi_de_probabilit%C3%A9\" title=\"Loi de probabilité\">distributions</a> de probabilités. Elle doit son nom à [[Solomon Kullback]] et [[Richard Leibler]], deux cryptanalystes américains.</p>","Words":"Kullback-Leibler Divergence (KL)"},{"Category":"Machine Learning","Definition":"<p>Another [[Gradient Boosted decision trees]] popular [[Model]] similar to [[XGBoost]] that leverages boosted-tree ensembles and histogram based split finding. </p>\n<p>The main differences lie in the split method's algorithms that LighGBM sampling with <a href=\"GOSS\">[Gradient-based One-Side Sampling]</a> and bundling sparse features with <a href=\"EFB\">[Exclusive Feature Bundling]</a>.\n-&gt; Note that GOSS makes LightGBM much faster than XGBoost.</p>\n<p>[[Decision Tree]] are built [[Best-first]] (Across a tree's leaves)</p>\n<p>[[Explainable Boosting Machine]] makes LightGBM ideal for training on sparse features efficiently and effectively.</p>","Words":"LightGBM"},{"Category":"Machine Learning","Definition":"<p>Part of the [[Reinforcement Learning (RL)]] [[Machine Learning]] #Models #Algorithm  about maximizing payoff when you have limited resources to explore all unknown possibilities. </p>\n<p>It originated from understadning how casino slot machine players could maximize their payoff by playing multiple machines. The trick is to learn how to balance exploration (trying unknown slot machines) with explotation (using those you already have reasons to prefer).</p>","Words":"Multi-Armed Bandit (MAB)"},{"Category":"Machine Learning","Definition":"<p>Contingent on the solver, it can handle L1 and L2, or Elastic net penalties.</p>","Words":"Logistic regression"},{"Category":"Machine Learning","Definition":"<p>Adaptation to know $n$ unknowns within a single task or well-defined set of tasks. (Typical ML models)\n[[Machine Learning]] [[Adaptability]] [[Task]] [[Robust AI]] [[Model]] [[Generalization]]</p>","Words":"Local generalization"},{"Category":"Machine Learning","Definition":"<p>A subfield of #Machine<em>Learning based on leveraging the advantages of [[Symbolic AI]] with #Machine</em>Learning [[Model]].</p>\n<p>How task-specific knowledge can be used to add structure to the <strong>input representation</strong> and the <strong>function</strong> :</p>\n<p>![[Pasted image 20211208172822.png]]\n![[Pasted image 20211209080601.png]]</p>\n<p>Related Paper : </p>\n<p><a href=\"https://arxiv.org/abs/1612.06890\">CLEVR: A diagnostic Dataset for Compositional Language and Elementary Visual Reasoning</a></p>\n<p><a href=\"https://arxiv.org/abs/2012.05876\">NeuroSymbolic AI: The 3rd Wave</a></p>","Words":"NeuroSymbolic AI"},{"Category":"Machine Learning","Definition":"<p>A <strong>multilayer perceptron</strong> (<strong>MLP</strong>) is a class of <a href=\"https://en.wikipedia.org/wiki/Feedforward_neural_network\" title=\"Feedforward neural network\">feedforward</a> <a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network\" title=\"Artificial neural network\">artificial neural network</a> (ANN). The term MLP is used ambiguously, sometimes loosely to mean <em>any</em> feedforward ANN, sometimes strictly to refer to networks composed of multiple layers of <a href=\"https://en.wikipedia.org/wiki/Perceptron\" title=\"Perceptron\">perceptrons</a> (with threshold activation); see <a href=\"https://en.wikipedia.org/wiki/Multilayer_perceptron#Terminology\">§&nbsp;Terminology</a>. Multilayer perceptrons are sometimes colloquially referred to as \"vanilla\" neural networks, especially when they have a single hidden layer.<a href=\"https://en.wikipedia.org/wiki/Multilayer_perceptron#cite_note-1\">[1]</a></p>\n<p>An MLP consists of at least three <a href=\"https://en.wikipedia.org/wiki/Layer_(deep_learning)\" title=\"Layer (deep learning)\">layers</a> of nodes: an input <a href=\"https://en.wikipedia.org/wiki/Layer_(deep_learning)\" title=\"Layer (deep learning)\">layer</a>, a hidden <a href=\"https://en.wikipedia.org/wiki/Layer_(deep_learning)\" title=\"Layer (deep learning)\">layer</a> and an output <a href=\"https://en.wikipedia.org/wiki/Layer_(deep_learning)\" title=\"Layer (deep learning)\">layer</a>. Except for the input nodes, each node is a neuron that uses a nonlinear <a href=\"https://en.wikipedia.org/wiki/Activation_function\" title=\"Activation function\">activation function</a>. MLP utilizes a <a href=\"https://en.wikipedia.org/wiki/Supervised_learning\" title=\"Supervised learning\">supervised learning</a> technique called <a href=\"https://en.wikipedia.org/wiki/Backpropagation\" title=\"Backpropagation\">backpropagation</a> for training.<a href=\"https://en.wikipedia.org/wiki/Multilayer_perceptron#cite_note-2\">[2]</a><a href=\"https://en.wikipedia.org/wiki/Multilayer_perceptron#cite_note-3\">[3]</a> Its multiple layers and non-linear activation distinguish MLP from a linear <a href=\"https://en.wikipedia.org/wiki/Perceptron\" title=\"Perceptron\">perceptron</a>. It can distinguish data that is not <a href=\"https://en.wikipedia.org/wiki/Linear_separability\" title=\"Linear separability\">linearly separable</a>.<a href=\"https://en.wikipedia.org/wiki/Multilayer_perceptron#cite_note-Cybenko1989-4\">[4]</a></p>","Words":"Multi-layer Perceptron (MLP)"},{"Category":"Machine Learning","Definition":"<p>[[Artificial Neural Networks (ANN)]] where a layer of [[Neuron]] has more unit than the number of training input.</p>","Words":"Overspecified Neural Network"},{"Category":"Machine Learning","Definition":"<p>A [[NeuroSymbolic AI]] designed to answer complex multi-step questions based on an image.</p>\n<blockquote>\n  <p>Disentangling Reasoning from Vision and Language Understanding</p>\n</blockquote>\n<ol>\n<li>it first segments objects (with a mask) </li>\n<li>then trains a deep learning model to predict their size, shape, color, material, position. </li>\n<li>A program is then generated from the question by composing predefined  python functions with no learnable parameters. (Here in the example, 5 python functions are generated to be able to solve the question)</li>\n<li>The program is then executed on the scene representation to produce an answer. </li>\n</ol>\n<p>![[Pasted image 20211209081538.png]]</p>\n<h2 id=\"scores\">Scores :</h2>\n<ul>\n<li><p><strong>Interpratibility</strong> \n-&gt; <strong>4/5</strong>\nIt defines and assembles python functions based on the question and applies them to the structured scene. Super clear reasonning.</p></li>\n<li><p><strong>Data Efficiency</strong>\n-&gt; <strong>4/5</strong>\nBuilt in data structures. Gives less spaces for learning but makes it more efficient.</p></li>\n<li><p><strong>Transfer</strong>\n-&gt; <strong>3/5</strong>\nBy fine-tuning, we can choose to fine-tune the scene encoder or the problem solving code to help solve new tasks.</p></li>\n<li><p><strong>Universality</strong>\n-&gt; <strong>2/5</strong>\nA lot of baked in specific data in the model makes it hard to answer questions from input outside of the original domain.</p>\n<p>Scores slightly less than [[Symbolic AI]] on all fields except <strong>universality</strong>, but this model can learn directly from data !</p></li>\n</ul>","Words":"NeuroSymbolic VQA"},{"Category":"Machine Learning","Definition":"<p>A [[NeuroSymbolic AI]] that learns with raw data without highly structured data structures.\nIt defines a set of more general learnable modules that can be applied directly to images. </p>\n<p>It uses an <strong>Attention masks</strong> which makes the AI able to focus on certain parts of the images. This attention can be used sequentialy (Re-Attention) or with a combination of attention masks (Combination).</p>\n<p>![[Pasted image 20211209083816.png]]</p>\n<p>Classification and Measurement are also defined and used to assign labels :</p>\n<p>![[Pasted image 20211209084015.png]]</p>\n<p>It then learns to combine those in a program that help solve questions.</p>\n<h2 id=\"scores\">Scores :</h2>\n<ul>\n<li><p><strong>Interpratibility</strong> \n-&gt; <strong>3/5</strong>\nBecause the input is raw, we are not sure to what the questions are exactly looking at. Not always to clear to identify which part of the images are actually contributing to the answer.</p></li>\n<li><p><strong>Data Efficiency</strong>\n-&gt; <strong>3/5</strong>\nBetter than deep learning model with the same amount of data.</p></li>\n<li><p><strong>Transfer</strong>\n-&gt; <strong>3/5</strong>\nIs able to score efficiently on problems with more steps than its been trained on.</p></li>\n<li><p><strong>Universality</strong>\n-&gt; <strong>4/5</strong>\nDoes not require any specific assumptions or data knowledge. Uses Raw data. </p>\n<p>Scores slightly less than [[Symbolic AI]] on all fields except <strong>universality</strong>, but this model can learn directly from data !</p></li>\n</ul>","Words":"Neural Module Networks"},{"Category":"Machine Learning","Definition":"<p>[[Machine Learning]] Tools to learn a target distribution.</p>\n<ul>\n<li>Start with simple distribution $z \\tilde\\ \\pi$ (uniform, Gaussian, …)</li>\n<li>Smooth family of invertible maps $F_{\\theta}$</li>\n<li>Define $q<em>{\\theta}(x) = \\pi (z)|\\det \\frac{\\partial F</em>\\theta}{\\partial z}|^{-1}$</li>\n</ul>\n<p>![[Pasted image 20211208150224.png]]</p>","Words":"Normalizing flows"},{"Category":"Machine Learning","Definition":"<p>Adding an extra term in [[Neural Network]] [[Prediction Error]], allowing to add more or less importance on certain weights.\nThis final matrice of weights have several advantages such as [[Interpretability]].</p>\n<ul>\n<li>[[Chapter 3 - Interpretation Challenges]]</li>\n<li>Chapter 12</li>\n<li>[[Ch5 - Multilayer Networks]]</li>\n</ul>","Words":"Regularization"},{"Category":"Machine Learning","Definition":"<p>Uses L2 penalty in the loss function and because of this can only shrink coefficients of irrelevance close to 0, but not to 0.</p>","Words":"Ridge regression"},{"Category":"Machine Learning","Definition":"<p>The <strong>principal components</strong> of a collection of points in a <a href=\"https://en.wikipedia.org/wiki/Real_coordinate_space\" title=\"Real coordinate space\">real coordinate space</a> are a sequence of {\\displaystyle p}![p](https://wikimedia.org/api/rest_v1/media/math/r</p>","Words":"Principale component Analysis (PCA)"},{"Category":"Machine Learning","Definition":"<p>[[Machine Learning]] category where an agent [[Learning]] by maximizing a [[Reward]] modulated by cost factors such as risk of loss, punishement, and effort investment. Most of the information comes from the environment.</p>\n<p>[[Reward]] is harder to define in real life.</p>","Words":"Reinforcement Learning (RL)"},{"Category":"Machine Learning","Definition":"<p>In <a href=\"https://en.wikipedia.org/wiki/Machine_learning\" title=\"Machine learning\">machine learning</a>, <strong>support-vector machines</strong> (<strong>SVMs</strong>, also <strong>support-vector networks</strong><a href=\"https://en.wikipedia.org/wiki/Support-vector_machine#cite_note-CorinnaCortes-1\">[1]</a>) are <a href=\"https://en.wikipedia.org/wiki/Supervised_learning\" title=\"Supervised learning\">supervised learning</a> models with associated learning <a href=\"https://en.wikipedia.org/wiki/Algorithm\" title=\"Algorithm\">algorithms</a> that analyze data for <a href=\"https://en.wikipedia.org/wiki/Statistical_classification\" title=\"Statistical classification\">classification</a> and <a href=\"https://en.wikipedia.org/wiki/Regression_analysis\" title=\"Regression analysis\">regression analysis</a>. Developed at <a href=\"https://en.wikipedia.org/wiki/AT%26T_Bell_Laboratories\" title=\"AT&T Bell Laboratories\">AT&T Bell Laboratories</a> by <a href=\"https://en.wikipedia.org/wiki/Vladimir_Vapnik\" title=\"Vladimir Vapnik\">Vladimir Vapnik</a> with colleagues (Boser et al., 1992, <a href=\"https://en.wikipedia.org/wiki/Isabelle_Guyon\" title=\"Isabelle Guyon\">Guyon</a> et al., 1993, <a href=\"https://en.wikipedia.org/wiki/Corinna_Cortes\" title=\"Corinna Cortes\">Cortes</a> and Vapnik, 1995,<a href=\"https://en.wikipedia.org/wiki/Support-vector_machine#cite_note-article1995-2\">[2]</a> Vapnik et al., 1997[<em><a href=\"https://en.wikipedia.org/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\">citation needed</a></em>]) SVMs are one of the most robust prediction methods, being based on statistical learning frameworks or <a href=\"https://en.wikipedia.org/wiki/VC_theory\" title=\"VC theory\">VC theory</a> proposed by Vapnik (1982, 1995) and Chervonenkis (1974). Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-<a href=\"https://en.wikipedia.org/wiki/Probabilistic_classification\" title=\"Probabilistic classification\">probabilistic</a> <a href=\"https://en.wikipedia.org/wiki/Binary_classifier\" title=\"Binary classifier\">binary</a> <a href=\"https://en.wikipedia.org/wiki/Linear_classifier\" title=\"Linear classifier\">linear classifier</a> (although methods such as <a href=\"https://en.wikipedia.org/wiki/Platt_scaling\" title=\"Platt scaling\">Platt scaling</a> exist to use SVM in a probabilistic classification setting). SVM maps training examples to points in space so as to maximise the width of the gap between the two categories. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.</p>\n<p>In addition to performing <a href=\"https://en.wikipedia.org/wiki/Linear_classifier\" title=\"Linear classifier\">linear classification</a>, SVMs can efficiently perform a non-linear classification using what is called the <a href=\"https://en.wikipedia.org/wiki/Kernel_method#Mathematics:_the_kernel_trick\" title=\"Kernel method\">kernel trick</a>, implicitly mapping their inputs into high-dimensional feature spaces.</p>\n<p>When data are unlabelled, supervised learning is not possible, and an <a href=\"https://en.wikipedia.org/wiki/Unsupervised_learning\" title=\"Unsupervised learning\">unsupervised learning</a> approach is required, which attempts to find natural <a href=\"https://en.wikipedia.org/wiki/Cluster_analysis\" title=\"Cluster analysis\">clustering of the data</a> to groups, and then map new data to these formed groups. The <strong>support-vector clustering</strong><a href=\"https://en.wikipedia.org/wiki/Support-vector_machine#cite_note-HavaSiegelmann-3\">[3]</a> algorithm, created by <a href=\"https://en.wikipedia.org/wiki/Hava_Siegelmann\" title=\"Hava Siegelmann\">Hava Siegelmann</a> and <a href=\"https://en.wikipedia.org/wiki/Vladimir_Vapnik\" title=\"Vladimir Vapnik\">Vladimir Vapnik</a>, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data.[<em><a href=\"https://en.wikipedia.org/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\">citation needed</a></em>]</p>\n<p>[[Machine Learning]] #Models [[Kernel Methods]] [[Unsupervised Learning]] </p>","Words":"Support Vector Machine (SVM)"},{"Category":"Machine Learning","Definition":"<p>A [[Machine Learning]] task of [[Learning]] a function that maps an input to an output based on example input-output pairs.\nTask algorithm POV</p>\n<p>Consider a [[Probability Distribution]] $p(x, y)$ over suitable inputs $x \\in \\mathcal{X}$ and labels $y \\in \\mathcal{Y}$, from which we get smaples $\\mathcal{D} = {(x^1, y^1), \\dots ,(x^M, y^M)}$, as well as a loss $l : \\mathcal{Y} \\times\\mathcal{Y} \\rightarrow \\mathbb{R}$. \nFind a [[Model]] $f$ from a class $\\mathcal{F}$ that minimises the expected loss over the data distribution : </p>\n<p>$$\\widehat{f} = \\min<em>{f \\in \\mathcal{F}} \\int</em>{\\mathcal{X} \\times \\mathcal{Y}} p(x, y) l(f(x), y) dxdy$$</p>\n<p>The standard way to do this is to minimise</p>\n<p>$$\\widehat{f} = \\min<em>{f \\in \\mathcal{F}} \\sum</em>{(x,y) \\in  \\mathcal{D}} l(f(x), y)$$</p>\n<p>and hope for the best.</p>","Words":"Supervised Learning"},{"Category":"Machine Learning","Definition":"<p>$$Pr(\\text{ToChoose i}) = \\frac{\\exp{(\\gamma w<em>i)}}{\\sum</em>j \\exp{(\\gamma w_j)}}$$</p>\n<ul>\n<li>$\\gamma$ is often called the <em>inverse temperature</em>, because 0 corresponds to randmoness ('hot' environment close to entropy), and $+∞$ becomes full determinsim ('cold' environment)</li>\n<li>Every element can be calculated to have their own probability of being active <ul>\n<li>$\\sum_j \\Pr (\\text{ToChoose j}) = 1$</li></ul></li>\n</ul>","Words":"Softmax Function"},{"Category":"Machine Learning","Definition":"<p><strong>Spiking neural networks</strong> (<strong>SNNs</strong>) are <a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network\" title=\"Artificial neural network\">artificial neural networks</a> that more closely mimic natural neural networks.<a href=\"https://en.wikipedia.org/wiki/Spiking_neural_network#cite_note-Maas_1996-1\">[1]</a> In addition to <a href=\"https://en.wikipedia.org/wiki/Artificial_neuron\" title=\"Artificial neuron\">neuronal</a> and <a href=\"https://en.wikipedia.org/wiki/Electrical_synapse\" title=\"Electrical synapse\">synaptic</a> state, SNNs incorporate the concept of time into their <a href=\"https://en.wikipedia.org/wiki/Operating_Model\" title=\"Operating Model\">operating model</a>. The idea is that <a href=\"https://en.wikipedia.org/wiki/Artificial_neuron\" title=\"Artificial neuron\">neurons</a> in the SNN do not transmit information at each propagation cycle (as it happens with typical multi-layer <a href=\"https://en.wikipedia.org/wiki/Perceptron\" title=\"Perceptron\">perceptron networks</a>), but rather transmit information only when a <a href=\"https://en.wikipedia.org/wiki/Membrane_potential\" title=\"Membrane potential\">membrane potential</a> – an intrinsic quality of the neuron related to its membrane electrical charge&nbsp;– reaches a specific value, called the threshold. When the membrane potential reaches the threshold, the neuron fires, and generates a signal that travels to other neurons which, in turn, increase or decrease their potentials in response to this signal. A neuron model that fires at the moment of threshold crossing is also called a <a href=\"https://en.wikipedia.org/wiki/Spiking_neuron_model\" title=\"Spiking neuron model\">spiking neuron model</a>.<a href=\"https://en.wikipedia.org/wiki/Spiking_neural_network#cite_note-2\">[2]</a></p>\n<p>[[Artificial Neural Networks (ANN)]] [[Synaptic Neurotransmission]] </p>\n<p>Reading : </p>\n<ul>\n<li>[[Thoughts/Research Idea/Self Generating Model/Reading/Supervised training of convolutional spiking neural networks with PyTorch.pdf]]</li>\n<li>Implementation of SNN :  http://github.com/romainzimmer/s2net</li>\n</ul>","Words":"Spiking Neural Networks (SNNs)"},{"Category":"Machine Learning","Definition":"<p>Exploit the fact that quantum states realized in nature have little entanglement. In [[Machine Learning]] these models are called [[Tensor Decompositions]].</p>","Words":"Tensor Networks"},{"Category":"Machine Learning","Definition":"<p>A form of word vectorization for [[Natural Language Processing (NLP)]]. \nUsed to evaluate how often a term (each words) appears in a document (each phrase). However it is weighted according to its frequency in the entire corpus (all phrases). </p>\n<p>Most often, the vectorizer is fitted on the training data, so that each words have a consistent scoring for each term. </p>","Words":"Term Frequency-Inverse Document Frequency"},{"Category":"Machine Learning","Definition":"<p>[[Multi-layer Perceptron (MLP)]] of arbitrary width or length, can approximate any continuous functions upto the desired accuracy level.</p>","Words":"Universal Function Approximator"},{"Category":"Machine Learning","Definition":"<p>A family of [[Machine Learning]] [[Model]]s. </p>\n<p>The goal is to represent the original input data from the environment as faithfully as possible without supervision/labels.\nSeveral of those models use additional units with a lower number of dimensions than the original input. As a consequence, the network is forced to extract and internally represent the common strcture across the input patterns via its hidden or output units and weights.</p>","Words":"Unsupervised Learning"},{"Category":"Machine Learning","Definition":"<p>A [[Decision Tree]] used for the #High_Dimension  searches.</p>","Words":"k-Decision Tree"},{"Category":"Deep Learning","Definition":"<p>Deep learning methods that learn how to best encode data from a high dimension and then decode it back from a low dimension to a high dimension.\nIt provides reversibility, unlike PCA and t-SNE, and can even generate new data.</p>\n<p>The original $J$-dimensional input is first mapped into a lower $K$-dimensional hidden layer (with $K &lt; J$), after which it projects to a $J$-dimensional output layer.</p>\n<p>Because no extra information is required beyond the input patter, [[Unsupervised Learning]] algorithms can be used to train them. </p>\n<p>[[Deep Learning (DL)]] #High_Dimension </p>\n<p>Example of a simple VAE : </p>\n<pre><code class=\"py language-py\">input_layer = tf.keras.Input(shape=(21))\n\nencoder = tf.keras.layers.Dense(10, activation='relu')(input_layer)\n\nbottleneck = tf.keras.layers.Dense(3, activation='relu')(encoder)\n\ndecoder = tf.keras.layers.Dense(10, activation='relu')(bottleneck)\n\noutput_layer = tf.keras.layers.Dense(21, activation='linear')(decoder)\n\nautoencoder_mdl = tf.keras.Model(input_layer, output_layer)\n\nautoencoder_mdl.summary()\n\n\nautoencoder_mdl.compile(loss='mean_squared_error', optimizer='adam')\n\n# Same values for training and output !\nautoencoder_history = autoencoder_mdl.fit(X_train.values, X_train.values, epochs=16, batch_size=32, validation_split=0.2, verbose=0)\n</code></pre>","Words":"Variationnal Autoencoder (VAE)"},{"Category":"Deep Learning","Definition":"<p>Large and/or deep [[Multi-layer Perceptron (MLP)]]. Can be composed and/or combined with many different types of layers such as [[Convolutional Neural Network (CNN)]], [[Recurrent Neural Network (RNN)]], [[Graph Neural Network (GNN)]], …</p>\n<h2 id=\"scores\">Scores :</h2>\n<ul>\n<li><strong>Interpratibility</strong> \n-&gt; <strong>1/5</strong>\nIts a blackbox model. One brain per interpratibility.</li>\n<li><strong>Data Efficiency</strong>\n-&gt; <strong>1/5</strong>\nHuges amount of data. GPT3 is trained on 300 Billion tokens from 5 datasets. </li>\n<li><strong>Transfer</strong>\n-&gt; <strong>1/5</strong>\nDo not generalize well to small changes in input data.</li>\n<li><strong>Universality</strong>\n-&gt; <strong>5/5</strong>\nA single model can be trained to solve different types of tasks. E.g. AlphaZero used for chess and for GO. Used for speech, images, video games , …</li>\n</ul>","Words":"Deep Learning (DL)"},{"Category":"Deep Learning","Definition":"<p>[[Neural Network]] containing loops  in its connectivity structure. It is trained with a variation of the [[Backpropagation]] algorithm called the [[Backpropagation-through-time]]</p>\n<p>One of the simplest network proposed [[Cognitive Neuroscience]] is the <em>Simple Recurrent Network (SRN)</em> (Elman, 1960), a 3 layer neural network but with an extra contxt layer to which hidden units project and which itselfs projects back to the hidden units. The <em>context-towards-hidden</em> weights are also trained. </p>\n<p>Reccurence between the hidden and context layers allows the model to reprocess its older information, thus creating a working memory in the system, making them especially useful as models of cognition because <strong>the target for the network is the next input!</strong></p>","Words":"Recurrent Neural Network (RNN)"},{"Category":"Deep Learning","Definition":"<ul>\n<li><p>[[IG]]</p></li>\n<li><p>[[Salency Maps]]</p></li>\n<li><p>[[Grad-CAM]]</p></li>\n<li><p>[[SmoothGrad]]</p></li>\n<li><p><em>Semantic Segmentation</em></p></li>\n<li><p>Chapter 8</p></li>\n<li><p>Chapter 9</p></li>\n</ul>","Words":"Deep Learning-Specific"},{"Category":"Interpretable ML","Definition":"<p>Similar to [[Partial Dependence Plots]]</p>","Words":"Accumulated Local Effect"},{"Category":"Interpretable ML","Definition":"<p>F-test measures the linear dep</p>","Words":"ANOVA F-test - Analysis of Variance"},{"Category":"Interpretable ML","Definition":"<p><strong>Concerns :</strong> </p>\n<ul>\n<li>Reliability</li>\n<li>Certainty</li>\n<li>Security</li>\n<li>Safety</li>\n<li>Robustness</li>\n<li>Privacy</li>\n</ul>\n<p><strong>Interpretation Methods :</strong> </p>\n<ul>\n<li>[[Out-of-sample Evaluations]]</li>\n<li>[[Sensitivity Analysis]]</li>\n<li>[[Causal Inference]] methods</li>\n<li>[[Evasion Adversarial Robustness Evaluations]]</li>\n<li><em>Inference Extraction & Poisoning Adversarial Robustness Evaluations</em></li>\n<li><em>Anomaly Detection / Metrics</em></li>\n<li><em>Privacy Metrics</em></li>\n</ul>\n<h2 id=\"treatment\">Treatment</h2>\n<ul>\n<li>[[Enhancing Reliability]]</li>\n<li>[[Reducing Complexity]]</li>\n<li>[[Mitigating Bias]]</li>\n<li>[[Ensuring Privacy]]</li>\n</ul>","Words":"Accountability (ML)"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>Chapter 13</li>\n</ul>","Words":"Adversarial Training"},{"Category":"Interpretable ML","Definition":"<p>A [[Feature Selection]] that doesn't fall into any of the [[Wrapper feature selection methods]] or [[Hybrid feature selection methods]]. </p>\n<p>Examples : </p>\n<ul>\n<li>[[Dimensionality Reduction]]</li>\n<li>[[Model-agnostic]] feature importance : Any feature importance covered in [[Chapter 4 - Fundamentals of Feature Importance and Impact]] and [[Chapter 5 - Global Model-Agnostic Interpretation Methods]] such as [[Shapley values (SHAP)]].</li>\n<li>[[Genetic Algorithms (GA)]] : Can be used as a [[Wrapper feature selection methods]] in the sense that it \"wraps\" a model assessing predictive performance acress many feature subsets. But it's not greedy ! </li>\n<li>[[Variationnal Autoencoder (VAE)]]</li>\n</ul>","Words":"Advanced feature selection methods"},{"Category":"Interpretable ML","Definition":"<p>Similar to [[Local Interpretable Model-agnostic Explanations]], <strong>anchors</strong> are derived from a [[Model-agnostic]] pertubation-based strategy (meaning that it creates a <em>pertubed</em> version of your dataset).</p>\n<ul>\n<li>However they are not about decision boundary but <strong>decision region</strong>. </li>\n<li>They are also known as <strong>Scoped Rules</strong> because they list some <strong>decision rules</strong> that apply to your instance and its pertubed neighborhood. <ul>\n<li>This <em>pertubed</em> neighborhood is also known as the <strong>pertubation space</strong>.</li></ul></li>\n<li><strong>Precision</strong> lets us know\"to what extent the rules apply\". </li>\n<li><strong>Coverage</strong> is the percentage of your <em>pertubation space</em> that yeilds a specific <em>precision</em>.</li>\n<li>Anchors explore possible candidate decision rules using an algorithm called <a href=\"KL-LUCB\">[Kullback-Leibler divergence Lower and Upper Confidence Bounds]</a>.</li>\n</ul>","Words":"Anchor"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>Chapter 13</li>\n</ul>","Words":"Adversarial Preprocessing Defenses"},{"Category":"Interpretable ML","Definition":"<p>The difference between <strong>false-positive rates</strong> (FPR) averaged with the difference between <strong>false-negative rates (FNR)</strong> for both priviledged and underpriviledged groups. Negative means there's a disadvantage for the underpriviledged group, and the closer to zero, the better. </p>\n<p>$$\n\\frac{1}{2}[(FPR<em>{D=\\textrm{unpriviledged}} - FPR</em>{D=\\textrm{priviledged}}) + (TPR<em>{D=\\textrm{unpriviledged}} - TPR</em>{D=\\textrm{priviledged}})]\n$$</p>","Words":"Average Odds Difference (AOD)"},{"Category":"Interpretable ML","Definition":"<p>Use a procedure that does well in sparse problems, since no procedure does well in dense problems.</p>","Words":"Bet On Sparsity Principle"},{"Category":"Interpretable ML","Definition":"<p><strong>Basic filter methods</strong> are employed in the data preparation stage, before any modelling.</p>\n<p>They involve common sense operations such as : </p>\n<ul>\n<li>removing features that carry <strong>no information</strong> or <strong>duplicate</strong> it<ul>\n<li>use the pandas function <code>duplicated()</code></li></ul></li>\n<li><strong>constant features</strong> that don't change or with very low variance<ul>\n<li>Filter numerical values with <strong>zero variance</strong></li>\n<li>Filter categorical values with only 1 unique value</li></ul></li>\n<li><strong>quasi-constant</strong> features that are almost entirely the same value<ul>\n<li>Variance threshold won't work because high variance and quasi-constantness aren't mutually excluive. </li>\n<li>We can calculate <code>value_counts()</code> for each column and divide the counts by the total number of rows to get a pecentage and sort by the highest.</li>\n<li>This must be done with a lot of care and understanding of the problem.</li></ul></li>\n</ul>","Words":"Basic filter-based methods"},{"Category":"Interpretable ML","Definition":"<p>Another term for [[Opaque models]]. </p>\n<p>A system in which only the input and the output are observable, and you cannot see what is transforming the inputs into outputs.</p>\n<p>[[Model]]</p>\n<p>[[White-box models]] [[Opaque models]]</p>","Words":"Black-box models"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>[[Chapter 7 - Anchor and Counterfactual Explanations]]</li>\n<li>[[Chapter 11 - Bias Mitigation and Causal Inference Methods]]</li>\n</ul>","Words":"Calibrating and Equalizing Odds"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>Chapter 13</li>\n</ul>\n<p>[[Robust AI]] </p>","Words":"Adversarial Robustness Certified Training and Inference"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>[[Chapter 11 - Bias Mitigation and Causal Inference Methods]]</li>\n</ul>","Words":"Adversarial Debiasing"},{"Category":"Interpretable ML","Definition":"<p>The distance between the mean of different classes.</p>\n<p>[[Mean]] [[Variance]] [[Class]]</p>","Words":"Between-class variance"},{"Category":"Interpretable ML","Definition":"<p>Creating causal graphs and [[Causal Models]], tiying all variables together and estimating effects to make more principled decisions.</p>\n<p>Understanding cause and effect of a model. </p>\n<ul>\n<li>[[Chapter 11 - Bias Mitigation and Causal Inference Methods]]</li>\n</ul>","Words":"Causal Inference"},{"Category":"Interpretable ML","Definition":"<p>An efficient [[Gradient Boosted decision trees]]. Similar to [[LightGBM]] except it uses new technique called <a href=\"**MVS**\">[Minimal Variance Sampling]</a> instead of the [[Gradient-based One-Side Sampling]].</p>\n<p>Unlike LightGBM, it grows trees in a balanced fashion.</p>\n<p>It is called CatBoost because it can automatically encode #Categorical features, and it's particularly good at tracking #Overfitting , with #Unbias treatment of categorical features and class imbalances.</p>","Words":"CatBoost"},{"Category":"Interpretable ML","Definition":"<p>Confusion Matrix, ROC Curves, PR Curves</p>\n<ul>\n<li>[[Chapter 7 - Anchor and Counterfactual Explanations]]</li>\n<li>[[Chapter 11 - Bias Mitigation and Causal Inference Methods]]</li>\n<li>Chapter 12 </li>\n</ul>","Words":"Comparing Plots"},{"Category":"Interpretable ML","Definition":"<p>The idea of <em>controlling</em> some variables in a model, in order to <em>observe</em> others.</p>\n<p>[[Feature]] [[Model]]</p>","Words":"Ceteris Paribus"},{"Category":"Interpretable ML","Definition":"<p>False Positive Rate / False Negative Rate</p>\n<ul>\n<li>[[Chapter 7 - Anchor and Counterfactual Explanations]]</li>\n<li>[[Chapter 10 - Feature Selection and Engineering for Interpretability]]</li>\n<li>Chapter 12 </li>\n</ul>","Words":"Comparing Metrics"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>[[Chapter 3 - Interpretation Challenges]]</li>\n<li>[[Chapter 4 - Fundamentals of Feature Importance and Impact]]</li>\n<li>[[Chapter 7 - Anchor and Counterfactual Explanations]]</li>\n<li>[[Chapter 10 - Feature Selection and Engineering for Interpretability]]</li>\n<li>[[Chapter 11 - Bias Mitigation and Causal Inference Methods]]</li>\n<li>Chapter 12  - [[Research/AI/Machine Learning/Interpretable ML/Interpretable Machine Learning.pdf]]</li>\n</ul>","Words":"Class Balance"},{"Category":"Interpretable ML","Definition":"<p>[[Spearman Correlation Coefficients]]\n[[Point-biserial correlation coefficient]]\n[[Cramer's V]]\n[[Z test]]</p>\n<ul>\n<li>[[Chapter 5 - Global Model-Agnostic Interpretation Methods]]</li>\n<li>[[Chapter 10 - Feature Selection and Engineering for Interpretability]]</li>\n<li>Chapter 12</li>\n</ul>","Words":"Confirming with Statistical Tests and Correlation"},{"Category":"Interpretable ML","Definition":"<p>Similar to both [[Anchor]] and [[Counterfactual]] since it explains predictions using what is present (anchor) and absent (counterfactual). </p>\n<p>-&gt; <strong>Pertinent Positive</strong> : What is present (PP)\n-&gt; <strong>Pertinent Negative</strong> : What is absent (PN)</p>\n<p>However the differnece is that PPs are qualified as being minimally and sufficiently present to predict the same class. Liekwise, PNs are minimally and necessarily absent to predict the opposite class.\nTherefor CEM, works best with continuous and ordinal features because it expects to subtract from features until it reaches the desired outcome. \n-&gt; For this reason <strong>it doesn't know how to deal</strong> with non-monotonic continuous, non-ordinal, categorical, or even binary, features.</p>\n<p>It has a pertubation-based strategy, an [[Naive Elastic Net]], and a optionnal [[Variationnal Autoencoder (VAE)]] to help guide the #loss_function. (Very similar to [[Counterfactual Algorithms]] : <code>CounterFactualProto</code>). \nHowever, it doesn't fall back on a [[k-Decision Tree]], so the optional autoencoder is highly recomm</p>","Words":"Contrastive Explanation Method"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>[[Chapter 10 - Feature Selection and Engineering for Interpretability]]</li>\n<li>[[Chapter 11 - Bias Mitigation and Causal Inference Methods]]</li>\n<li>Chapter 12</li>\n</ul>","Words":"Cost senstive Learning"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>Chapter 12</li>\n</ul>","Words":"Contour and Heat Probability Maps"},{"Category":"Interpretable ML","Definition":"<p><strong>Correlation filter-based methods</strong> quantify the strength of the relationship between two features. It is usefull for feature selection because we might want to filter out extremely correlated features or those that aren't correlated with other at all.</p>\n<p>We need to choose a correlation method : </p>\n<ul>\n<li>[[Pearson's Correlation Coefficents]]</li>\n<li>[[Spearman Correlation Coefficients]]</li>\n<li>[[K</li>\n</ul>","Words":"Correlation filter-based methods"},{"Category":"Interpretable ML","Definition":"<p>Deep Neural Network</p>","Words":"DNN"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>Chapter 8</li>\n<li>[[Chapter 11 - Bias Mitigation and Causal Inference Methods]]</li>\n<li>Chapter 13</li>\n</ul>","Words":"Data Augmentation"},{"Category":"Interpretable ML","Definition":"<p>This metric comes from the same paper as [[Smoothed Emprirical Differential Fairness (SEDF)]], and like this, it also has zero as baseline of fairness and is also intersectional. \nHowver, it only measures the difference in unfairness in proportion between the model and the data in a phenomenon called [[Bias amplification]]. \nIn other words, <strong>the value represents how much more the model increases unfairness over original data</strong>. </p>","Words":"Differential fairness Bias Amplification (DFBA)"},{"Category":"Interpretable ML","Definition":"<p>Any fix that increases the confidence and consistency of predictions, excluding those that do so by reducing complexity.</p>\n<h2 id=\"datapreprocessing\">Data (pre-processing):</h2>\n<h3 id=\"fairnessml\">[[Fairness (ML)]]</h3>\n<ul>\n<li>[[Data Augmentation]]</li>\n</ul>\n<h3 id=\"accountabilityml\">[[Accountability (ML)]]</h3>\n<ul>\n<li><em>Drift Detection</em></li>\n<li>[[Data Augmentation]]</li>\n</ul>\n<h2 id=\"modelinprocessing\">Model (in-processing):</h2>\n<h3 id=\"fairnessml-1\">[[Fairness (ML)]]</h3>\n<ul>\n<li>[[Adversarial Debiasing]]</li>\n</ul>\n<h3 id=\"accountabilityml-1\">[[Accountability (ML)]]</h3>\n<ul>\n<li>[[Adversarial Training]]</li>\n<li>[[Adversarial Robustness Certified Training and Inference]]</li>\n</ul>\n<h2 id=\"predictionpostprocessing\">Prediction (post-processing):</h2>\n<h3 id=\"fairnessml-2\">[[Fairness (ML)]]</h3>\n<ul>\n<li><em>Fairness Model Certification</em></li>\n</ul>\n<h3 id=\"accountabilityml-2\">[[Accountability (ML)]]</h3>\n<ul>\n<li><em>Adversarial Postprocessing Defenses</em></li>\n<li><em>Adversarial Detection Defenses</em></li>\n<li><em>Prediction Confidence Intervals</em></li>\n</ul>","Words":"Enhancing Reliability"},{"Category":"Interpretable ML","Definition":"<p>Similar to [[Statistical Parity Difference (SPD)]] except it's the ratio not the difference. And, as ratios go, the closer to one the better; under one would mean disadvantaged, and over one means advantaged. The formula is shown here:</p>\n<p>$f$ is the value for the favorable class.</p>\n<p>$$\n\\frac{Pr(Y = f|  D = \\textrm{ unpriviledged})}{Pr(Y = f|  D = \\textrm{ priviledged})}\n$$</p>","Words":"Disparate Impact (DI)"},{"Category":"Interpretable ML","Definition":"<p>Any effort to secure private data and model architecture from third parties.</p>\n<h2 id=\"data\">Data :</h2>\n<h3 id=\"accountabilityml\">[[Accountability (ML)]]</h3>\n<ul>\n<li><em>Data Anonymization</em></li>\n<li><em>Differential Privacy</em></li>\n</ul>\n<h2 id=\"model\">Model :</h2>\n<h3 id=\"accountabilityml-1\">[[Accountability (ML)]]</h3>\n<ul>\n<li><em>Federated Learning</em></li>\n<li><em>All inference-attack Adversarial Defenses</em></li>\n</ul>\n<h2 id=\"prediction\">Prediction :</h2>\n<h3 id=\"accountabilityml-2\">[[Accountability (ML)]]</h3>\n<ul>\n<li><em>Privacy-Preserving Inference</em></li>\n</ul>","Words":"Ensuring Privacy"},{"Category":"Interpretable ML","Definition":"<p>Chapter 13  - [[Research/AI/Machine Learning/Interpretable ML/Interpretable Machine Learning.pdf]]</p>","Words":"Evasion Adversarial Robustness Evaluations"},{"Category":"Interpretable ML","Definition":"<p>Takes all that [[Interpretability]] does but deeper on the transparency requirement because it demands humand-friendly language.</p>","Words":"Explainability"},{"Category":"Interpretable ML","Definition":"<p>It's only the <strong>true-positive rate (TPR)</strong> differences of [[Average Odds Difference (AOD)]], so it's only useful to measure the <em>opportunity</em> for TPRs. As with AOD, negative confirms a disadvantage for the underpriviledged group, and the closer to zero, the better. </p>\n<p>$$\nTPR<em>{D=\\textrm{unpriviledged}} - TPR</em>{D=\\textrm{priviledged}}\n$$</p>","Words":"Equal Opportunity Difference (EOD)"},{"Category":"Interpretable ML","Definition":"<h2 id=\"diagnostic\">Diagnostic</h2>\n<p><strong>Concerns :</strong> </p>\n<ul>\n<li>Equity</li>\n<li>Justice</li>\n<li>Diversity</li>\n<li>Inclusion</li>\n</ul>\n<p><strong>Interpretation Methods :</strong> </p>\n<ul>\n<li>[[Class Balance]]</li>\n<li>[[Comparing Metrics]]</li>\n<li>[[Comparing Plots]]</li>\n<li>[[Group and Individual Fairness Metrics]]</li>\n<li>[[Contour and Heat Probability Maps]]</li>\n<li><em>Sampling Bias Evaluation</em></li>\n</ul>\n<h2 id=\"treatment\">Treatment</h2>\n<p><strong>Approach</strong> : </p>\n<ul>\n<li>[[Mitigating Bias]]</li>\n<li>[[Placing Guardrails]]</li>\n<li>[[Enhancing Reliability]]</li>\n<li>[[Reducing Complexity]]</li>\n</ul>","Words":"Fairness (ML)"},{"Category":"Interpretable ML","Definition":"<p>Selecting features based on statistical scores with the outcome varibale.\nMethods generally used as a preprocessing step. The selection of features is independent of any machine learning algorithms.</p>\n<p>Exemple of tests : </p>\n<ul>\n<li>[[Pearson's Correlation Coefficents]]</li>\n<li>[[Linear Discriminant Analysis (LDA)]]</li>\n<li>[[ANOVA F-test - Analysis of Variance]]</li>\n<li>[[Chi-squared test of independence]]</li>\n</ul>","Words":"Filter-based methods"},{"Category":"Interpretable ML","Definition":"<p>[[Shapley values (SHAP)]], [[Permutation Feature Importance]][[Model-specific]]</p>\n<ul>\n<li>[[Chapter 1 - Interpretation, Interpretability and Explainability]]</li>\n<li>[[Chapter 2 - Key Concepts of Interpratibility]]</li>\n<li>[[Chapter 3 - Interpretation Challenges]]</li>\n<li>[[Chapter 4 - Fundamentals of Feature Importance and Impact]]</li>\n<li>[[Chapter 5 - Global Model-Agnostic Interpretation Methods]]</li>\n<li>Chapter 8</li>\n<li>Chapter 9</li>\n<li>[[Chapter 10 - Feature Selection and Engineering for Interpretability]]</li>\n<li>Chapter 12  - [[Research/AI/Machine Learning/Interpretable ML/Interpretable Machine Learning.pdf]]</li>\n</ul>","Words":"Feature Importance Methods"},{"Category":"Interpretable ML","Definition":"<p>Also known as <strong>variable/attribute selection</strong> is the method to automatically or manually select a subset of specific features useful to the construction of ML models.</p>\n<p>[[Machine Learning]] #Models #Feature </p>\n<ul>\n<li>[[Chapter 10 - Feature Selection and Engineering for Interpretability]]</li>\n</ul>","Words":"Feature Selection"},{"Category":"Interpretable ML","Definition":"<p>[[Model]]s with close to complete [[Interpretability]].</p>\n<p>Examples :</p>\n<ul>\n<li><p>[[EBM]]</p></li>\n<li><p>[[Skopped Rules]]</p></li>\n<li><p>[[Chapter 3 - Interpretation Challenges]]</p></li>\n</ul>","Words":"Glass-box Model"},{"Category":"Interpretable ML","Definition":"<p>In the same way you can explain the role of <em>parts</em> of an internal combustion engine in the <em>whole</em> process of turning fuel into movement, you can also do so with a model. </p>\n<p>(<em>e.g. Feature importance help us understand how some parts affect the most the whole. Feature importance is only one of many global modular interpratation but arguiably the most important one.</em>)</p>\n<p>[[Global holistic interpretation]]</p>\n<p>[[Model]] #Explaination #Parts #Feature_Importance </p>","Words":"Global modular interpretation"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>[[Chapter 11 - Bias Mitigation and Causal Inference Methods]]</li>\n</ul>","Words":"GerryFair"},{"Category":"Interpretable ML","Definition":"<p>You can explain how a model makes predictions simply because you can compreh</p>","Words":"Global holistic interpretation"},{"Category":"Interpretable ML","Definition":"<p>A form of [[Decision Tree]].</p>","Words":"Gradient Boosted decision trees"},{"Category":"Interpretable ML","Definition":"<p>SPD, DI, AOD, DFBA, CDD</p>\n<ul>\n<li>[[Chapter 11 - Bias Mitigation and Causal Inference Methods]]</li>\n</ul>","Words":"Group and Individual Fairness Metrics"},{"Category":"Interpretable ML","Definition":"<p>Explaining [[Black-box models]] through [[White-box models]] that approximate them.\nCan be very accurate and efficient interpretation tools when chosen correctly.</p>\n<p>Usually refers to a white-box model trained with black-box model's prediction.\nCan also be used with a black-box model to approximate and evaluate another model that you don't have access to, but you have its predictions. Also called [[Proxy model]] for this kind of surrogate.</p>\n<p>[[Explainability]] [[Explanation]] [[Model]] </p>\n<blockquote>\n  <p><strong>Note</strong>\n  A surrogate model's finding can only be conclusive about the original model, and not about the data used to train the model.</p>\n</blockquote>","Words":"Global Surrogates"},{"Category":"Interpretable ML","Definition":"<p>A method that combines [[Embedded methods]] and [[Filter-based methods]] with [[Wrapper feature selection methods]]. </p>\n<p>Wrapper have the default of being greedy and computationally expensive. But we limit the dataset we might miss the best combination..!</p>\n<p>Combination of all three : Employ filter or embedded methods to derive only the top 10-features and perform EFS or SBS on only those. </p>\n<p><strong>Recursive feature elimination</strong> (RFE) : similar to SBS, but instead of removing feature based on improving a metric alone, we can use the model's intrisic parameters to rank features and only removing the least ranked.\nWe can only use models with <code>feature_importances_</code> or coefficients (<code>coef_</code>) because this is how the method knows what features to remove.\n<em>( Example of compatible models : <code>linear_model</code>, <code>tree</code>, <code>ensemble</code> )</em></p>\n<p>[[Feature Selection]]</p>","Words":"Hybrid feature selection methods"},{"Category":"Interpretable ML","Definition":"<p>Some of the most important in-processing or data-specific bias mitigation methods : </p>\n<ul>\n<li><strong>Cost-sensitive training</strong>: Same as using the <code>scale_pos_weight</code> parameter. It's typically used in imbalanced classification problems and is simply seen as a means to improve accuracy for minor classes. However given that imbalances with classes t</li>\n</ul>","Words":"In-processing bias mitigation methods"},{"Category":"Interpretable ML","Definition":"<p>Features that are of a higher cardinality are those that have more unique values (ex : Age has 72 uniques values, whereas questions usually have up to 6 answers).</p>\n<p>[[Feature]]</p>","Words":"Higher-cardinality features"},{"Category":"Interpretable ML","Definition":"<p>https://en.wikipedia.org/wiki/Homoscedasticity</p>\n<p>In statistics, a sequence (or a vector) of random variables is <strong>homoscedastic</strong> if all its random variables have the <strong>same finite variance</strong>. \nThis is also known as <strong>homogeneity of variance</strong>. The complementary notion is called heteroscedasticity. The spellings homoskedasticity and heteroskedasticity are also frequently used.</p>\n<p>Can be tested with the Goldfeld-Quandt test, and heteroscedasticity can be correxted with non-linear transformation.</p>\n<p>[[Variance]] [[Variable]]</p>","Words":"Homoscedasticity"},{"Category":"Interpretable ML","Definition":"<p>ICE plots answer the question : <em>What if my PDP plots obscure the variance in my feature-target relationships?</em></p>","Words":"Individual Conditional Expectation"},{"Category":"Interpretable ML","Definition":"<p>The extent to which humans, including nonsubject-matter experts, can understand the cause and effect, and input and output, of a machine learning model.</p>\n<p>To say a model has a high level of interpretability means you can describe in a human-interpretable way its inference. </p>\n<ul>\n<li><em>Why does an input to a model produce a specific output?</em></li>\n<li><em>What are the requirements and constraints of the input data?</em></li>\n<li><em>What are the confidence bounds of the predictions?</em></li>\n<li><em>Why does one variable have a more substantial effect than another?</em></li>\n</ul>\n<p>[[Model]] #Explaination [[Explainability]]</p>","Words":"Interpretability"},{"Category":"Interpretable ML","Definition":"<p>Explaining the meaning of something.</p>","Words":"Interpretation"},{"Category":"Interpretable ML","Definition":"<p>Same as [[White-box models]].</p>\n<p>[[Model]] [[Interpretation]]</p>","Words":"Intrinsically interpretable"},{"Category":"Interpretable ML","Definition":"<p>A nonparametric measure of the strength and direction of association that exists between two variables measured on at least an ordinal scale. It is considered a nonparametric alternative to the&nbsp;<a href=\"https://statistics.laerd.com/spss-tutorials/pearsons-product-moment-correlation-using-spss-statistics.php\">Pearson’s product-moment correlation</a>&nbsp;when your data has failed one or more of the assumptions of this test. It is also considered an alternative to the nonparametric&nbsp;<a href=\"https://statistics.laerd.com/spss-tutorials/spearmans-rank-order-correlation-using-spss-statistics.php\">Spearman rank-order correlation coefficient</a>&nbsp;(especially when you have a small sample size with many tied ranks). If you consider one of your variables as an independent variable and the other as a dependent variable, you might consider running a&nbsp;<a href=\"https://statistics.laerd.com/spss-tutorials/somers-d-using-spss-statistics.php\">Somers' d</a>&nbsp;test instead.</p>\n<p>For example, you could use to understand whether there is an association between exam grade and time spent revising (i.e., where there were six possible exam grades – A, B, C, D, E and F – and revision time was split into five categories: less than 5 hours, 5-9 hours, 10-14 hours, 15-19 hours, and 20 hours or more).</p>","Words":"Kendall's tau Correlation Coefficients"},{"Category":"Interpretable ML","Definition":"<p>Uses L1 penalty in the loss function, it can set coefficients to 0.</p>","Words":"Least absolute shrinkage and selection operator (LASSO)"},{"Category":"Interpretable ML","Definition":"<p>Derived from a <a href=\"MAB\">[Multi-Armed Bandit (MAB)]</a> algorithm. \nUses confidence regions based on the [[Kullback-Leibler Divergence (KL)]]. </p>\n<p>Similar algorithm than [[Upper Confidence Bound Method (UCB)]]</p>","Words":"Kullback-Leibler divergence Lower and Upper Confidence Bounds"},{"Category":"Interpretable ML","Definition":"<p>LIME trains local surrogates to explain a single prediciton.</p>\n<p>To this</p>","Words":"Local Interpretable Model-agnostic Explanations"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>It stems from [[Dimensionality Reduction]] and it's closely related to the [[Principale component Analysis (PCA)]]. </li>\n<li>It computes the <strong>[[Between-class variance]]</strong>, and the <strong>[[Within-class variance]]</strong>.</li>\n<li>Then it projects the data to a lower-dimensional space in such a way that it maximizes the distance between classes and minimizes the distance within classes.</li>\n</ul>\n<p>[[Distance]] [[Class]]</p>","Words":"Linear Discriminant Analysis (LDA)"},{"Category":"Interpretable ML","Definition":"<p>The same as 'single-prediction' expect that it applies to groups of predictions.</p>\n<p>[[Local single-prediction interpretation]]</p>","Words":"Local group-prediction interpretation"},{"Category":"Interpretable ML","Definition":"<p>You can explain why a single prediction was made.</p>\n<p>Methods :</p>\n<ul>\n<li><p>[[Decision Regions]]</p></li>\n<li><p>[[ICE]]</p></li>\n<li><p>[[Anchor]]</p></li>\n<li><p>[[Counterfactual]]</p></li>\n<li><p>[[WIT]]</p></li>\n<li><p>[[CEM]]</p></li>\n<li><p>[[Shapley values (SHAP)]]</p></li>\n<li><p>[[Chapter 6 - Local Model-Agnostic Interpretation Methods]]</p></li>\n<li><p>[[Chapter 7 - Anchor and Counterfactual Explanations]]</p></li>\n<li><p>Chapter 9</p></li>\n</ul>\n<p>[[Prediction]] [[Explainability]] [[Local group-prediction interpretation]]</p>","Words":"Local single-prediction interpretation"},{"Category":"Interpretable ML","Definition":"<p>A variable that influences the strength between the indep</p>","Words":"Mediating variables"},{"Category":"Interpretable ML","Definition":"<p>Any corrective measure taken to account for bias. Please note that this bias refers to the sampling, exclusion, prejudice and measurement biases in the data, along with any other bias, introduced in the ML workflow.</p>\n<h2 id=\"whentoapply\">When to apply?</h2>\n<ul>\n<li>[[In-processing bias mitigation methods]]</li>\n<li>[[Pre-processing bias mitigation methods]]</li>\n<li>[[Post-processing bias mitigation methods]]</li>\n</ul>\n<h2 id=\"data\">Data :</h2>\n<h3 id=\"fairnessml\">[[Fairness (ML)]]</h3>\n<ul>\n<li>[[Reweighting]] / DIR</li>\n<li>LFR / DIR / Unawarness <ul>\n<li>Chapter 12</li></ul></li>\n</ul>\n<h3 id=\"accountabilityml\">[[Accountability (ML)]]</h3>\n<ul>\n<li>[[Feature Selection]]</li>\n<li>[[Adversarial Preprocessing Defenses]]</li>\n</ul>\n<h2 id=\"model\">Model :</h2>\n<h3 id=\"fairnessml-1\">[[Fairness (ML)]]</h3>\n<ul>\n<li>[[Cost senstive Learning]]</li>\n<li>[[Prejudice Regularization]] and [[GerryFair]]</li>\n</ul>\n<h3 id=\"accountabilityml-1\">[[Accountability (ML)]]</h3>\n<ul>\n<li>[[Regularization]]</li>\n</ul>\n<h2 id=\"prediction\">Prediction :</h2>\n<h3 id=\"fairnessml-2\">[[Fairness (ML)]]</h3>\n<ul>\n<li>[[Calibrating and Equalizing Odds]]</li>\n<li><em>Reject Option Classification</em></li>\n</ul>","Words":"Mitigating Bias"},{"Category":"Interpretable ML","Definition":"<p>Methods that can work with any model class.</p>\n<p>[[Model]] #Method</p>\n<p>[[Model-specific]]</p>","Words":"Model-agnostic"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>Chapter 12</li>\n</ul>","Words":"Monotonic Constraints"},{"Category":"Interpretable ML","Definition":"<p>Methods that can only be used for a specific model class.</p>\n<p>[[Model]] #Method </p>\n<p>[[Model-agnostic]]</p>","Words":"Model-specific"},{"Category":"Interpretable ML","Definition":"<p>A function that preserves or reverse she given order. It is either entirely non-increasing, or entirely non-decreasing.</p>\n<p>[[Function]] [[Monotonic function]]</p>","Words":"Monotonic function"},{"Category":"Interpretable ML","Definition":"<p>Randomly sample from a probability distribution. Observation and features.</p>\n<p>[[Random]] [[Probability Distribution]] </p>","Words":"Monte Carlo sampling"},{"Category":"Interpretable ML","Definition":"<p>Occurs when features are highly correlated with each other. Can be tested with a correlation matrix, tolerance measure, or Variance Inflation Factor (VIF), and can be fixed by removing one of each higly correlated features.</p>\n<p>[[Correlation]] [[Feature]]</p>","Words":"Multicollinearity"},{"Category":"Interpretable ML","Definition":"<p>The features are distributed normally for each class.</p>\n<p>[[Class]] [[Feature]] [[Normal Distribution]]</p>","Words":"Multivariate normality"},{"Category":"Interpretable ML","Definition":"<p>Models that lack <em>model transparency</em>, but for many models this is unavoidable, however justified the model choice might be. </p>\n<p>[[Model]]  [[Transparency (ML)]]</p>\n<p>[[White-box models]] [[Black-box models]] </p>","Words":"Opaque models"},{"Category":"Interpretable ML","Definition":"<p>An open standard for [[Interoperability]] of [[Machine Learning]] algorithms.</p>","Words":"Open Neural Netwrok Exchange (ONNX)"},{"Category":"Interpretable ML","Definition":"<p>The property that each figure is normally distributed. Can be tested with a <strong>Q-Q plot</strong>, histogram, or <strong>Kolmogorov-Smirnov</strong> test. Non-normality can be corrected with corrected with non-linear transformation.</p>\n<p>[[Normal Distribution]]</p>","Words":"Normality"},{"Category":"Interpretable ML","Definition":"<p>Chapter 8 </p>","Words":"Out-of-sample Evaluations"},{"Category":"Interpretable ML","Definition":"<p>Graph showing the dependence between the target response and a set of input features of interest, marginalizing over the values of all other input features.\nThese plots can be interpreted as the <strong>expected target reponse as a function of the input features of interest</strong>. </p>\n<p>![[Partial Dependence Plot.png]]</p>","Words":"Partial Dependence Plots"},{"Category":"Interpretable ML","Definition":"<p>Measures how linearly correlated two features between -1 (negative) and 1 (positive) with 0 meaning no linear correlation.\nIt assumes #Linearity , #Normality , and [[Homoscedasticity]]</p>","Words":"Pearson's Correlation Coefficents"},{"Category":"Interpretable ML","Definition":"<p>A reliable permutation-based method to explore #Feature_Importance.\nMeasures the increase in prediction error once the values of each feature have been shuffled.\nThe theory is that if the feature has a relationship with the target variable, shuffling will disrupt and increase the error. Then you can rank each features by those whose shuffling increases the error the most, we can appreciate which ones are most important to the model.</p>\n<p>It is [[Model-agnostic]], and can be used with unseen data such as the test dataset, which is a massive advantage.</p>\n<p>[[Interpretability]] #Shuffling #Error </p>\n<p><strong>Main disadvantages</strong> : The method won't pick up on the impact of features correlated with each other. In other words, multicollinearity will trump feature importances. #Multicollinearity </p>","Words":"Permutation Feature Importance"},{"Category":"Interpretable ML","Definition":"<p>Interpretability that doesn't exclude the understanding that the definition of interpretability shoudn't necessarily exclude opaque models, which, for the most part, are complex, as long as the choices made don't compromise their trustworthiness.</p>\n<p>[[Interpretability]] [[Model]] [[Explanation]] [[Explainability]]</p>","Words":"Post-hoc interpretability"},{"Category":"Interpretable ML","Definition":"<p>Any solutions that ensures that the model doesn't contradict domain knowledge and predict without confidence.</p>\n<h2 id=\"data\">Data :</h2>\n<h3 id=\"fairnessml\">[[Fairness (ML)]]</h3>\n<ul>\n<li>[[Feature Engineering]]</li>\n</ul>\n<h2 id=\"model\">Model :</h2>\n<h3 id=\"fairnessml-1\">[[Fairness (ML)]]</h3>\n<ul>\n<li>[[Monotonic Constraints]]</li>\n</ul>\n<h2 id=\"predicition\">Predicition :</h2>\n<h3 id=\"fairnessml-2\">[[Fairness (ML)]]</h3>\n<ul>\n<li>[[Prediction and Abstention]]</li>\n</ul>","Words":"Placing Guardrails"},{"Category":"Interpretable ML","Definition":"<p>Same as [[Spearman Correlation Coefficients]] but for #Dichotomous_feature. \nIt doesn't assume [[Monotonicity]].</p>","Words":"Point-biserial correlation coefficient"},{"Category":"Interpretable ML","Definition":"<p>Some of the most important postprocessing or data-specific bias mitigation methods : </p>\n<ul>\n<li><strong>Prediction abstention</strong>: <ul>\n<li>Many potential benefits such as fairness, safety, or controlling costs. Typically, a model will return all predictions, even the low-confidence ones. When fairness is involved, if we change predictions to <strong>I don't know (IDK)</strong> in low confidence regions, the model will likely become fairer as a side effect when we assess fairness metrics only against predictions that were made. </li>\n<li>it is also possible to make prediction abstention an in-processing method. <a href=\"https://arxiv.org/abs/1711.06664\">This paper</a> discusses two approaches to do this by training a model to either <strong>punt</strong> (learn to predict IDK) or <strong>defer</strong> (predict IDK when the odds of being correct are lower than expert opinion).</li>\n<li>Similar paper with <a href=\"https://arxiv.org/abs/1512.08133#:~:text=We%20explore%20the%20problem%20of,without%20committing%20to%20any%20prediction.\">this paper</a> with a [[Reinforcement Learning (RL)]] framework called <strong>Knows what it knows (KWIK)</strong>, which ahs self awarness of its mistakes but allows for abstentions. </li></ul></li>\n<li><strong>Equalized odds postprocessing</strong>: Also known as <strong>disparate mistreatment</strong>, this ensures that priviledged and underpriviledged groups have <strong>equal treatment for misclassifications</strong>, wether FP or FN.  It finds optimal probability thresholds with which chaning the labels equalizes the odds between groups.</li>\n<li><strong>Calibrated eqaulized odds postprocessing</strong>: Instead of changing the labels, this method modifies the probability estimates so that they are on average equal. It calls this <em>calibration</em>. However, this constraint cannot be satisfied for FP or FN concurrently, so you are forced to prefer one over the other. Therefor it is advantageous in cases where recall is far more important than precision or vice-versa. </li>\n<li><strong>Reject option classification</strong>: This method leverages the intuition that *predictions around the decision boundary t</li>\n</ul>","Words":"Post-processing bias mitigation methods"},{"Category":"Interpretable ML","Definition":"<p>Some of the most important preprocessing or data-specific bias mitigation methods : </p>\n<ul>\n<li><p><strong>Unawareness</strong>: Also known as <strong>suppresion</strong>. The most straightforward way to remove bias is to exclude Biased features from the dataset but it's a naive approach because you assume that bias is stricly contained in those features. </p></li>\n<li><p><strong>Feature engineering</strong>: Continuous features capture bias because there are so many sparse areas where the model can fill voids with assumptions or learn from outliers. It can do the same with interactions. Feature engineering can place guardrails.</p></li>\n<li><p><strong>Balancing</strong>: Also known as <strong>resampling</strong>. On their own, representation problems are relatively easy to fix by balancing the dataset. The <a href=\"https://github.com/EthicalML/xai\">XAI library</a> has a <code>balance</code> function that does this by random downsampling and upsampling of group representations.</p>\n<ul>\n<li>Down sampling is what we call typically sampling, which is just taking a certain percentage of the observations</li>\n<li>upsampling creates a random amount of random duplicates. </li>\n<li>Some strategies synthetically upsample rather than duplicate such as the [[Synthetic Minority Oversampling TEchnique (SMOTE)]]. </li>\n<li>However, it is always preferable to downsample instead of upsampling if we have enough data. It is best not to use balancing strategy if there are other possible bias problems.</li></ul></li>\n<li><p><strong>Relabeling</strong>: Also known as <strong>massaging</strong>, this is having an algorithm change the labels for observation that appear to be most biasedm resulting in <em>massaged data</em> by ranking them. </p>\n<ul>\n<li>Usually this is performed with a [[Naive-Bayes classifier]], and to maintain class distribution, it not only promotes some observations but demotes an equal amount. </li></ul></li>\n<li><p><strong>Reweighing</strong>: This method similarly ranks observations as relabeling does, but instead of flipping their labels it derives a weigth for each one, which can then implement in the learning process. Much like class weigths are applied to each class, sample weights are applied to each observation or sample.</p>\n<ul>\n<li>This method does not impact negatively on model's performance.</li></ul></li>\n<li><p><strong>Disparate impact remover</strong>: The authors of this methods were very careful to abide by legal definitions of bias and preserve the integrity of the data without changing the labels or the protected attribues. It implements a repair process that attemps to remove bias in the remaining features. It's an excellent process to use whenevercorrelated with the protected attributes but it doesn't adress bias elsewhere. In any case it's a good baseline to use to understand <em>how much of the bias is non-proteted features</em>.</p></li>\n<li><p><strong>Learning fair representations</strong>: This leverages an adversarial learning framework. There's a generator ([[Variationnal Autoencoder (VAE)]]) that creates representations of the data ecluding the protected attribute, and a critic whose goal is that the learned representaitons within privileged and underprivilieged groups are as close as possible.</p></li>\n<li><p><strong>Optimized preprocessing for discrimination prevention</strong>: This method produces transformations through mathematical optimization to the data in such a way that overall probability distributions are maintained. At the same time, the correlation between protected attributes and the target is nullified. The result of this process is data that is distorted slightly to de-bias it. </p></li>\n</ul>\n<p>All of those methods are available at the <a href=\"https://aif360.mybluemix.net/\">AIF360 Library</a> **</p>","Words":"Pre-processing bias mitigation methods"},{"Category":"Interpretable ML","Definition":"<p>Increasing the [[Fairness (ML)]] of a [[Model]] by allowing it to not give a response when in a low confidence region. </p>\n<ul>\n<li>[[Chapter 11 - Bias Mitigation and Causal Inference Methods]]</li>\n<li>Chapter 12</li>\n</ul>","Words":"Prediction and Abstention"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>[[Chapter 11 - Bias Mitigation and Causal Inference Methods]]</li>\n</ul>","Words":"Prejudice Regularization"},{"Category":"Interpretable ML","Definition":"<p><strong>A statistical scorecard that is used to predict the behaviour of your customer or prospect base</strong>. They are often used to identify those most likely to respond to an offer, or to focus retention activity on those most likely to churn.</p>\n<p>[[Churn]] [[Marketing]]</p>","Words":"Propensity Model"},{"Category":"Interpretable ML","Definition":"<p><strong>Ranking filter-based methods</strong> are based on statistical univariate ranking tests, which asses the strength of features against the target. </p>\n<p>Here are some of the most popular methods : </p>\n<ul>\n<li>[[ANOVA F-test - Analysis of Variance]]</li>\n<li>[[Chi-squared test of independence]]</li>\n</ul>","Words":"Ranking filter-based methods"},{"Category":"Interpretable ML","Definition":"<p>Means to emulate output from a [[Black-box models]] just like [[Global Surrogates]] #Models</p>\n<p>In ML, surrogate and proxy are terms often used interchangeably.</p>\n<p>[[Machine Learning]] [[Interpretability]] </p>","Words":"Proxy Models"},{"Category":"Interpretable ML","Definition":"<p>Root Mean Squared Error</p>\n<p>$$\nRMSE = \\sqrt{\\sum^n<em>{i = 1} \\frac{(\\widehat y</em>i - y_i)^2}{n}}\n$$</p>","Words":"RMSE"},{"Category":"Interpretable ML","Definition":"<p>Similar to [[Linear Discriminant Analysis (LDA)]], but makes no normality assumptions and splits the classes with a quadratic decision boundary rather than a linear one.</p>\n<p>[[Normality]] [[Class]]</p>","Words":"Quadratic Discriminant Analysis"},{"Category":"Interpretable ML","Definition":"<p>A form of [[Global Surrogate]] that uses a black-box model to approximate and evaluate another model that you don't have access to, but you have its predictions.</p>","Words":"Proxy model"},{"Category":"Interpretable ML","Definition":"<p>The <strong>Rashomon effect</strong> is the situation in which an event is given <strong>contradictory interpretations or descriptions by the individuals involved</strong>, and is a storytelling and writing method in cinema meant to provide different perspectives and points of view of the same incident.</p>\n<p>![[Pasted image 20220103101057.png]]</p>","Words":"Rashomon effect"},{"Category":"Interpretable ML","Definition":"<ul>\n<li>[[Chapter 11 - Bias Mitigation and Causal Inference Methods]]</li>\n</ul>","Words":"Reweighting"},{"Category":"Interpretable ML","Definition":"<p>A collection of methods , or explainers, that approximate [[Shapley values (SHAP)]] while adhering to its mathematical properties, for the most part.</p>\n<p>Three properties that are loosely based on Shapley's : </p>\n<ul>\n<li><strong>Local accuracy</strong> : Equivalent to Shapley's efficiency property</li>\n<li><strong>Consistency</strong> : Encompasses additivity and substitutability axioms, and, in theory, dummy as well.</li>\n<li><strong>Missingness</strong> : This means that if a feature is missing, its Shapley value is zero. It's a sanity-check property that, in practice, is only needed when features are constant.</li>\n</ul>\n<p>SHAP has a bunch of explainers adapted for each type of model. They need to be adapted for approximation efficiency, leveraging the model's structure or parameters. For this reason, four of them aren't [[Model-agnostic]] [[Model-specific]].\nMost of them are discussed in the main <a href=\"https://arxiv.org/abs/1705.07874\">SHAP paper : A Unified Approach to Interpreting Model Predictions</a></p>\n<p>|                |       Explainer      |      Method \"unified\"     |                          Compatibility with …                          |\n|----------------|:--------------------:|:-------------------------:|:------------------------------------------------------------------------:|\n| <strong>Model-Specific</strong> |     TreeExplainer    |          TreeSHAP         | XGBoost, LightGBM, CatBoost, PySpark, sklearn.tree.<em>, sklearn.ensemble.</em> |\n|                |     DeepExplainer    |          DeepLIFT         |                      tf.keras.Model, torch.nn.Module                     |\n|                |   GradientExplainer  |    Integrated Gradients   |                      tf.keras.Model, torch.nn.Module                     |\n|                |    LinearExplainer   | Shapely Regression Values |                          sklearn,linear_model.*                          |\n| <strong>Model-Agnostic</strong> |    kernerExplainer   |            LIME           |                                                                          |\n|                |   SamplingExplainer  |  Shapely Sampling Values  |                                                                          |\n|                | PermutationExplainer |                           |                                                                          |\n|                |  PartitionExplainer  |                           |                                                                          |\n|                |   AdditiveExplainer  |                           |                                                                          |</p>\n<p><strong>Advantages</strong></p>\n<ul>\n<li>SHAP is grounded in game theory and approximate [[Shapley values (SHAP)]], so it's SHAP values mean something.</li>\n<li>They have great properties such as additivity, efficiency and substitutability that make it consistent but violate the dummy property.</li>\n</ul>\n<p><strong>Disadvantages</strong></p>\n<ul>\n<li>More suited for global interpretations</li>\n<li><code>KernelExplainer</code> is agnostic but really slow.</li>\n</ul>","Words":"SHapley Additive exPlanations"},{"Category":"Interpretable ML","Definition":"<p>Average marginal contribution by a feature across all possible subsets.</p>\n<p>In [[Coalitional theory]] (also known as [[cooperative game theory]]) : </p>\n<ul>\n<li>The different combinations of features are <strong>coalitions</strong> (different subset of features are the <strong>coalitions of features</strong>)</li>\n<li>The differences in scores are <strong>marginal contributions</strong></li>\n<li>The contribution of a feature, also known as the <strong>payoff</strong>, is a reduction in predictive error, for regression, or an increase in probability for classification.</li>\n<li>The <strong>Shapley value</strong> is the average of these contributions over many simulations.</li>\n</ul>\n<p>You have a full coalition with all your features, and you have all the possible subsets of the features minus the feature you are evaluating. \nThe contribution of a feature, also known as the <strong>payoff</strong>, is a reduction in predictive error (for regression), or an increase in probability (for classification).\nAll this is weighted by <strong>the probability of randomly drawing that subset of features over all possible subsets</strong>. And these weighted contributions are added up across all possible subsets, and voila !</p>\n<p>Shapley values have several properties derived from coalitional game theory that make it ideal as a #Feature_Importance #Method : </p>\n<ul>\n<li><strong>Dummy</strong> : If a feature <em>i</em> never contributes any marginal value,\n$$Shapley_i = 0$$</li>\n<li><strong>Substitutability</strong> : If two given features $i$ and $j$ contribute equally to all their possible subsets\n$$Shapley<em>i = Shapley</em>j$$</li>\n<li><strong>Additivity</strong> : If a model $p$ is an ensemble of $k$ submodels, the contributions of a feature $i$ in the submodel should add upp \n$$Shapley^p<em>i = \\sum^k</em>{n=1}{Shapley^n_j}$$ </li>\n<li><strong>Efficiency</strong> : Likewise, all Shapley values must add up as the difference between predictions and expected value.</li>\n</ul>","Words":"Shapley values (SHAP)"},{"Category":"Interpretable ML","Definition":"<p>Any means by which sparsity is introduced. As a side effect, this generally enhances reliability by generalizing better.</p>\n<h2 id=\"data\">Data :</h2>\n<h3 id=\"fairnessml\">[[Fairness (ML)]]</h3>\n<ul>\n<li>[[Feature Selection]]</li>\n</ul>\n<h3 id=\"accountabilityml\">[[Accountability (ML)]]</h3>\n<ul>\n<li>[[Feature Selection]]</li>\n<li>[[Adversarial Preprocessing Defenses]]</li>\n</ul>\n<h2 id=\"model\">Model :</h2>\n<h3 id=\"fairnessml-1\">[[Fairness (ML)]]</h3>\n<ul>\n<li>[[Regularization]]</li>\n</ul>\n<h3 id=\"accountabilityml-1\">[[Accountability (ML)]]</h3>\n<ul>\n<li>[[Regularization]]</li>\n</ul>\n<h2 id=\"prediction\">Prediction :</h2>\n<h3 id=\"fairnessml-2\">[[Fairness (ML)]]</h3>\n<ul>\n<li>[[Feature Selection]]</li>\n</ul>\n<h3 id=\"accountabilityml-2\">[[Accountability (ML)]]</h3>\n<ul>\n<li>[[Regularization]]</li>\n</ul>","Words":"Reducing Complexity"},{"Category":"Interpretable ML","Definition":"<p>A goodness-of-fit #Measure that tells you what percentage of #variability is explained by the model.</p>","Words":"R-squared"},{"Category":"Interpretable ML","Definition":"<p>Chapter 9</p>","Words":"Sensitivity Analysis"},{"Category":"Interpretable ML","Definition":"<p>A [[Bias]] in which a sample is collected in such a way that some members of the intended population have a lower or higher sampling [[Probability Distribution]] than others.</p>","Words":"Sample bias"},{"Category":"Interpretable ML","Definition":"<p>Also known as the <strong>mean difference</strong>, this is the difference between the mean probability of favorable outcomes between underpriviledged and priviledged groups.</p>\n<p>A negative number is bad and a positive number is better, yet a number closer to zero is always preferable. </p>\n<p>It's computed with the following formula, where $f$ is the value for the favorable class:</p>\n<p>$$\nPr(Y = f|D =  \\textrm{ unpriviledged}) - Pr(Y = f| D =  \\textrm{ priviledged})\n$$</p>","Words":"Statistical Parity Difference (SPD)"},{"Category":"Interpretable ML","Definition":"<p>[Measure] the [[Monotonicity]] between two continuous feature.</p>\n<p>It outputs a number between -1 and 1, indicating both the strength and direction of the relationship. \nValues closest to both extremes are the strongest, either negatively or positively, while values nearer to zero are the least strong.</p>\n<p>They can mesure relationships as long as they are behave like a [[Monotonic function]]. Non-[[Linearity]] relationship that are non-[[Monotonicity]] won't be considered strong by this method. \nE.g. A parabolic curve will have a value of $0$.</p>","Words":"Spearman Correlation Coefficients"},{"Category":"Interpretable ML","Definition":"<p>This #Fairness metric is one of the many newer ones from a paper classed <a href=\"https://arxiv.org/abs/1807.08362\">\"An Intersectional Definition of Fairness\"</a>. \nUnlinke [[Statistical Parity Difference (SPD)]] and [[Disparate Impact (DI)]], it's not restricted to the predetermined privieges and underprivileged groups, but it's ext</p>","Words":"Smoothed Emprirical Differential Fairness (SEDF)"},{"Category":"Interpretable ML","Definition":"<h2 id=\"diagnostic\">Diagnostic</h2>\n<p><strong>Concerns</strong> : </p>\n<ul>\n<li>[[Interpretability]]</li>\n<li>[[Explainability]]</li>\n<li>Consistency</li>\n<li>Credibility</li>\n<li>Clarity</li>\n</ul>\n<p><strong>Interpretation Methods</strong> : </p>\n<ul>\n<li>[[Feature Importance Methods]]</li>\n<li>[[Dimensionality Reduction]] Methods</li>\n<li>[[Glass-box Model]]</li>\n<li>[[Partial Dependence Plots]]</li>\n</ul>","Words":"Transparency (ML)"},{"Category":"Interpretable ML","Definition":"<p>A family of [[Model]]s that operate in high-dimensional spaces to find an optimal hyperplane, where they separate the classes with the maximum margin between them. </p>\n<p>They are the points closest to the decision boundary. </p>\n<p>The [[Cost function]] is the [[Hinge loss]].\nThey use a [[Kernel Trick]] to operate cheap operation in high dimensional spaces.</p>","Words":"Support Vector"},{"Category":"Interpretable ML","Definition":"<p>Defined as the belief in the reliability, ability, or credibility of something or someone.</p>","Words":"Trust"},{"Category":"Interpretable ML","Definition":"<p>A tool made by Google for interpretation of [[Counterfactual]] elements. </p>\n<p>It requires very little input or preparation and opens up in you jupyter notebook as an interactive dashboard with three tabs : </p>\n<ul>\n<li><strong>Datapoint editor</strong> : To visualize your datapoints, edit them, and explain their predictions.</li>\n<li><strong>Performance</strong> : To see high-level model performance metrics (for all regression and classification models). For binary classification, this tab is called <strong>performance and Fairness</strong> because, in addition to high-level metrics, predictive fairness can be compared between your datas's feature-based slices.</li>\n<li><strong>Features</strong> : To view general feature statistics.</li>\n</ul>\n<p><strong>Configuration</strong> : </p>\n<ul>\n<li>Creating <strong>attributions</strong> : Values that explain how much each feature contributes to each prediction. Can be created by using [[Shapley values (SHAP)]]. </li>\n<li>Seting up a custom distance in the dashboard</li>\n</ul>\n<p><strong>Features</strong> :</p>\n<ul>\n<li><strong>Datapoint Editor</strong> which has is [[Partial Dep</li>\n</ul>","Words":"What-if Tool"},{"Category":"Interpretable ML","Definition":"<p>Opposite of black-box models. Also known as transparent models.</p>\n<p>They achieve total to near-total interpretation transparency. \nThey are called <strong>[[Intrinsically interpretable]]</strong> in the book. </p>\n<p>[[Opaque models]] [[Black-box models]] [[Model]] [[Transparency (ML)]] </p>\n<p>[[Global Surrogates]]</p>\n<ul>\n<li>[[Chapter 5 - Global Model-Agnostic Interpretation Methods]]</li>\n<li>[[Chapter 10 - Feature Selection and Engineering for Interpretability]]</li>\n<li>Chapter 12  - [[Research/AI/Machine Learning/Interpretable ML/Interpretable Machine Learning.pdf]]</li>\n</ul>","Words":"White-box models"},{"Category":"Interpretable ML","Definition":"<p>Exhaustively look for the best subset of features by fitting an [[Machine Learning]] model using a search strategy that measures improvement on a metric.\nIt evaluates different subsets of features on the ML model and choose the one that achieves the best score in a predetermined objective function.</p>\n<p>What varies here is the search strategy : </p>\n<ul>\n<li><strong>Sequential foward selection</strong> (SFS) : begins without a feature, and adds one at a time. </li>\n<li><strong>Sequential forward floating selection</strong> (SFFS): Same as SFS except for every features it adds, it can remove one as long as the objective function increases.</li>\n<li><strong>Sequential backward selection</strong> (SBS): This process begins with all features present and eliminates one feature at a time.</li>\n<li><strong>Sequential floating backward selection</strong> (SFBS) : Same as SBS except for every feature it removes, it can add one as long as the objective function increases.</li>\n<li><strong>Exhaustive feature selection</strong> (EFS) : This approach seeks all possible combinations of features.</li>\n<li><strong>Bidirectional search</strong> (BDS) : Allows both foward and backward function selection to get one unique solution.</li>\n</ul>\n<p>They are greedy by nature. Even though they may arrive at a local maximum, the take an approach more suited for finding local maxima.</p>\n<p>Dep</p>","Words":"Wrapper feature selection methods"},{"Category":"Interpretable ML","Definition":"<p>The variance within each class</p>\n<p>[[Variance]] [[Class]]</p>","Words":"Within-class variance"},{"Category":"Interpretable ML","Definition":"<p>A library that implements [[Gradient Boosted decision trees]] much like ScikitLearn <code>GradientBoostingRegressor</code>, an [[Ensemble Method]] we have used in previous chapters. \nHowever, it has a lot of optimizations making it faster and more scalable, increase predictive performance and potentially make it even less prone to overfitting.</p>\n<p>It uses [[Weighted Quantile Sketch]] and [[Sparsity-aware Split Finding]].\n[[Decision Tree]] are built <a href=\"top-down\">[Depth-first]</a>.</p>","Words":"XGBoost"},{"Category":"Computer Science","Definition":"<p>Study of the \"information content* of mathematical objects. We can use Algorithmic Complexity to define the information content that a string <em>s2</em> possesses about a string <em>s1</em> (called “Relative Algorithmic Complexity” and noted $H(s1|s2))$, as the length of the shortest program that, taking s2 as input, produces s1.</p>\n<p>[[Measure]] [[Information]] [[Mathematics]]</p>","Words":"Algorithmic Complexity"},{"Category":"Computer Science","Definition":"<p>Computer science's extension of Information Theory. AIT concerns itself with formalizing useful computer science intuitions regarding complexity, randomness, information, and computation.</p>\n<p>[[Information Theory]] [[Complexité Algorithmique]] [[Random]] [[Information]]</p>","Words":"Algorithmic Information Theory"},{"Category":"Computer Science","Definition":"<p>Logically possible environmnets which cannot be rendered</p>","Words":"CantGoTu environments"},{"Category":"Computer Science","Definition":"<p>A Device that can generate specifiable sensations for a user. </p>","Words":"Image Generator"},{"Category":"Computer Science","Definition":"<p>An [[Image]] is accurate in so far as the sensations it geneates are close to the int</p>","Words":"Image accuracy"},{"Category":"Computer Science","Definition":"<p>Something that gives rise to sensations.</p>","Words":"Image"},{"Category":"Computer Science","Definition":"<p>The ability of a system, either learning or static, to handle situations that neither the system nor the developer of the system has encountered before.</p>\n<p>[[Learning]] [[Generalization]]</p>","Words":"Developer-aware generalization"},{"Category":"Computer Science","Definition":"<p>An [[Image accuracy]] so great that the user cannot distinguish the [[Image]] or r</p>","Words":"Perfect Image Accuracy"},{"Category":"Computer Science","Definition":"<p>The repertoir of a [[Virtual Reality]] generator is the set of environments that the generator can be programmed to give the user the experience of.</p>","Words":"Repertoire"},{"Category":"Computer Science","Definition":"<h2 id=\"strongestform\">Strongest Form</h2>\n<p>It is physically possible to build a [[Universal Virtual-Reality Generator]].</p>\n<h2 id=\"original\">Original</h2>\n<p><em>There exists an abstract universal computer whose [[Repertoire]] includes any #Computation that any physically possible object can perform.</em>\n=&gt; [[Universal Turing Machine]]</p>","Words":"Turing Principle"},{"Category":"Computer Science","Definition":"<p>One of the first abstract models of computation.</p>\n<p>Allows the [[Turing Principle]].</p>\n<p>Made by [[Alan Turing]], [[Emil Post]], and [[Alonzo Church]].</p>","Words":"Turing Machine"},{"Category":"Computer Science","Definition":"<p>an [[Image Generator]] that can be programmed to generate any sensation that the user is capable of experiencing.</p>","Words":"Universal Image Generator"},{"Category":"Computer Science","Definition":"<p>a [[Turing Machine]]</p>","Words":"Universal Turing Machine"},{"Category":"Computer Science","Definition":"<p>One whose [[Repertoire]] contains every physically possible environments.</p>","Words":"Universal Virtual-Reality Generator"},{"Category":"Computer Science","Definition":"<p>Any situation in which the user is given the experience of being in a specified environment.</p>","Words":"Virtual Reality"},{"Category":"Web","Definition":"<p>A form of [[Proxy]]</p>\n<p>In&nbsp;<a href=\"https://en.wikipedia.org/wiki/Computer_network\" title=\"Computer network\">computer networks</a>, a&nbsp;<strong>reverse proxy</strong>&nbsp;is the application that sits in front of back-end applications and forwards client (e.g. browser) requests to those applications. Reverse proxies help increase #Scalability, #Performance, #Resilience and #Security. The resources returned to the client appear as if they originated from the web server itself.<a href=\"https://en.wikipedia.org/wiki/Reverse_proxy#cite_note-apache-forward-reverse-1\">[1]</a></p>\n<p>[[Computer Network]]</p>","Words":"Reverse Proxy"},{"Category":"Web","Definition":"<p>Helps processing incoming [[Requests]].\nAnalyzes, see if wanted information is in cache, redirects to the application, …</p>","Words":"Proxy"},{"Category":"Mathematics","Definition":"<p>Having a physical property that has a different value when measured in different directions. An example is wood, which is stronger along the grain than across it.</p>","Words":"Anisotropic"},{"Category":"Mathematics","Definition":"<p>Core idea is to place distributions not just on observed variablesm as in classical frequentist statistics, but also on parameters that generate those observed variables.</p>\n<p>E.g.  Consider a coin that lands heads or tails with a probability $p$. We observe variable $X \\in { \\text{Heads, Tails} }$ with the probability of the coin landing heads up being $p$. \nIn classical statistics, only $X$ has a distribution. Here, $p$ also has a distribution.\nWe don't talk about \"frequency\" but belief assigned to particular value : </p>\n<ul>\n<li>If the coin has a 0.5 probability of being Head, it means that we have a 50% belief that the coin will end up on heads</li>\n<li>We can say that the probability that $p=0.5$ is 0.8, it means that we have an 80% belief that our coin is fair.</li>\n</ul>\n<p>A goal is to derive the distribution of parameters (here, $p$), conditional on the data (here, $X$). This is called the [[Posterior Distribution]]. This allows the postulate of ![[Bayes' Theorem]]</p>\n<p>Bayes's rule provides a recipe for specifying the belief about a parameter based on available evidence.</p>","Words":"Bayesian Statistics"},{"Category":"Mathematics","Definition":"<p>The [[Posterior Distribution]] $f(p|X)$ can be written as : $$f(p|X) = \\frac{f(p) f(X|p)}{f(X)}$$\nwhere $f(p)$ is the [[Prior Distribution]]</p>","Words":"Bayes' Theorem"},{"Category":"Mathematics","Definition":"<p>Assume $G$ acts on spaces $X$ and $Y$.</p>\n<p>$F: X \\leftarrow Y$ is <strong>invariant if</strong> $F(g \\cdot x) = F(x)$</p>\n<p>![[Pasted image 20211208140337.png]]</p>\n<p>An exemple : \nin this neuron addition, because there is an addition, the function is invariant to $x<em>1$ and $x</em>2$.</p>\n<p>![[Pasted image 20211208140553.png]]</p>\n<p>Invariance is a form of [[Equivariant]] : </p>\n<h2 id=\"equivariantmap\">Equivariant Map</h2>\n<p>Define the <em>trivial</em> action on $Y$ by $g \\cdot y = y$ for all symmetries $g$. Then an equivariant map satisfies \n$$F(g \\cdot x) = g \\cdot F(x) = F(x)$$</p>\n<h2 id=\"groupaveraging\">Group Averaging</h2>\n<p>For any function $F:X \\leftarrow Y$, the following function is invariant</p>\n<p>$$ H<em>F(x) = \\frac{1}{#G \\sum</em>{g \\in G}{F(g \\cdot x)}}$$</p>\n<p>The map $F \\leftarrow H_F$ is a projection.</p>\n<p>Exemple : \nTake all possible transformations applied to the input photo and take all features spaces that they produces. \nWe can then take an average of all the features and that is the group average.</p>\n<p>![[Pasted image 20211208142540.png]]</p>","Words":"Invariant"},{"Category":"Mathematics","Definition":"<p>A form of proof in which one imagines listing a [[Set]] of entities, and then uses the list to construct a related entity that cannot be on the list.</p>","Words":"Diagonal Argument"},{"Category":"Mathematics","Definition":"<p>A Lebesgue-integrable #Function  $f : \\mathbb{R}^n → \\mathbb{R}$ is a measurable if satisfying  </p>\n<p>$$\n\\int_{\\mathbb{R}^n} |f(x)| \\mathop{dx} &lt; ∞\n$$\nwhich contains continuous functions, including functions such as the $sgn$ function.</p>\n<p>[[Lebesgue]] [[Integral]]</p>","Words":"Lebesgue Functions"},{"Category":"Mathematics","Definition":"<p>Assume $G$ acts on spaces $X$ and $Y$.</p>\n<p>$F: X \\leftarrow Y$ is <strong>equivariant if</strong> $F(g \\cdot x) = g \\cdot F(x)$</p>\n<p>![[Pasted image 20211208140303.png]]</p>\n<p>Equivariance is a form of [[Invariant]].</p>\n<h2 id=\"equivariantmap\">Equivariant map</h2>\n<p>Let $Z$ be the set of maps $Z = {F: X -&gt; Y}$\nDefine an action on $Z$ by $(g.F)(x) = g.F(g^{-1}.x)$</p>\n<p>A map $F$ that is invariant under this action (that is $g.F = F$) is an equivariant map.</p>\n<h2 id=\"groupaveraging\">Group averaging</h2>\n<p>Assume $X$ and $Y$ are vector spaces. </p>\n<p>For any functions $F:X \\leftarrow Y$, the following funciton is equivariant </p>\n<p>$$K<em>F(x) = \\frac{1}{#G \\sum</em>{g \\in G}{gF(g^{-1}.x)}}$$</p>","Words":"Equivariant"},{"Category":"Mathematics","Definition":"<p>Objects which : </p>\n<ul>\n<li>Can be composed</li>\n<li>Can be inverted</li>\n<li>presever \"something\"</li>\n</ul>\n<p>Anything left unchanged after a transformation. Symmetries transform something. \n=&gt; Needs a <strong>space of symmetries</strong> and a <strong>space of objects</strong> being transformed</p>\n<p><strong>Properties definition</strong> : \nA <strong>group G acts</strong> a on a space $X$ if for every $g$ in $G$, there is a transformation </p>\n<ul>\n<li>$$X \\rightarrow X$$</li>\n<li>$$x \\rightarrow g \\cdot x$$</li>\n</ul>\n<p>such that $(g<em>2g</em>1)\\cdot x=g<em>2\\cdot (g</em>1 \\cdot x)$</p>\n<p>Transformations action can be <strong>Discrete</strong> or <strong>Continuous</strong>.</p>\n<p><strong>Discrete transformations</strong></p>\n<ul>\n<li>Discrete translations acting on $Z^n$</li>\n<li>Permutations acting on a set.</li>\n<li>Isomorphisms of a graph.</li>\n<li>Transformations of a rubik's cube</li>\n</ul>\n<p><strong>Continuous transformations</strong></p>\n<ul>\n<li>Translations actions on $R^n$</li>\n<li>$SL(n)$ acting on $R^n</li>\n<li>Rotating in any dimensions</li>\n<li>Angle preserving tranformations on a sphere.</li>\n</ul>","Words":"Symmetries"},{"Category":"Mathematics","Definition":"<p>A set of invertible transformations which can be composed such that </p>\n<ul>\n<li>$$ g<em>3(g</em>2g<em>1) = (g</em>3g<em>2)g</em>1$$</li>\n<li>$$ ge = eg = g$$</li>\n<li>$$ gg^{-1} = g^{-1}g = e$$</li>\n</ul>\n<p>Group actions must <strong>transform</strong> something and <strong>preserve</strong> something</p>\n<ul>\n<li>Distances<ul>\n<li>Translation in space conserves distances between objects</li></ul></li>\n<li>Meaning<ul>\n<li>Translate wrods between two languages</li></ul></li>\n<li>Identity or Style<ul>\n<li>Using the sytle of an artist to convert photos or paintings</li></ul></li>\n</ul>","Words":"Symmetry Group"},{"Category":"Mathematics","Definition":"<p>Probability that an event or a sequence of event happens given a probability $p$ for the event.</p>\n<p>For an event with probability $p<em>{\\text{event}}$ that happens $n</em>{h}$ times and doesn't happens $n_t$ times :</p>\n<p>$$L = P(\\text{event}|p<em>{\\text{event}}) = (p</em>{\\text{event}})^{n<em>{\\text{h}}}(1-p</em>{\\text{event}})^{n<em>{\\text{t}}}$$\nTo optimize, take the logarithm of the function to create additions which are much easier to optimize. A logarithmic transformation also keeps the optimum, at the same parameter value : $$\\log L = n</em>H \\log p + n_T \\log(1-p)$$</p>","Words":"Likelihood"},{"Category":"Neuroscience","Definition":"<p>Large [[Motor Neuron]] that sends [[Motor Information]] that has ascended from the [[Axon]].</p>\n<p>8th part of the [[Direct Motor Pathway]].</p>","Words":"Alpha Motor Neuron"},{"Category":"Neuroscience","Definition":"<p><strong>A</strong>rriving #Information. \n[[Neuron]]al projections <strong>to</strong> … </p>\n<p>Opposite of [[Efferent]]</p>","Words":"Afferent"},{"Category":"Neuroscience","Definition":"<p>Opposite order-preference fron [[Hebbian STDP]], with pre-leading-post spike order driving LTD, and post-ealding-pre spiking diving LTP</p>\n<ul>\n<li>Occurs at [[Excitatory synapse]] onto medium spiny neurons and cholinergic interneurons in striatum, and onto #L5<em>pyramids in #somatosensory</em>cortex in response to spike bursts. </li>\n<li>At most [[Synapse]], however [[STPD]] contains <strong>only</strong> the LTD component, and referred to simply as [[Anti-Hebbian LTD] ](Han et al 2000)</li>\n</ul>\n<p>[[Long-term Depression (LTD)]][[Long-term Potentation (LTP)]] </p>","Words":"Anti-Hebbian STDP"},{"Category":"Neuroscience","Definition":"<p>An approximation of the \"distance\" between the observed data and the data predicted by the model. Measures the complexity and the fit of a [[Model]] by adding two times the number of parameters to $-2 \\times \\log \\text{-likelihood}$  : $$\\text{AIC} = -2\\log L + 2K$$</p>\n<p>The [[Likelihood]] term is calulated using the maximum-likelihood parameters.</p>\n<ul>\n<li>Fit term : $-2\\log L$</li>\n<li>Complexity term : $2K$</li>\n</ul>","Words":"Akaike's Information Criterion (AIC)"},{"Category":"Neuroscience","Definition":"<p>Area part of the [[Cerebral Cortex]], so old that it does <strong>not</strong> have layers but consists of roughly two clusters of nuclei.\nIt's surface is called the <strong>uncus</strong>. </p>\n<p>Means \"<em>Almond</em>\" because of its shape</p>\n<h2 id=\"function\">Function</h2>\n<ul>\n<li>General [[Limbic System]] emotions and behaviors : <ul>\n<li>Fear</li>\n<li>Anger</li>\n<li>Arousal</li>\n<li>Reactions to the environment</li></ul></li>\n<li>Upon stimulation : Fear and Rage</li>\n<li>Related to [[Post traumatic Stress Disorder (PTSD)]]</li>\n</ul>\n<h2 id=\"region\">Region</h2>\n<h3 id=\"corticomedialgroup\">Corticomedial group</h3>\n<p>Primarily related to : </p>\n<ul>\n<li>[[Olfactory Bulb]]</li>\n<li>[[Visceral]] nuclei of [[Brain Stem]]</li>\n<li>[[Hypothalamus]]</li>\n</ul>\n<p>May mediate autonomic responses to frightening stimuli</p>\n<h3 id=\"basolateralgroup\">Basolateral group</h3>\n<p>Primarly related to : </p>\n<ul>\n<li>[[Thalamus]]</li>\n<li>[[Prefrontal Cortex]]</li>\n</ul>\n<p>Helps recognize danger</p>\n<h2 id=\"connections\">Connections</h2>\n<h3 id=\"afferent\">[[Afferent]]</h3>\n<ul>\n<li>[[Primary Sensory Cortex]]<ul>\n<li>Espacially olfactory</li></ul></li>\n<li>[[Forebrain]]</li>\n<li>[[Frontal Lobe]]</li>\n</ul>\n<h3 id=\"efferent\">[[Efferent]]</h3>\n<ul>\n<li>[[Hypothalamus]] (regulation of autonomics)</li>\n<li>[[Brain Stem]] </li>\n<li>[[Cerebral Cortex]]</li>\n<li>[[Hippocampal Formation]]<ul>\n<li>The amygdala is really close to the hippocampus</li></ul></li>\n</ul>\n<p>![[Amygdala Zone.png]]\n![[Amydgala.png]]</p>","Words":"Amygdala"},{"Category":"Neuroscience","Definition":"<p>Takes the input of a unit, and if the excitation is enough, the unit is 'activated'/excited passing the signal to the next unit.\nFunction usually taking the weights and inputs, ruled by threshold limits.</p>\n<p>Some popular examples : </p>\n<ul>\n<li>[[Logistic function]]</li>\n<li>[[ReLU]]</li>\n<li>[[Sigmoid function]]</li>\n</ul>","Words":"Activation function"},{"Category":"Neuroscience","Definition":"<p>Connects areas of the [[Brain]] to areas of the [[Brain]] within the same hemisphere.</p>\n<p>They can be :</p>\n<ul>\n<li><strong>Long</strong><ul>\n<li>Examples : <ul>\n<li>Connect [[Frontal Lobe]] to [[Occipital Lobe]] : [[Superior longitudinal fasciculus]]</li>\n<li>Connections within [[Limbic Lobe]] : [[Cingulum]]</li></ul></li></ul></li>\n<li><strong>Short</strong><ul>\n<li>Examples<ul>\n<li>Gyrus to Gyrus</li></ul></li></ul></li>\n</ul>","Words":"Association Fibers"},{"Category":"Neuroscience","Definition":"<p>Where different modalities come together. Merging of the regions of the [[Cerebral Cortex]].</p>\n<p>![[Brodmann's map - Association Cortex.png]]</p>","Words":"Association Cortex"},{"Category":"Neuroscience","Definition":"<p>Middle layer of the [[Meninges]].</p>\n<p>It provides a pathway and support for the incoming arteries and outgoing veins.</p>\n<p>A bit spongy, kinda of like a web (hence the name).\nThe top part is adherent to the [[Dura Mater]] and the inner layer is stuck to the [[Pia Mater]].</p>\n<p>The space between the Arachnoid Mater and the Pia Mater is called the [[Subarachnoid Space]], filled with <em>trabeculae</em>, filled of [[Cerebrospinal fluid (CSF)]].</p>\n<p>![[Arachnoid Mater.png]]</p>\n<p>![[Arachnoid Mater - 3D.png]]</p>\n<p>The Arachnoid Granulations represents areas that pushes into the dural sinus, allowing [[Cerebrospinal fluid (CSF)]] to go from the [[Subarachnoid Space]] back into the venous circulation and then drain.</p>\n<p>![[Subarachnoid Mater - Spinal Fluid.png]]</p>","Words":"Arachnoid Mater"},{"Category":"Neuroscience","Definition":"<p>The autonomic Nervous System is also the <strong>automatic</strong> nervous system.</p>\n<p>[[Afferent]] and [[Efferent]] systems that refulate [[Motor Innervation]] of <strong>smooth muscle and glands and [[Sensory Information]] from the internal environment</strong>.</p>\n<h2 id=\"elements\">Elements</h2>\n<p>Two [[Neuron]] Chain</p>\n<ul>\n<li>Preganglionic neuron in the [[Central Nervous System (CNS)]]</li>\n<li>The other chain has 3 scenarios : <ul>\n<li>Ganglionic neuron in the sympathetic chain </li>\n<li>Ganglia associated with a cranial nerve </li>\n<li>Ganglia associated with the target organ</li></ul></li>\n</ul>\n<p>![[Autonomic Nervous System - Two Neuron Chain.png]]</p>\n<h2 id=\"composition\">Composition</h2>\n<ul>\n<li>[[Parasympathetic Nervous System]]<ul>\n<li>\"Rest and Digest\"</li></ul></li>\n<li>[[Sympathetic Nervous System]]<ul>\n<li>\"Fight or Flight\"</li></ul></li>\n</ul>\n<p>-&gt; There is an ongoing balance between the two</p>","Words":"Autonomic Nervous System"},{"Category":"Neuroscience","Definition":"<p>Also known as [[Basal Ganglia]]. \nA group of [[Neuron]] within the [[Central Nervous System (CNS)]] that functions together with : </p>\n<ul>\n<li>common targets</li>\n<li>common inputs</li>\n<li>common [[Neurotransmitter]]</li>\n</ul>\n<p>They are the basis of [[Habits]].</p>\n<h2 id=\"sections\">Sections</h2>\n<p>In the [[Brain]] section [[Striatum]]</p>\n<ul>\n<li>[[Caudate]]</li>\n<li>[[Putamen]]</li>\n</ul>\n<p>In the [[Brain]] section [[Pallidum]]</p>\n<ul>\n<li>[[Globus Pallidus]]<ul>\n<li>internal segment</li>\n<li>external segment</li></ul></li>\n</ul>\n<p>In the [[Brain]] section [[Brain Stem]]</p>\n<ul>\n<li>[[Substantia Nigra]]</li>\n</ul>\n<p>In the [[Brain]] section [[Diencephalon]]</p>\n<ul>\n<li>[[Subthalamic Nucleus]]</li>\n</ul>\n<p>![[Basal Nuclei - Sections (1).png]]</p>\n<p>![[Basal Nuclei - Sections (2).png]]</p>\n<p>![[Basal Nuclei - Sections (3).png]]</p>\n<h2 id=\"circuitry\">Circuitry</h2>\n<p>Very complex !</p>\n<p>![[Basal Nuclei - Circuitry (1).png]]</p>\n<ul>\n<li>Direct pathway<ul>\n<li><strong>Facilitates</strong> appropriate motor program<ul>\n<li>Ex : If i have a problem in my direct pathway, i may have trouble initiating motor habits such as walking</li></ul></li></ul></li>\n<li>Indirect pathway <ul>\n<li><strong>Inhibits</strong> competing/unwanted motor programs<ul>\n<li>Ex : If I have a problem in my indirect pathway, I may have unwanted motions like a tremor.</li></ul></li></ul></li>\n</ul>","Words":"Basal Nuclei"},{"Category":"Neuroscience","Definition":"<p>A [[Model]] for [[Short-term Memory]] proposing that items are associated to each pther (as in a chain: A -&gt; B -&gt; C -&gt; …). \nHoweven, the concept of the chain predicts that if one item is not recalled, none of the subsequent will be either.</p>\n<p>By itself this prediction is not consistent with emprical data, but [[Context-based Models]] representation elegantly remedies this problem.</p>","Words":"Associative-Chain Model"},{"Category":"Neuroscience","Definition":"<p>A flexible algorithm for training multilayer [[Neural Network]]. Its goal consists of minimizing an error function at the output layer.\nIt is used in [[Cognitive Neuroscience]] (as a model of the [[Brain]]) and in [[Artificial Intelligence]] (for solving various tasks) and forms an active area of research in both fields.</p>\n<p>Some drawbacks : </p>\n<ul>\n<li>[[Local Minima]]</li>\n<li>[[Catastrophic Interference]]</li>\n<li>[[Vanishing and Exploding Gradient Problem]]</li>\n</ul>","Words":"Backpropagation"},{"Category":"Neuroscience","Definition":"<p>[[Model]]s of perception where the visual system chooses <strong>the most likely</strong> interpretation of its surrounding visual world.</p>\n<p>Subjects combine prior information with data, depending on the amount of uncertainty in each.</p>","Words":"Bayesian Perception"},{"Category":"Neuroscience","Definition":"<p>Criterion where specific parameter value is not important, more used to know the average fit of the model averaged across all possible parameter values.\nThe average [[Likelihood]] approach will average both the good and the bad likelihoods, thus punishing the model for predicting a bad fit at other parameter values. $$\\text{BIC} = -2\\log L + K \\log N$$\nwhere $N$ is the number of data points used for estimating the parameters, and the likelihood is calculated as for [[Akaike's Information Criterion (AIC)]], using the maximum-likelihood parameters.</p>\n<ul>\n<li>Fit term : $-2\\log L$</li>\n<li>Complexity term : $K \\log N$</li>\n</ul>","Words":"Bayesian Information Creterion (BIC)"},{"Category":"Neuroscience","Definition":"<p>Consider the case where a parameter $\\theta$ represents a state of the world and leads to an observed variable $X$. The parameter $\\theta$ could represent real-world angle between two lines; the variable $X$ could represent the angle between the two lines as projected on my retina. </p>\n<p>I only observe $X$ but I want to infer the value of $\\theta$.\nWe can create the posterior distribution of $\\theta$ as $$\\text{Posterior}(\\theta | X) \\propto f(\\theta | X) f(\\theta) = f(\\theta, X)$$\nWhere $f(\\theta, X)$ is called the <em>joint probability</em> for the parameter $\\theta$ and the data $X$. </p>\n<p>To find the most likely value of $\\theta$, we can perform [[Gradient Ascent]] on the log of this joint probability $$\\Delta \\theta = \\alpha \\frac{\\partial}{\\partial \\theta} \\log ( f(\\theta, X))$$\nOten, the distribution $f(\\theta, X)$ has parameters itself that we can annotate $\\xi$  changin to its full form being $f(\\theta, X; \\xi)$.\nChanging the parameters $\\xi$ would be considered [[Learning]] in a Bayesian framework, involving an adaptation to one's cognitive apparatus based on environmental input.</p>\n<p>How to find the best parameters $\\xi$ ? Re-apply [[Gradient Ascent]] on the log of the joint probability $$\\Delta \\xi = \\alpha \\frac{\\partial}{\\partial \\xi} \\log (f(\\theta, X; \\xi))$$\nThe panel $c)$ shows on the left a plot of a joint distribution as a function of $\\theta$. The right panel of the same figure shows the same joint density, but as a function of $\\xi$. \n![[Slide61.jpeg]]</p>","Words":"Bayesian Brain Hypothesis"},{"Category":"Neuroscience","Definition":"<p>\"How do we infer the beliefs of other people? How does an obersever infer what another agent finds rewarding or costly?\"</p>\n<p>Recent Bayesian model of social cognition postulates that social observers interpret the behavior of other agents by assuming that those observed agents optimize value.</p>\n<p>Observers would infer the most likely reward ($R$) and cost ($C$) structures based on the observations done on a particular subject. The observers sees the agent's actions and then infers what the agents most likely consider to be rewarding or costly, given the observations. The calculation would be the following posterior probability $$\\Pr (R, C | \\text{Actions}) \\propto \\Pr(\\text{Actions} | R, C) \\Pr(R, C)$$\nThis allows to find the values $R$ and $C$ that miximizes the posterior and thus infer what the other agents find rewarding and costly.\nThe probability $\\Pr(\\text{Actions}| R, C)$ can be calculated by intergrating over all posible policies $\\pi$. </p>","Words":"Bayesian Social Cognition"},{"Category":"Neuroscience","Definition":"<p>\"How to decide between multiple input, and how do we decide where to give our attention?\"</p>\n<p>If there is $N$ sources to pay attention to, Yu and Dayan (2005) proposed that at trial $t$, an agent may consider the posterior belief that source $j$ is the relevant source, together with the belief about current vlaue of $\\eta$ given all data thus far.</p>\n<p>This posterior probability can be written as $$\\Pr ( \\text{cue } j \\text{ relevant at trial }t, \\eta_t | \\text{Data})$$\nThis probability allows for optimal allocation of attention: Simply pay attention to the cue that maximizes the equation.</p>\n<p>This calculation can be simplified with some assumptions : </p>\n<ul>\n<li>Subjects may consider a singlu cue as being relevant (instead of tracking multiple)<ul>\n<li>The validity of the considered cue is $\\eta_t$ </li>\n<li>$1 - \\eta_t$ is the unreliability also called <em>expected uncertainty</em> (EU)\n-&gt; if $\\eta$ is low, then EU is high which means that there is a lot of noise.</li></ul></li>\n<li>Subjects may keep track of their confidence that cue $j$ is the relevant one with a parameter called $\\gamma_t$<ul>\n<li>The parameter $1-\\gamma_t$ is labeled the <em>unexpected uncertainty</em> (UU)</li></ul></li>\n</ul>\n<p>To allow the model to make discrete switches between differnet cues, an agent must assume that the relecant cue has changed whenever $$UU &gt; \\frac{EU}{1/2 + EU}$$\nAt a Neurobiological level, the authors proposed that EU and UU were signaled by two [[Neuromodulator]]s : </p>\n<ul>\n<li>EU by #Acetylcholine, originating from the [[Basal Nuclei]] in the [[Forebrain]]</li>\n<li>UU by #Noradrenaline, originating from [[Locus Coeruleus]]</li>\n</ul>","Words":"Bayesian Attention"},{"Category":"Neuroscience","Definition":"<p>Helps the [[Brain]] protect from all kind of foreign substance and chemicals.</p>\n<p>![[Blood Brain Barrier.png]]</p>\n<h2 id=\"sections\">Sections</h2>\n<h3 id=\"peripheralcapillary\">Peripheral Capillary</h3>\n<p>Things can come and go out of the peripheral capillary, there are pores (little gates) and gateways that allow elements to pass.</p>\n<p>In the [[Brain]], capillaries are joined by tight junctions and so nothing is getting through this membrane.</p>\n<p>Some stuff gets in : </p>\n<ul>\n<li>Glucose </li>\n<li>Alcohol</li>\n</ul>\n<p>But most of it doesn't : </p>\n<ul>\n<li>Antibiotics</li>\n<li>Most drugs<ul>\n<li>It is actually very hard to design a drug that crosses the blood brain barrier. </li></ul></li>\n</ul>","Words":"Blood Brain Barrier"},{"Category":"Neuroscience","Definition":"<p>\"How rationally, subjects can judge and object as having value $c$ on feature $j$, depending on all data seen thus far.\"</p>\n<p>Anerson's algorithm does not explore all possibilities from previous data, but creates subclass and assigns information to those class to greatly reduce the space of exploration ([[Curse of Dimensionality]]).</p>","Words":"Bayesian Categorization"},{"Category":"Neuroscience","Definition":"<p>A [[Recurrent Neural Network (RNN)]] [[Model]] where the main goal is to autocomplete a pattern based on an incomplete version of that pattern.</p>\n<p>Learning problems are formulated in a probabilistic framwork. \nAn environment consisting of different states are each characterized by a vector $\\textbf{x} = (x<em>1, …, x</em>I)$. </p>\n<blockquote>\n  <p>E.g. \"A Fluffy, non aggressive cat\" where the states are $x<em>1 = \\text{fluffy}$, $x</em>2 = \\text{aggresive}$ and $x_3 = \\text{dog}$, would be represented as $(1, 0, 0)$. </p>\n</blockquote>\n<p>The statistical distribution across al possible states is denoted $\\Pr(\\textbf{X} = \\textbf{x})$ or $\\Pr(\\textbf{x})$. The machine defines an explicit statistical distribution of the network $\\Pr<em>w(\\textbf{x})$, where $w$ indicates that the probability depends on parameters $w</em>{ij}$. \nThe goal of the model is to tune the weights to make $\\Pr_w(\\textbf{x})$ as close as possible to $\\Pr(\\textbf{x})$. </p>\n<p>The probability that the models finds itself in state $\\textbf{x} = (x<em>1, …, x</em>I)$ is the ![[Boltzmann Distribution]] </p>\n<p>The systems attemps to minimize it's energy, where high probability assign low energy states.</p>\n<p>If we observe $\\textbf{x}$ with probability $\\Pr (\\textbf{x})$, the desired probability $\\Pr<em>w (\\textbf{x})$ generated by the model should be as close as possible to $\\Pr (\\textbf{x})$. To measure how close, we can use the [[Cross Entropy]] error function and try to maximize it : $$\\log L = \\sum</em>x \\Pr (\\textbf{x}) \\log ( \\Pr<em>w (\\textbf{x}))$$\nThe update rule in order to implement [[Gradient Ascent]] is : $$\\Delta w</em>{ij} = \\beta (p(i,j) - p_w(i,j))$$\nwith : </p>\n<ul>\n<li>$\\beta$ is a learning rate, absrobing the temperature $T$;</li>\n<li>$p(i,j)$ is the observed environmental probability that units $i$ and $j$ both take on the value of 1</li>\n<li>$p_w(i,j)$ is the model-based probability that both units $i$ and $j$ take on the value of 1</li>\n</ul>","Words":"Boltzmann Machines"},{"Category":"Neuroscience","Definition":"<p>$$\\Pr<em>w(\\textbf{X} = \\textbf{x}) = \\frac{\\exp ( - \\frac{1}{T} (- \\sum</em>j \\sum<em>{i<j} w</em>{ij} x<em>i x</em>j)}{Z}$$</p>\n<p>where : </p>\n<ul>\n<li>$T$ is a temperature parameter, with $T &gt; 0$, which is the inverse of $\\gamma$. ($T = \\frac{1}{\\gamma}$)</li>\n<li>weights $w_{ij}$ connects units $i$ and $j$.</li>\n<li>$Z$ is a normalization term to make sure the summation across all possible patterns equals 1.</li>\n<li>The term $-\\sum<em>j \\sum</em>{i&lt;j} w<em>{ij} x</em>i x_j$ can be defined as the <em>energy</em> of the system/machine/model.</li>\n</ul>","Words":"Boltzmann Distribution"},{"Category":"Neuroscience","Definition":"<p>Systematic Deviation from structure underlying data, low model complexity.</p>","Words":"Bias"},{"Category":"Neuroscience","Definition":"<p>A complex network of [[Plexuses Nerves]] that innervates the upper extremity (arms and shoulders)</p>\n<p>Provides : </p>\n<ul>\n<li>[[Sensory Innervation]] and [[Motor Innervation]] to the upper extremity. </li>\n</ul>\n<p>![[Brachichal Plexus - Peripheral.png]]</p>\n<p>The different colors represent different parts of the nerves : </p>\n<p>![[Brachical Plexus - In Situ.png]]</p>","Words":"Brachical Plexus"},{"Category":"Neuroscience","Definition":"<p>![[Brain Sections.png]]</p>","Words":"Brain Sections"},{"Category":"Neuroscience","Definition":"<p>Transition [[Brain]] area between the [[Spinal Cord (SC)]] and the [[Cerebral Cortex]].</p>\n<p>The Brain Stem is a transitional area, [[White Matter]] and [[Gray Matter]] are mixing in some regions with cell bodies and it isn't as simple as \"white on top of gray\" or the inverse.\n=&gt; In the brain, the [[Gray Matter]] is on the outside and the [[White Matter]] inside, and it is inversed in the [[Spinal Cord (SC)]], the Brain Stem <strong>does the transition</strong>.</p>\n<p>Home of the [[Reticular Formation]].</p>\n<p>![[Brain Stem - Region.png]]</p>\n<h2 id=\"regions\">Regions</h2>\n<ul>\n<li>[[Medulla Oblongata]]</li>\n<li>[[Pons]]</li>\n<li>[[Midbrain]]</li>\n</ul>\n<p>![[Brain Stem - Regions.png]]</p>","Words":"Brain Stem"},{"Category":"Neuroscience","Definition":"<p>Metaphor which suggetss that the brain works like a computer. </p>\n<p>Example : \nThe [[Brain]] takes senses and perceptions as an input and outputs a [[Behavior]].</p>","Words":"Brain-Computer Metaphor"},{"Category":"Neuroscience","Definition":"<h2 id=\"grossanatomy\">Gross Anatomy</h2>\n<p>![[Brain Gross Anatomy.png]]</p>\n<p>Note : </p>\n<ul>\n<li><em>Caudal</em> means \"<em>tail</em>\".</li>\n<li><em>Dorsal</em> here is <strong>up</strong> and <em>Ventral</em> is <strong>down</strong><ul>\n<li>\"Towards the Ventre\"</li></ul></li>\n</ul>\n<h3 id=\"importantlandmarks\">Important Landmarks</h3>\n<p>![[Brain Important Landmarks.png]]</p>\n<h4 id=\"frontalandtemporallobe\">Frontal and Temporal Lobe</h4>\n<p>The Frontal lobe and the Temporal Lobe is seperated with the <strong>lateral fissure</strong></p>\n<p>![[Brain Lateral Fissure.png]]</p>\n<h4 id=\"precentralandpostcentralgyri\">Precentral and Postcentral Gyri</h4>\n<p>The [[Central Sulcus]] seperates the the [[Precentral Gyrus]] from the [[Postcentral Gyrus]]. Those two giri are important when talking about the [[Primary Motor System]] and [[Primary Sensory Systems]].</p>\n<p>[[Postcentral Gyrus]] -&gt; Movement control and Motor system\n[[Precentral Gyrus]] -&gt; Where the mosquito bite you and Sensory System</p>\n<p>![[Brain Precentral and Postcentral Gyrus.png]]</p>\n<h4 id=\"parietalandoccipitallobe\">Parietal and Occipital lobe</h4>\n<p>[[Parietal Lobe]] and [[Occipital Lobe]]. \nNo clear landmark to between parietal and occipital lobe but there is a clearer landmark on the lateral surface.</p>\n<p>![[Brain Parietal and Occipital Lobe.png]]</p>\n<h4 id=\"gyrus\">Gyrus</h4>\n<p>The surface of the brain is is thrown in a bunch of folds. \nThe bumps are called [[Gyri]] and the folds in between them are called [[Suici]].</p>\n<p>The reason it appears is that our brain is too big for our head and the only way to fit your brain inside was to fold it up.</p>\n<h4 id=\"preoccipitalnotch\">Preoccipital Notch</h4>\n<p>The boundary between the [[Temporal Lobe]] and the [[Occipital Lobe]]</p>\n<p>![[Brain Preoccipital Notch.png]]</p>\n<h4 id=\"superiorlongitudinalsulcus\">Superior Longitudinal Sulcus</h4>\n<p>Separates the [[Occipital Lobe]] from the [[Frontal Lobe]]</p>\n<p>a.k.a -&gt; Longitudinal Fissure</p>\n<p>![[Brain Superior Longitudinal Sulcus.png]]</p>\n<h4 id=\"lobes\">Lobes</h4>\n<p>4 Lobes accessible from the outside of the brain : </p>\n<ul>\n<li>[[Parietal Lobe]]</li>\n<li>[[Frontal Lobe]]</li>\n<li>[[Temporal Lobe]]</li>\n<li>[[Occipital Lobe]]</li>\n</ul>\n<p>![[Brain Exterior Lobes.png]]</p>\n<p>2 inner lobes burried inside</p>\n<ul>\n<li>[[Insula Lobe]] (aka Island Lobe)</li>\n</ul>\n<p>![[Brain Inner Lobes.png]]</p>\n<ul>\n<li>[[Limbic Lobe]] visible after removing the [[Brain Stem]] and the [[Cerebellum]]. <ul>\n<li>In Latin <em>Limbic</em> means \"Circle\" which is kind of the shape of this lobe hence the name.</li>\n<li>The [[Paraphippocampal Gyrus]] combined with the [[Cingulate Gyrus]] forms the [[Limbic Lobe]].</li></ul></li>\n</ul>\n<p>![[Limbic Lobe.png]]</p>\n<h3 id=\"mediallandmarks\">Medial Landmarks</h3>\n<p>Many parts of the brain are visible from the medial view.</p>\n<ul>\n<li>The [[Paracentral Lobe]] is a zone where the [[Precentral Gyrus]] and [[Postcentral Gyrus]] kinda come together</li>\n<li>The [[Parietooccipital Sulcus]] is a clear landmark separating the [[Parietal Lobe]] and [[Occipital Lobe]]</li>\n<li>The [[Corpus Callosum]] is a big [[White Matter]] fiber [[Tract]] that conducts all of the [[Neuron]] from one hemisphere to the other.</li>\n<li>The [[Diencephalon]] is strongly linked to the [[Autonomic Nervous System]] and the [[Primary Sensory Systems]]. It is [[Grey matter]] deep within the brain. It's a very old part of the brain. It's kinda continuous with the [[Brain Stem]].</li>\n</ul>\n<p>![[Medial Brain Cut Landmarks.png]]</p>","Words":"Brain"},{"Category":"Neuroscience","Definition":"<p>5 types of [[Brain]] waves : </p>\n<ul>\n<li>[[Gamma Band]]<ul>\n<li>40 Hz to 100 Hz (Highest)</li></ul></li>\n<li>[[Beta Band]]<ul>\n<li>12 Hz to 40 Hz (High)</li></ul></li>\n<li>[[Alpha Band]]<ul>\n<li>8 Hz to 12 Hz (Moderate)</li></ul></li>\n<li>[[Theta Band]]<ul>\n<li>4 Hz to 8 Hz (Slow)</li></ul></li>\n<li>[[Delta Band]]<ul>\n<li>0 Hz to 4 Hz (Slowest)</li></ul></li>\n</ul>","Words":"Brain Waves Frequencies"},{"Category":"Neuroscience","Definition":"<p>A [[Model]] where [[Agent]] sample data from their world in order to construct a [[Posterior Distribution]] belief about parameters that generated those #data. \nAs a next step, based on those posteriors, one can choose an action that minimizes a [[Loss function]].</p>","Words":"Bayesian Model"},{"Category":"Neuroscience","Definition":"<p>Special [[Visceral]] [[Efferent]]. \nDesignation based on developmental pattern of pharyngeal muscle.</p>","Words":"Branchial Motor"},{"Category":"Neuroscience","Definition":"<blockquote>\n  <p>\"The cellular structure of the brain reflects what it does.\"</p>\n</blockquote>\n<p>Map of the regions of the [[Cerebral Cortex]].</p>\n<p>![[Brodmann's map.png]]</p>\n<h2 id=\"regions\">Regions</h2>\n<p>![[Brodmann's map - regions.png]]</p>","Words":"Brodmann's map"},{"Category":"Neuroscience","Definition":"<p>[[Visceral]] [[Sensory Innervation]] organs that measure blood pressure and CO2 concentration. \nThis information then goes back to the [[Brain Stem]] by the [[IX Glossopharyngeal]] [[Nerves]].</p>","Words":"Carotid Sinus"},{"Category":"Neuroscience","Definition":"<p>[[Visceral]] [[Sensory Innervation]] organs that measure blood pressure and CO2 concentration. \nThis information then goes back to the [[Brain Stem]] by the [[IX Glossopharyngeal]] [[Nerves]].</p>","Words":"Carotid Body"},{"Category":"Neuroscience","Definition":"<p>[[Brain]] and [[Spinal Cord (SC)]].</p>\n<h2 id=\"grossanatomy\">Gross Anatomy</h2>\n<ul>\n<li>[[Brain]]<ul>\n<li>[[Brain Stem]]</li>\n<li>[[Cerebellum]]</li></ul></li>\n<li>[[Spinal Cord (SC)]]<ul>\n<li>Ventral</li>\n<li>Dorsal</li></ul></li>\n</ul>\n<p>![[CSN Gross Anatomy.png]]</p>","Words":"Central Nervous System (CNS)"},{"Category":"Neuroscience","Definition":"<p>A [[Memory]] and [[Hebbian Learning]] [[Model]] where both [[Short-term Memory]] and [[Long-term Memory]]are formed but short-terms weigths develop and decay much more quickly than long-term weigths. (Even if saying \"there is short and long term\" is a bit easy).</p>","Words":"Burgess and Hitch Model"},{"Category":"Neuroscience","Definition":"<p>Located at the back of the [[Brain]], easily distinguishable from the rest of the brain because it is a element by itself, sitting underneath the [[Occipital Lobe]].</p>\n<ul>\n<li>About 10% of the brain's mass.</li>\n<li>Contains about 50% of the brain's [[Neuron]]</li>\n<li>Forms  the roof the 4th [[Ventricles]]</li>\n</ul>\n<blockquote>\n  <p>Means \"<em>Little Brain</em>\".</p>\n</blockquote>\n<h2 id=\"functions\">Functions</h2>\n<p>Really important for [[Motor Behavior]] ! </p>\n<ul>\n<li>It compares the intended behavior with what's actually happening <ul>\n<li>Helps adjust</li>\n<li>Input from [[Brain Stem]] and [[Spinal Cord (SC)]]</li>\n<li>output back to the [[Motor Cortex]]</li></ul></li>\n<li>Associated with balance<ul>\n<li>Input form the [[Brain Stem]] (middle ear) and [[Spinal Cord (SC)]]</li>\n-</ul></li>\n<li>Muscle tone and Synergie<ul>\n<li>\"how much muscle and energy needed for use\"</li>\n<li>Input form [[Spinal Cord (SC)]]</li>\n<li>Output back to [[Motor Cortex]]</li></ul></li>\n</ul>\n<h2 id=\"anatomy\">Anatomy</h2>\n<ul>\n<li>2 cerebellaer hemispheres<ul>\n<li>right hemispheres</li>\n<li>left hemispheres</li></ul></li>\n<li>For each hemispheres, 2 lobes separated by primary fissure<ul>\n<li>Anterior Lobe</li>\n<li>Posterior Lobe</li></ul></li>\n<li>[[Folia]]<ul>\n<li>The bumby structure seen on the surface of the Cerebellum.</li>\n<li>Kind of similar to the sulci and gyri in the [[Cerebral Cortex]] but much thinner</li>\n<li>Means \"<em>pages</em>\" </li></ul></li>\n<li>[[Vermis]]<ul>\n<li>Means \"<em>worm</em>\"</li></ul></li>\n</ul>\n<p>![[Cerebellum - Ventral anatomy.png]]</p>\n<h3 id=\"cerebellumpeduncle\">Cerebellum Peduncle</h3>\n<p>Attached to the [[Brain Stem]] by 3 large fiber tracts =&gt; Peduncles</p>\n<ul>\n<li><strong>Superior Cerebellar Peduncle</strong><ul>\n<li>Main Outflow, fibers project to [[Motor Cortex]]</li></ul></li>\n<li><strong>Middle Cerebellar Peduncle</strong><ul>\n<li>Fiber enter from the [[Pons]]</li></ul></li>\n<li><strong>Inferior Cerebellar Peduncle</strong><ul>\n<li>Fiber enter from the [[Medulla]] and [[Spinal Cord (SC)]]</li></ul></li>\n</ul>\n<p>![[Cerebellum - Peduncle.png]]</p>\n<h3 id=\"layers\">Layers</h3>\n<ul>\n<li>Cerebellar Cortex<ul>\n<li>[[Afferent]] information via inferior and middle peduncles</li>\n<li>[[Efferent]] to [[Motor Cortex]] via superior peduncle</li>\n<li>3 Layers : <ul>\n<li>Molecular Layer<ul>\n<li>Mostly has denditric arbord </li></ul></li>\n<li>[[Purkinje Cell]] layer</li>\n<li>[[Granule Cell]] layer<ul>\n<li>Very dense neuronal layer</li></ul></li></ul></li></ul></li>\n</ul>\n<p>![[Cerebellum - Cell Layers.png]]</p>\n<p>![[Cerebellum - Connection flow.png]]</p>","Words":"Cerebellum"},{"Category":"Neuroscience","Definition":"<p>Weight changes in [[Gradient Descent]] [[Learning]] are too global.\nLearning new skills completely interefere with previous learning, and the weights that were fine tuned tend to move towards the new learning goal.</p>\n<p>Also known as the [[Stability-Plasticity Dilemma]]. It is a major reason why [[Backpropagation]] is not a good enough candidate for how the human [[Brain]] learns.</p>\n<p>Two solutions the brain may have come up with : </p>\n<ul>\n<li>[[Replay]]</li>\n<li>[[Protection]]</li>\n</ul>","Words":"Catastrophic Interference"},{"Category":"Neuroscience","Definition":"<p>include [[Cerebral Cortex]], [[Brain Stem]], [[Spinal Cord (SC)]], [[Pyramidal System]] including the [[Motor System]], [[Extrapyramidal System]], [[Cerebellum]] in the brainstem and the spinal cord.</p>","Words":"Central Structure"},{"Category":"Neuroscience","Definition":"<p>Produced by the [[Chloroid plexus]].</p>\n<p>Very similar to plasma, it contains : </p>\n<ul>\n<li>Lot less protein</li>\n<li>No cells</li>\n</ul>","Words":"Cerebrospinal fluid (CSF)"},{"Category":"Neuroscience","Definition":"<p>The most cranial/superior of the [[Plexuses Nerves]].</p>\n<p>Provides : </p>\n<ul>\n<li>[[Sensory Innervation]] to the head and neck</li>\n<li>[[Motor Innervation]] to the infrahyoid muscles and diaphragm</li>\n</ul>\n<p>![[Cervical Plexus - Peripheral.png]]</p>","Words":"Cervical Plexus"},{"Category":"Neuroscience","Definition":"<p>Surface of the [[Brain]]. Also called the Neocortex because only mammals have it.\nComposed of #Sulci and #Gyri.</p>\n<p>About 80% of the mass of the [[Brain]]. </p>\n<h2 id=\"composition\">Composition</h2>\n<h3 id=\"parts\">Parts</h3>\n<ul>\n<li>[[Neocortex]] : 6 layers</li>\n<li>Archicortex and Paleocortex : <ul>\n<li>Old cortex : 3 layers</li>\n<li>[[Hippocampal Formation]]</li></ul></li>\n</ul>\n<p>![[Cerebral Cortex - Layers.png]]</p>\n<h3 id=\"regions\">Regions</h3>\n<p>![[Brodmann's map - regions.png]]</p>\n<ul>\n<li>[[Primary Sensory Cortex]]</li>\n<li>[[Secondary Sensory Cortex]]</li>\n<li>[[Association Cortex]]<ul>\n<li>On of the thing that makes humans and apes special is the large amount of association cortex that they have.</li></ul></li>\n</ul>\n<p>![[brodmann's map - Sensory Cortex.png]]</p>\n<h3 id=\"matter\">Matter</h3>\n<ul>\n<li>[[Deep Gray Matter]]</li>\n<li>[[Subcortical White Matter]]</li>\n</ul>\n<h4 id=\"subcorticalwhitematter\">Subcortical White Matter</h4>\n<ul>\n<li>The [[Gray Matter]] does not work in isolation =&gt; Connections are critical !</li>\n</ul>\n<p>Not very thick.</p>\n<p>![[Cerebral Cortex - Deep Gray Matter.png]]</p>\n<h2 id=\"stains\">Stains</h2>\n<p>Different types of stains allow to see the brain view different \"filters\". </p>\n<ul>\n<li>[[Golgi Stain]]</li>\n<li>[[Nissl Stain]]</li>\n<li>[[Myel Stain]]</li>\n</ul>","Words":"Cerebral Cortex"},{"Category":"Neuroscience","Definition":"<p>Located inside the [[Ventricles]]. \nIt is what makes the [[Cerebrospinal fluid (CSF)]].</p>\n<ul>\n<li>Kinda lumpy like grapes</li>\n<li>There's blood supply to it and that is how it makes CSF</li>\n</ul>\n<p>![[Ventricles - Choroid Plexus.png]]</p>","Words":"Chloroid plexus"},{"Category":"Neuroscience","Definition":"<p>Organ responsible for the sense of hearing.</p>","Words":"Cochlea"},{"Category":"Neuroscience","Definition":"<p>![[Circle of Willis - Diagram.png]]</p>\n<p>POV : Base of the brain \n![[Circle of Willis - Real Image.png]]</p>","Words":"Circle of Willis"},{"Category":"Neuroscience","Definition":"<p>A tool to help construct better theories of [[Cognition]] and [[Behavior]]. More of a conceptual tool than an empirical tool.\nIt requires being able to formulate a useful level of abstraction, with <em>useful</em> meaning that the model allows for integrating and understanding data at that specific level and allowing the derivations of novel empirical tests.</p>","Words":"Cognitive Modeling"},{"Category":"Neuroscience","Definition":"<p>The ability of the [[Brain]] to create map representation of the world around us.\nDifferent types of [[Neuron]] and their activity make up what is known as a \"map\". </p>\n<ul>\n<li>Some [[Neuron]] fire only when tilt is felt</li>\n<li>Some are fired when next to a boundary</li>\n</ul>","Words":"Cognitive Maps"},{"Category":"Neuroscience","Definition":"<p>Connects the [[Brain]] hemispheres and coordinates their functions.</p>\n<ul>\n<li>[[Corpus Callosum]]</li>\n<li>[[Anterior Comissure]]</li>\n<li>[[Posterior Commissure]]</li>\n</ul>\n<p>![[Subocrtical White Matter - Commissural.png]]</p>","Words":"Commissural Fibers"},{"Category":"Neuroscience","Definition":"<p>Allowing to turn verbal theories into precise formulations, thus aiding both the integration of behavioral, [[Electroencephalography (EEG)]], [[functional Magnetic Resonance Imaging (fMRI)]], and other kinds of data and testing of the theory.</p>","Words":"Computational Modeling"},{"Category":"Neuroscience","Definition":"<p>[[Memory]] [[Model]] centered around [[Context (Memory)]] that explains that recall is mainly driven by the context rather than by the previous item in a list. (Complementary to [[Associative-Chain Model]]s)</p>","Words":"Context-based Models"},{"Category":"Neuroscience","Definition":"<p>$$CV = \\frac{\\text{std}}{\\text{mean}}$$\n-&gt; CV = 1 is high variability ([[Poisson Distribution]])\n-&gt; CV = 0 is a regular process</p>","Words":"Coefficient of Variation (CV)"},{"Category":"Neuroscience","Definition":"<p>The idea that [[Information]] is stored in a module (decomposed) fashion.</p>\n<p>E.g. \"Bob is the father of Mary\", one can learn the sentence, or the individual blocks of information that there are two characters and a relationship between them.</p>","Words":"Compositionality"},{"Category":"Neuroscience","Definition":"<p>A form of [[Unsupervised Learning]] where output units enter a competition in order to be able to represent at best the current input vector.</p>\n<p>E.g. with a simple small two input units and two output units network.</p>\n<p>![[Slide54.jpeg]]</p>\n<p>The competitive part consists of the fact that the output unit with the maximal sum (smallest distance to the input pattern) is then allowed to be active ($y<em>{win} = 1$), whereas all other output units are inactovated ($y=0$). \nThis winning unit is then allowed to change its weigths with the following equation : $$\\Delta w</em>{\\text{win}, j} = \\beta (x<em>j - w</em>{\\text{win},j})$$\nIt attemps to balance the weights attached to the winning output unit such that it is the \"middle\" between all the input vectors $\\textbf{x}$ that this particular output unit represents.</p>","Words":"Competitive Learning"},{"Category":"Neuroscience","Definition":"<p>A big [[White Matter]] fiber [[Tract]] inside the [[Brain]] that conducts all of the [[Neuron]] from one hemisphere to the other.</p>\n<p>![[Medial Brain Cut Landmarks.png]]</p>","Words":"Corpus Callosum"},{"Category":"Neuroscience","Definition":"<p>All the features that cooccur with a specific [[Memory]].</p>","Words":"Context (Memory)"},{"Category":"Neuroscience","Definition":"<p>5 situations can lead to cooperation </p>\n<p>![[Kin Selection]]</p>\n<p>![[Direct Reciprocity]]</p>\n<p>![[Indirect Reciprocity]]</p>\n<p>![[Network Reciprocity]]</p>\n<p>![[Group Cooperation]]</p>\n<p>These analyses were derived under the assumption that each [[Agent]] aims to maximize his own reward. It is not needed to assume that the afents are really concerned with each other. </p>","Words":"Cooperation"},{"Category":"Neuroscience","Definition":"<p>A nice paper explaining different methods to calculate correlations : <a href=\"https://www.stat.berkeley.edu/~rabbee/correlation.pdf\">Rodgers and Nicewander 1988</a>.</p>","Words":"Correlation"},{"Category":"Neuroscience","Definition":"<p>7th part of the [[Direct Motor Pathway]]. [[Synapse]] on the lower [[Alpha Motor Neuron]].</p>\n<p>Called this way because it starts in the cortex and ends in the [[Spinal Cord (SC)]].</p>\n<h2 id=\"sections\">Sections</h2>\n<p>Composed of two main sections : </p>\n<ul>\n<li>Lateral Corticospinal Tract<ul>\n<li>Innervates Limbs</li></ul></li>\n<li>Ventral Corticospinal Track<ul>\n<li>Innvervates Trunk</li></ul></li>\n</ul>\n<blockquote>\n  <p>[[Motor Innervation]]</p>\n</blockquote>","Words":"Corticospinal Tract"},{"Category":"Neuroscience","Definition":"<p>12 [[Nerves]] that innervate targets in the head and neck.\nThey are [[Motor Innervation]] and [[Sensory Innervation]] and they carry [[Autonomic Nervous System]] information.</p>\n<h2 id=\"nerves\">Nerves</h2>\n<p>(OOOTTAFVGVSH)</p>\n<blockquote>\n  <p>\"On Old Olympus Towering Top, a Finn and German Viewed Some Hops\"</p>\n</blockquote>\n<ul>\n<li>[[I Olfactory]]</li>\n<li>[[II Optic]]</li>\n<li>[[III Oculomotor]]</li>\n<li>[[IV Trochlear]]</li>\n<li>[[V Trigeminal]]</li>\n<li>[[VI Abducens]]</li>\n<li>[[VII Facial]]</li>\n<li>[[VIII Vestibulo-cochlear]]</li>\n<li>[[IX Glossopharyngeal]]</li>\n<li>[[X Vagus]]</li>\n<li>[[XI Spinal Accessory]]</li>\n<li>[[XII Hypoglossal]]</li>\n</ul>","Words":"Cranial Nerve"},{"Category":"Neuroscience","Definition":"<p>Calculating the log-[[Likelihood]] but on a separate data set that was not used for training or estimating the parameters.\n[[Model]] complexity that does not capture actual structure in the data cannot yield an advantage in fitting another, held-out data set.</p>","Words":"Cross Validation"},{"Category":"Neuroscience","Definition":"<p>Correlation dep</p>","Words":"Correlation dependent plasticity"},{"Category":"Neuroscience","Definition":"<p>A [[Model]] for often observed spatial response profile of neurons with respect to a #stimulus or a movement that can be well approximated by a cosine function. </p>\n<p>E.g. Data, shown as [[Rasta Plot]], is the neural activity recorded from a [[Primary Motor System]] [[Pyramidal Cell]]\nThe average rate of [[Action Potential]]/Spiking can be ploted as a function of movement direction in a single equation : $$\\frac{f(s) - f<em>0}{f</em>{\\text{max}}} = \\cos (s - s_p)$$</p>\n<p>where : </p>\n<ul>\n<li>$f$ is the firing rate as a function of the movement direction $s$, substracting the baseline firing rate $f_0$</li>\n<li>$s_p$ is the prefered neuron direction for firing.</li>\n</ul>\n<h2 id=\"advantages\">Advantages</h2>\n<ul>\n<li>Provied a really nice compact summary of data</li>\n<li>Nice generalisation across movements</li>\n<li>Also applies for sensory stimuli</li>\n<li>Can be used for applications such as [[Brain-Computer Interface (BCI)]]</li>\n</ul>\n<h2 id=\"inconvenients\">Inconvenients</h2>\n<ul>\n<li>Purely descriptive</li>\n<li>No consideration <strong>how/why</strong> cosine tuning arises</li>\n<li>Limited insight</li>\n</ul>","Words":"Cosine Tuning (CT)"},{"Category":"Neuroscience","Definition":"<p>A broad issue referering to <em>how credit must be distributed accross several units</em> in [[Neural Network]].</p>\n<p>The learning algorithm must determine which units performed correctly (or not) and whoch other should receive the credit (or blame) for that.</p>\n<p>[[Learning]]</p>","Words":"Credit Assignment"},{"Category":"Neuroscience","Definition":"<p>When the [[Axon]] of the [[Direct Motor Pathway]] exits the [[Brain]].</p>\n<p>![[Direct Motor Pathways - Crus Cerebri.png]]</p>","Words":"Crus Cerebri"},{"Category":"Neuroscience","Definition":"<p>The study of the different regions of the [[Cerebral Cortex]]. </p>\n<p>How many [[Neuron]]s ? \nWhich kind? \nThe degree of [[Myelination]] within the layers.</p>\n<p>Mostly studied by [[Korbinian Brodmann]]</p>","Words":"Cytoarchitectonic"},{"Category":"Neuroscience","Definition":"<p>In [[Information Theory]], it measures the average number of&nbsp;[[Bits]]&nbsp;needed to identify an event drawn from a set if a coding scheme used for the set is optimized for an estimated [[Probability Distribution]]&nbsp;$q$, rather than the true distribution&nbsp;$p$.</p>\n<p>Often used in [[Machine Learning]] as a [[Loss function]] for the [[Logistic function]]\n$$\\log(L) = \\sum<em>i t</em>i \\log(y<em>i) + (1-t</em>i) \\log(1-y_i)$$</p>","Words":"Cross Entropy"},{"Category":"Neuroscience","Definition":"<p>A form of [[Reinforcement Learning (RL)]] where a [[Deep Learning (DL)]] [[Artificial Neural Networks (ANN)]] is used to tell the agent which actions to make.</p>","Words":"Deep Reinforcement Learning"},{"Category":"Neuroscience","Definition":"<p>Means \"crossing\" the midline. </p>\n<p>Most often used for the [[Spinal Nerve]] crossing on the other side of a fiber tract.</p>","Words":"Decussation"},{"Category":"Neuroscience","Definition":"<p>[[Gray Matter]]</p>\n<p>The gray matter that receives informations in the [[Brain]]. \nDoes not work on it's own, it is strongly connected to the [[Subcortical White Matter]].</p>\n<ul>\n<li><a href=\"Ganglia\">[Basal Nuclei]</a></li>\n<li>[[Diencephalon]]<ul>\n<li>[[Dorsal Thalamus]]</li>\n<li>[[Hypothalamus]]</li>\n<li>[[Epithalamus]]</li>\n<li><a href=\"Subthalamus\">[Ventral Thalamus]</a></li></ul></li>\n</ul>","Words":"Deep Gray Matter"},{"Category":"Neuroscience","Definition":"<p>![[Dermatome Map.png]]</p>","Words":"Dermatome"},{"Category":"Neuroscience","Definition":"<p>A [[Brain]] zone strongly linked to the [[Autonomic Nervous System]] and the [[Primary Sensory Systems]]. It is [[Deep Gray Matter]] within the brain. It's a very old part of the brain. It's kinda continuous with the [[Brain Stem]].</p>\n<p>All things related to the [[Thalamus]] : </p>\n<ul>\n<li>[[Dorsal Thalamus]]</li>\n<li>[[Hypothalamus]]</li>\n<li>[[Ventral Thalamus]]</li>\n<li>[[Epithalamus]]</li>\n</ul>\n<p>![[Medial Brain Cut Landmarks.png]]</p>\n<p>![[Diencephalon - Regions.png]]</p>","Words":"Diencephalon"},{"Category":"Neuroscience","Definition":"<p>Any situation where an [Agent] must choose between two or more actions.\nA very popular theme in cognitive [[Neuroscience]].</p>","Words":"Decision Making"},{"Category":"Neuroscience","Definition":"<p>[[Motor Information]] concerning [[Somatic]] movement of the skeletal muscles.</p>\n<ul>\n<li>[[Spinal Nerve]] </li>\n<li>[[Cranial Nerve]]</li>\n</ul>\n<h2 id=\"sections\">Sections</h2>\n<ul>\n<li>[[Premotor Cortex]]<ul>\n<li>[[Frontal Lobe]]</li></ul></li>\n<li>[[Motor Cortex]]<ul>\n<li>[[Upper Motor Neurons]]</li></ul></li>\n</ul>\n<p>Then </p>\n<p>The [[Axon]] then travels thorugh the great big fiber pathway within the [[Central Nervous System (CNS)]] called the [[Internal Capsule]]</p>\n<p>Then </p>\n<p>When the [[Axon]] actually leaves the [[Brain]] it becomes the [[Crus Cerebri]]</p>\n<p>Then </p>\n<p>Next step is the [[Pons]]</p>\n<p>Then </p>\n<p>Next steps is the [[Pyramids]]</p>\n<p>Then </p>\n<p>Next step is the [[Pyramidal Decussation]]</p>\n<p>Then </p>\n<p>Next step is the [[Corticospinal Tract]]</p>","Words":"Direct Motor Pathway"},{"Category":"Neuroscience","Definition":"<p>A [[Restricted Boltzmann Machines (RBM)]] where [[Hidden Layer]] and Visible layers are detached and mapped in a [[Variationnal Autoencoder (VAE)]] format.</p>\n<p>The goal here is not the activation in the output layers, but the compression of the data in the middle layers that happens in a highly non-linear way (compared to [[Principale component Analysis (PCA)]]).</p>\n<p>![[Slide57.jpeg]]</p>","Words":"Deep Restricted Boltzmann Machines"},{"Category":"Neuroscience","Definition":"<p>If agent $A$ interacts with agent $B$, agent $A$ is likely to interact with this same agent $B$ again.</p>","Words":"Direct Reciprocity"},{"Category":"Neuroscience","Definition":"<p>Part of the [[Diencephalon]]. Bilateral area of the [[Brain]].</p>\n<p>![[Diencephalon - Dorsal Thalamus.png]]</p>\n<p>It has a lot of subnuclei (40). Here are the major groups : </p>\n<ul>\n<li>Part of [[Motor System]] with [[Basal Nuclei]]<ul>\n<li>[[Ventral Lateral]]</li>\n<li>[[Ventral Anterior]]</li></ul></li>\n<li>Participates in [[Limbic System]]</li>\n<li>A Major [[Sensory Information]] relay<ul>\n<li>All the senses (except olfactory) go through the dorsal thalamus before going through cortex.</li>\n<li>[[Medial Geniculate Nucleus]]</li>\n<li>[[Lateral Geniculate Nucleus]]</li>\n<li>[[Ventral Posterior Nucleus]]</li></ul></li>\n</ul>","Words":"Dorsal Thalamus"},{"Category":"Neuroscience","Definition":"<p>The more two datas from different classes ressemble each other, the harder it is for a [[Model]] to learn. [[Response Time (RT)]] is slower and [[Accuracy]] decreases.</p>\n<p>Symbolic numbers that are <strong>more distant</strong>, are compared more quickly and with greater accuracy. (Moyer &amp; Landaeur, 1967)</p>\n<blockquote>\n  <p>\"It is easier to judge which of the two weigths is heavier if they are more different (distant).\"\n  Example from [[Psychophysics]]</p>\n</blockquote>","Words":"Distance Effect"},{"Category":"Neuroscience","Definition":"<p>[[Neuron]] responding specifically to <em>predictors of reward</em>. </p>\n<ul>\n<li>In the initial stages of [[Learning]], these neurons respond to actual reward onset (e.g. food). </li>\n<li>After learning, these same neurons respond only to cues that predict the reward, and no longer the reward itself.</li>\n</ul>\n<p>Later works have shown that they also encode other quantities than value and predictoin, but also the advance knowledge of what reward will be receive independent of the actual reward.</p>\n<p>[[Dopamine]]</p>","Words":"Dopamine Neuron"},{"Category":"Neuroscience","Definition":"<p>Originally developed in physics as an explanation for [[Brownian Motion]], then popularized in [[Psychology]] by [[Roger Ratcliff]] in 1978.</p>\n<p>It considers the <em>difference</em> between the activations (e.g. $d = y<em>{dog} - y</em>{cat}$), written as </p>\n<p>$$\nd(t) = d(t-1) + v + N(t)\n$$\nWhen the difference reaches an upper threshold ($a$), the model decides that the stimulus is a dog. (a cat for lower threshold ($-a$)).\nThe update rule attempts to minimize an [[Energy Function]] defined across an activation space. </p>\n<h2 id=\"parameters\">Parameters</h2>\n<ul>\n<li><strong>Threshold</strong> : Cautiousness</li>\n<li><strong>Drift rate</strong> : $v$ represents the average slope of the decision trajectory</li>\n<li><strong>Bias</strong> : the <em>starting point</em> can be halfway between the threshold but not necessarly</li>\n<li><strong>Non-decision time</strong> : When the time starts at</li>\n</ul>\n<p>Note : $N(t)$ is a noise function.</p>\n<p>![[Diffusion Model.jpeg]]</p>\n<blockquote>\n  <p>What is important here is the difference between the two activation lines.</p>\n</blockquote>","Words":"Drift-Diffusion Model"},{"Category":"Neuroscience","Definition":"<p>A form of [[Neuron]] close to the [[Spinal Cord (SC)]] and [[Spinal Nerve]].</p>","Words":"Dorsal Root Ganglion (DRG)"},{"Category":"Neuroscience","Definition":"<p>Exterior layer of the [[Meninges]]. </p>\n<p>Incredibly sturdy. The sturdiest of all three layers. Means \"Tough Mother\".\nIt covers the entire surface of the brain.</p>\n<p>![[Dura Mater.png]]</p>\n<h2 id=\"specialization\">Specialization</h2>\n<ul>\n<li>It covers the entire exterior surface but also in between the midline between the two cerebral hemispheres. Which is the <em>Falx Cerebri</em></li>\n<li>The <em>Tentorium Cerebelli</em> comes covering over the [[Cerebellum]], between the [[Occipital Lobe]].</li>\n</ul>\n<h2 id=\"duralsinusesareareaswherevenousbloodiscollectingonitswaybacktotheheart\">- <em>Dural sinuses</em> are areas where venous blood is collecting on it's way back to the heart.</h2>","Words":"Dura Mater"},{"Category":"Neuroscience","Definition":"<p>[[Model]] similiar to [[fMRI-based Model]] but with [[Electroencephalography (EEG)]]</p>\n<ol>\n<li>[[Model]] parameters are first estimated (typically based on behavioral data)</li>\n<li>Based on those parameters, trial-by-trial model-based [[Regression Model]] are constructed to be used in the [[Electroencephalography (EEG)]] analysis.</li>\n<li>[[Voxels]] are then sought across the [[Brain]] that correlate with the model-based regressors. </li>\n<li>[[Voxels]] that survives statistical thresholding, and thus correlate sufficiently strongly with the regressors, are interpreted to implement at least part of the model that generated the regressor.</li>\n</ol>\n<p>Advantages are that activation can be measured at a much faster time scale, wo within-trial dynamics predicted by the model also can be compared with the EEG data.</p>","Words":"EEG-Based Model"},{"Category":"Neuroscience","Definition":"<p><strong>E</strong>xiting #Information .\n[[Neuron]]al projections <strong>to</strong> … </p>\n<p>Opposite of [[Afferent]].</p>","Words":"Efferent"},{"Category":"Neuroscience","Definition":"<p>A popular method for [[Value Estimation]].</p>\n<p>Methods requiring that we know what happens in the world after we do something. aka we have a <em>Model</em> of the world with its complete information.</p>\n<p>This model consists of the transition probabilities $\\Pr(S<em>t = s' | S</em>{t-1} = s, A_{t-1} = a)$, or $\\Pr (s'|s,a)$ for short. This is the probability of going towards state $s'$ given that one has just performed action $a$ in state $s$.</p>\n<p>The following figure shows a transition matrix applied to the rodent's maneuvering its way through the maze.\n![[Slide50.jpeg]]</p>\n<p>This method entails that, due to [[Markov Process]] assumption, it is possible to write values $Q<em>s(s,a)$ as a linear system of equalities called the [[Bellman Equation]] that can be iteratively solved : $$Q</em>s(s,a) = \\sum<em>{s'} \\Pr(s'|s,a) (r(s') + \\sum</em>{a'} \\pi (s\\, a') Q_{\\pi} (s', a'))$$\nMore specifically</p>\n<ul>\n<li>One plugs in a set of values $Q^n$, and out comes a new set $Q_{n+1}$</li>\n<li>After convergence, one has the $Q$-values policy $\\pi$. This can be done alternatively for the $V$-values.</li>\n</ul>","Words":"Dynamic Programming"},{"Category":"Neuroscience","Definition":"<p>A unit of [[Cognition]]&nbsp;#Information imprinted in a physical substance, theorized to be the means by which &nbsp;<a href=\"https://en.wikipedia.org/wiki/Memory\" title=\"Memory\">memories</a>([[Memory]])&nbsp;are stored&nbsp;as&nbsp;<a href=\"https://en.wikipedia.org/wiki/Biophysics\" title=\"Biophysics\">biophysical</a>&nbsp;or&nbsp;[biochemical]&nbsp;changes in the brain or other biological tissue, in response to external stimuli.</p>\n<p>Demonstrating the existence of, and the exact mechanism and location of, neurologically defined engrams has been a focus of persistent research for many decades.</p>","Words":"Engram"},{"Category":"Neuroscience","Definition":"<p>Strongest form of organization of sociality.</p>\n<p>Defined by the following characteristics: </p>\n<ul>\n<li>cooperative&nbsp;brood&nbsp;care (including care of offspring from other individuals)</li>\n<li>overlapping generations within a colony of adults</li>\n<li>a division of labor into reproductive and non-reproductive groups. </li>\n</ul>\n<p>The division of labor creates specialized behavioral groups within an animal society which are sometimes referred to as 'castes'. </p>\n<p>Eusociality is distinguished from all other social systems because individuals of at least one caste usually lose the ability to perform at least one behavior characteristic of individuals in another caste.</p>","Words":"Eusociality"},{"Category":"Neuroscience","Definition":"<p>A goal function used to define the #Dynamics of a [[Model]].</p>","Words":"Energy Function"},{"Category":"Neuroscience","Definition":"<p>A generalization of the notion of monetary value optimization.\nIn 1944, [[John Von Neumann]] and [[Oskar Morgenstern]] published their book,&nbsp;<em>[Theory of Games and Economic Behavior]</em>. In this book, they moved on from Bernoulli's formulation of a utlity function over wealth, and defined an&nbsp;<em>expected utility function</em>&nbsp;over&nbsp;<em>lotteries</em>, or gambles. Theirs is an axiomatic derivation, meaning, a set of <strong>assumptions over people's preferences is required</strong> before one can construct a utility function.</p>\n<p>Each person $x$ has a utility (or value) of $v(x)$ , where $v(.)$ is a function measuring the value of the object $x$.\nSubjects choose the object $x$ with maximal $v(x)$.</p>","Words":"Expected Utility Theory"},{"Category":"Neuroscience","Definition":"<p>Also known as <strong>Declarative Memory</strong>. A [[Conscious]] [[Memory]].</p>\n<h2 id=\"types\">Types</h2>\n<h3 id=\"episodic\">Episodic</h3>\n<p>\"What happened\"</p>\n<h3 id=\"semantic\">Semantic</h3>\n<p>\"Facts\"</p>","Words":"Explicit Memory"},{"Category":"Neuroscience","Definition":"<p>A unifying term for a wide variety of cellular processes, in which outside of synaptic terminals transmitter substances activate extrasynaptic receptors. Whereas [[Synaptic Neurotransmission]], extrasynaptic exocytosis may last for seconds or even minutes, thus expanding the timing of neuronal signaling.</p>\n<p><a href=\"https://www.frontiersin.org/research-topics/601/extrasynaptic-neurotransmission-as-a-way-of-modulating-multiple-neuronal-functions\">More reading here</a></p>\n<p>[[Synapse]] </p>","Words":"Extrasynaptic neurotransmission"},{"Category":"Neuroscience","Definition":"<p>A dilemma from [[Reinforcement Learning (RL)]] where there is a delicate non-trivial balance needed between the exploration of situations and the predictions of behavior of an agent.</p>","Words":"Exploration-Exploitation Dilemma"},{"Category":"Neuroscience","Definition":"<p>Groups 3 motor [[Cranial Nerve]]s reponsible for the movements of the eyeball. </p>\n<ul>\n<li>[[III Oculomotor]]</li>\n<li>[[IV Trochlear]]</li>\n<li>[[VI Abducens]]</li>\n</ul>\n<p>When looking around an eyeball, it is divided between the [[Nasal Medial]] and the [[Temporal Lateral]] which refers the muscles on the nose side and the opposite side.</p>","Words":"Extraocular Muscles"},{"Category":"Neuroscience","Definition":"<p>Items that are presented more often are remembered better.</p>","Words":"Frequency Effect"},{"Category":"Neuroscience","Definition":"<p>A potential replacement of [[Backpropagation]] algorithm, where backwards weights are randomly replaced (random but fixed). The network when learning will then adapt to this set of backward weights. (thus the term <em>Alignement</em>)</p>\n<p>Studied in the following paper : [[Feedback_Alignment.pdf]]</p>","Words":"Feedback Alignement"},{"Category":"Neuroscience","Definition":"<p>A groups of [[Neuron]] outside the [[Central Nervous System (CNS)]] with similar function, connectivity and [[Neurotransmitter]].</p>","Words":"Ganglia"},{"Category":"Neuroscience","Definition":"<p>Statistician famous for noting that averages made by groups could yield better estimates than the individual ones on which the average is based. (Wisdom of crowds)</p>\n<p>If all estimates are generated independently and from the same statistical distributions, the standard error of an average based on $N$ subjects is $N^{1/2}$ times smaller than the standard error of an average subject.</p>","Words":"Francis Galton"},{"Category":"Neuroscience","Definition":"<p>[[Synaptic Strength]] changes as a function of : </p>\n<ul>\n<li>[[presynaptic]] activity</li>\n<li>[[postsynaptic]] activity</li>\n<li>[[Reward]] prediction error</li>\n<li>[[Attention]] (<strong>factor 4</strong>)</li>\n</ul>\n<p>This attention signal makes sure that the right synapses are changed; and the attentional signal itself is also learned via RL principles.</p>\n<p>A [[Deep Learning (DL)]] [[Reinforcement Learning (RL)]] version of the [[Three-Factor Rule of Reinforcement Learning]]. </p>","Words":"Four-Factor Rule of Reinforcement Learning"},{"Category":"Neuroscience","Definition":"<p>A set of models assembled.</p>\n<p>![[Generalized Linear Models.png]]</p>\n<p>Able to solve different problems depedning on the output type</p>\n<p>| Output type     |         Likelihood         |   Non Linearity   | Model                   |\n|-----------------|:--------------------------:|:-----------------:|-------------------------|\n| Real Values     |  [[Gaussian Distribution]] |      Identity     | [[Linear Regression]]   |\n| Discrete Counts |  [[Poisson Distribution]]  |    Exponential    | [[Poisson GLM]]         |\n| Binary          | [[Bernoulli Distribution]] | [[Logistic function]] | [[Logistic Regression]] |</p>","Words":"Generalized Linear Model"},{"Category":"Neuroscience","Definition":"<p>Dumping of heay metals on [[Brain]] tissues that fills [[Neuron]]s body and axon. </p>\n<p>It doesn't fill up every cell, but those that are stained are fully stained. </p>\n<p>Helps view full architecture of a cell body.</p>","Words":"Golgi Stain"},{"Category":"Neuroscience","Definition":"<p>One of the 6 [[Brain]] Lobes</p>\n<h2 id=\"area\">Area</h2>\n<p>Separated from the [[Temporal Lobe]] by the [[Lateral Sulcus]]</p>\n<p>![[Brain Lateral Fissure.png]]</p>\n<h2 id=\"functions\">Functions</h2>\n<p>Executive functions, personality, decision making. </p>\n<p>[[Executive Functions]], [[Personality]], [[Decision Making]] </p>","Words":"Frontal Lobe"},{"Category":"Neuroscience","Definition":"<p>Iterated interactions between two or more agents, each with its own goal function, are explicitely formalized. [[John Von Neumann]] &amp; [[Oskar Morgenstern]] 1944</p>\n<p>A key goal is to derive optimal strategies for different types of games. </p>\n<p><em>Games</em> is a broad term : </p>\n<ul>\n<li>It depends on the <strong>number of players</strong> \"0-player\", \"1-player\", \"2-player\", or more generally \"<em>n</em>-player\" games.</li>\n<li>it depends wether the <strong>summed gain</strong> is zero (\"<em>zero-sum games</em>\") or not (\"<em>nonzero-sum games</em>)<ul>\n<li>If it is zero, the gain of player A myst be fully compensated by an equivalent loss of player B (most competitive games)<ul>\n<li>e.g. Tennis is a zero game, when I win, my opponents loses by the same number of games.</li></ul></li>\n<li>It is is non-zero, it allows for some amount of cooperation between players.<ul>\n<li>e.g. in a bar, i visit and pay, the barman gets pays, both of us profit from the interaction</li></ul></li></ul></li>\n<li>It depends the <strong>number of steps</strong> wether the game is one-step or iterated.</li>\n</ul>","Words":"Game Theory"},{"Category":"Neuroscience","Definition":"<p>Reducing the amount of steps in a [[Policy Iteration]] to a few steps when a full exploration is not always possible.</p>\n<p>E.g. An agent would not estimate all $10^{45}$ chess positions before updating its policy.</p>","Words":"Generalized Policy Iteration (GPI)"},{"Category":"Neuroscience","Definition":"<p>[[Model]]s which learn to reconstruct/generate hypothesis/environments/distributions from their learning.</p>\n<p>It has been theorized that the goal of the [[Brain]] would be to generate and explain its own input.</p>","Words":"Generative Models"},{"Category":"Neuroscience","Definition":"<p>Sequential, repetitive [[Motor Behavior]] elicited by external or internal triggers. Once activated these #Behavior are completed without constant conscious oversight.</p>\n<p>Ex : Once we start walking, we don't have to think about walking. Other actions can be done in parallel such as checking phone, listening to music etc etc</p>","Words":"Habits"},{"Category":"Neuroscience","Definition":"<p>Major [[Brain]] and [[Central Nervous System (CNS)]] component most often opposed to [[White Matter]].\nIt consists of : </p>\n<ul>\n<li>[[Neuron]]al cell bodies</li>\n<li>[[Neuropil]]</li>\n<li>[[Glia]] cells</li>\n<li>[[Synapse]]</li>\n<li>[[Capillary]]</li>\n</ul>\n<p>It distinguishes from [[White Matter]] in that it contains : </p>\n<ul>\n<li>&gt; cell bodies</li>\n<li>&lt; [[Myelination]] [[Axon]]</li>\n</ul>","Words":"Gray Matter"},{"Category":"Neuroscience","Definition":"<p>Group-level selection of behavioral strategies (such as cooperation) can operate and drive evolution.</p>\n<p>If $m$ denotes the number of groups and $N$ the group size, then group selection for cooperation can oocur if $$\\frac{m}{m + N} \\times b - c &gt; 0$$</p>","Words":"Group Cooperation"},{"Category":"Neuroscience","Definition":"<p>A constraint that must be satisfied. Not satisfying it means breaking the rule.</p>","Words":"Hard Constraint"},{"Category":"Neuroscience","Definition":"<p>The cannonical form of STDP</p>\n<ul>\n<li><p>LTP occurs when presynaptic precedes post synaptic spikes by 0 to 20 ms</p></li>\n<li><p>LTD occurs when post synaptics spikes leads presynaptics speaks 0 to 20-100 ms</p>\n<ul>\n<li>LTD have either short or long windows spike delay <ul>\n<li>Short window : 0 to 10-20 ms (similar to LTP)</li>\n<li>Long window : 0 -to 50-100 ms</li></ul></li></ul></li>\n<li><p>Parings need to be done 10 to 100 times before being able to measure plasticity </p></li>\n<li><p>Hebbian STDP is different from CDP which lacks the precise time and order-dependent</p></li>\n</ul>","Words":"Hebbian STDP"},{"Category":"Neuroscience","Definition":"<p>Each langague grammar embodies a set of constraints via [[Neural Network]] #weights; in judging the grammaticality of a sentence, the cognitive system would compute the harmony of that sentence.</p>\n<p>This was proposed in the following paper by Prince &amp; Smolensky in 1997 : [[Optimality- From Neural Networks to Universal Grammar.pdf]]</p>","Words":"Harmony Theory"},{"Category":"Neuroscience","Definition":"<p>Similar to [[Restricted Boltzmann Machines (RBM)]] but strickly distinguishes between the top-down (generative) versus bottom-up weights.</p>\n<p>This model is trained with the ![[Wake-sleep Algorithm]]</p>","Words":"Helmholtz Machine"},{"Category":"Neuroscience","Definition":"<p>A area of the [[Cerebral Cortex]] continuous with the [[Temporal Lobe]]. It forms the floor of the inferior horn of the [[Lateral Ventricle]].</p>\n<p>Composed of the [[Archicortex]], 3 very very old layers.</p>\n<p>Necessary for the formation of new [[Memory]].</p>\n<p>Almost every place sends information to the Hippocampus.</p>\n<h2 id=\"regions\">Regions</h2>\n<ul>\n<li>[[Hippocampus]]</li>\n<li>[[Dentate gyrus]]</li>\n<li>[[Subiculum]]</li>\n</ul>\n<h2 id=\"connections\">Connections</h2>\n<h3 id=\"afferent\">Afferent</h3>\n<ul>\n<li>[[Amygdala]]</li>\n<li>[[Primary Sensory Cortex]]</li>\n<li>[[Frontal Lobe]]</li>\n<li>[[Cingulate Gyrus]]</li>\n</ul>\n<h3 id=\"efferent\">Efferent</h3>\n<ul>\n<li>[[Amygdala]]</li>\n<li>[[Primary Sensory Cortex]]</li>\n<li>[[Frontal Lobe]]</li>\n<li>[[Cingulate Gyrus]]</li>\n<li>Anterior nucleus of [[Dorsal Thalamus]]</li>\n<li>Mammilary nucleur of [[Hypothalamus]]</li>\n</ul>\n<h2 id=\"circuitry\">Circuitry</h2>\n<p>It may be noticed how it works like a loop, as does most of neurocircuits : \nTaking information to one area, procesing it, and sending it back to the area where it came from.</p>\n<p>![[Hippocampus - Perforant Pathway.png]]</p>\n<p>![[Hippocampus - Area.png]]</p>","Words":"Hippocampal Formation"},{"Category":"Neuroscience","Definition":"<p>Also known as <strong>Cornu Ammonis (CA)</strong> or <strong>Ammon's horn</strong>.</p>\n<p>Divided between CA1, CA2 and CA3.</p>\n<h2 id=\"computationalconnectivity\">Computational Connectivity</h2>\n<p>It has been hypothesized that it functions like a [[Hopfield Model]].\nThis is because of the peculiar anatomical connectivity pattern and its input/ouput pathways. \nIn particular, the [[Cerebral Cortex]] projects to the [[Entorhinal Cortex]], which projects to the [[Dentate gyrus]], which then projects to CA3, which reccurs a bit, which then flows out via region CA1.</p>\n<p><strong>CA3</strong> has a strong [[Recurrent Neural Network (RNN)]] like structure, much more than other cortical and subcortical regions.</p>","Words":"Hippocampus"},{"Category":"Neuroscience","Definition":"<p>[[Model]] created by [[Alan Lloyd Hodgkin]] and [[Andrew Huxley]] after studying the large [[Axon]] of a squid.</p>\n<p>The details and explanations they found on the hyperpolarization and depolarization of the [[Neuron]] is the base work of modern's [[Action Potential]].</p>\n<p>Their model has the form a first-irder differential equation : $$C \\cdot \\frac{dV}{dt} = - g<em>K n^4 \\cdot (V - E</em>K) - g<em>{Na}m^3 h \\cdot (V - E</em>{Na}) - g<em>L \\cdot (V - E</em>L) + I(t)$$\nabstracting the axon by a capacitor\n![[Conductance based models.png]]</p>\n<h2 id=\"advantages\">Advantages</h2>\n<ul>\n<li>Provides a <strong>mechanism</strong> for the generation of [[Action Potential]]</li>\n<li>Synthesies large amount of neural data</li>\n<li>Describes variables that are not easily measurable (latent)<ul>\n<li>E.g. Channel opening/closing, currents for individual ions</li></ul></li>\n<li>Allows for studying effect of interventions<ul>\n<li>E.g. How would a $K$ channel blocker affect spiking?</li></ul></li>\n<li>You can make real predictions<ul>\n<li>E.g. conditions controlling timing of action potential onset (threshold, refractory period)</li></ul></li>\n</ul>\n<h2 id=\"inconvenients\">Inconvenients</h2>\n<ul>\n<li>No idea <strong>why</strong> ion channels open/close</li>\n</ul>","Words":"Hodglin-Huxley Model (H&H)"},{"Category":"Neuroscience","Definition":"<p>State of balance that most organic form of life try to achieve.</p>","Words":"Homeostatis"},{"Category":"Neuroscience","Definition":"<p>Named after the Canadian neurophysiologist [[Donald Hebb]], sometimes characterized as <em>\"If it fires together, it wires together.\"</em>. </p>\n<ul>\n<li><strong>input unit activation</strong> : $x_i$</li>\n<li><strong>output unit activation</strong> : $y_i$</li>\n<li>Labels are provided by an external source -&gt; [[Supervised Learning]]</li>\n</ul>\n<p>Energy function example : \n$$E = -\\frac{1}{I} \\Sigma<em>{i=1}^I t</em>i y<em>i$$\nOne value prediction : \n$$y</em>i = w<em>{i1}x</em>1 + w<em>{i2}x</em>2 + … + w<em>{ij}x</em>j$$</p>\n<p>To describe the weigth change between two trials $n-1$ and $n$, the notation is the following :\n$$\\Delta w<em>{ij} = w</em>{ij}(n) - w<em>{ij}(n-1)$$\nIf we apply the gradient descent we end up with the following <strong>rule</strong> : \n$$\\Delta w</em>{ij} = \\beta x<em>j t</em>i$$</p>\n<ul>\n<li><strong>Learning rate</strong> $\\beta$  : the parameter which to scale the step siwe (rather than $\\alpha$). </li>\n</ul>\n<h2 id=\"generalform\">General Form</h2>\n<p>Change of weight between units $i$ and $j$ = function of unit $i$ $\\times$ function of unit $j$</p>\n<blockquote>\n  <p>Equation $(3.4)$ </p>\n</blockquote>\n<p>Note : </p>\n<ul>\n<li>\"function of unit $i$\" = $t_i$ </li>\n<li>\"function of unit j\" = $\\beta x_j$</li>\n</ul>","Words":"Hebbian Learning"},{"Category":"Neuroscience","Definition":"<p>[[Sensory Innervation]] responsible for the sense of smell.\nTravels from dorsal nasal cavity, through cribiform plate, to the [[Olfactory Bulb]].</p>\n<ul>\n<li>Olfactory nerves synapse in [[Olfactory Bulb]].</li>\n<li>Olfactory tract connects [[Olfactory Bulb]] to the [[Cerebral Cortex]].</li>\n</ul>\n<p>Olfaction is the only sense that is not gated by the [[Thalamus]]. Which is a reason why smell has a strong emotional affect, because it first goes through the [[Limbic System]] before going through the [[Thalamus]].</p>\n<p>Dorsal nasal cavity =&gt; [[Olfactory Bulb]] =&gt; [[Limbic System]] =&gt; [[Thalamus]]</p>","Words":"I Olfactory"},{"Category":"Neuroscience","Definition":"<p>[[Sensory Innervation]] responsible for the information going from the retina to our brain.\nThe [[Axon]] cross is the [[Optic Chiasm]] where half of the neuron cross, half does not.</p>\n<p>Nerve =&gt; [[Optic Chiasm]] =&gt; Optic tract =&gt; [[Thalamus]] (Lateral Geniculate) =&gt; Optic raidiation =&gt; [[Occipital Cortex]]</p>","Words":"II Optic"},{"Category":"Neuroscience","Definition":"<p>Both [[Sensory Innervation]] and [[Motor Innervation]] and [[Autonomic Nervous System]].\n[[Inferior Ganglion]]</p>\n<p>One of the most complicated [[Cranial Nerve]] because of all the composants it has</p>\n<h2 id=\"motor\">Motor</h2>\n<ul>\n<li>[[Somatic]]<ul>\n<li>[[Stylopharyngeus Muscle]]</li></ul></li>\n<li>[[Visceral]] ([[Parasympathetic Information]])<ul>\n<li>[[Parotid Gland]] via [[Auriculotemporal Nerve]]</li></ul></li>\n</ul>\n<h2 id=\"sensory\">Sensory</h2>\n<ul>\n<li>[[Somatic]]<ul>\n<li>Posterior portion of the tongue</li>\n<li>Part of external ear</li>\n<li>Internal surface of tympanic membrane</li></ul></li>\n<li>[[Special Senses]]<ul>\n<li>Taste, posterior portion of the tongue</li></ul></li>\n<li>[[Visceral]]<ul>\n<li>[[Carotid Body]] and [[Carotid Sinus]]</li></ul></li>\n</ul>","Words":"IX Glossopharyngeal"},{"Category":"Neuroscience","Definition":"<p>[[Motor Innervation]], reponsible for one specific ocular muscle.</p>\n<p>Called \"Trochlear\" because the [[Superior Oblique]] goes through a little hook and it inserts then into the pack part of the eyeball.</p>\n<h2 id=\"muscles\">Muscles</h2>\n<p>Innervates the muscle : </p>\n<ul>\n<li>[[Superior Oblique]]</li>\n</ul>","Words":"IV Trochlear"},{"Category":"Neuroscience","Definition":"<p>[[Motor Innervation]], reponsible for operating the most of the [[Extraocular Muscles]] that moves our eyeballs.</p>\n<h2 id=\"muscles\">Muscles</h2>\n<p>Innervates the following muscles : </p>\n<ul>\n<li>[[Somatic]] :<ul>\n<li>[[Levator Palpebrae Superioris]]</li>\n<li>[[Superior Rectus]]</li>\n<li>[[Medial Rectus]]</li>\n<li>[[Inferior Rectus]]</li>\n<li>[[Inferior Oblique]]</li></ul></li>\n</ul>\n<p>![[Oculomotor - Somatic Muscles.png]]</p>\n<ul>\n<li>[[Parasympathetic Information]] : <ul>\n<li>[[Constrictor Pupillae]]<ul>\n<li>Around the iris</li></ul></li>\n<li>[[Ciliary Muscle]]</li></ul></li>\n</ul>\n<p>Allows the contraction of the iris, so that the size can change to have a better focus depending on where the object is.</p>","Words":"III Oculomotor"},{"Category":"Neuroscience","Definition":"<p>A [[Model]] layer that receives neither input nor supervisory feedback. [[Neural Network]]</p>","Words":"Hidden Layer"},{"Category":"Neuroscience","Definition":"<p>A form od [[Recurrent Neural Network (RNN)]] popularized by [[John Hopfield]] in 1982. They serve as content-adressable [[Memory]] systems with binary threshold nodes, or continuous variables.</p>\n<p>Given an appropriate [[Energy Function]], the goal of the model is to minimize energy.</p>\n<p>The function is : </p>\n<p>$$\nE = - \\Sigma<em>j \\Sigma</em>{i&lt;j}{ w<em>{i,j} x</em>i x<em>j} + \\Sigma</em>i{\\theta<em>i x</em>i }\n$$</p>\n<blockquote>\n  <p>Equation (2.6)</p>\n</blockquote>\n<ul>\n<li>Double sided arrows means that there is a positive connections between the two words.<ul>\n<li><em>\"If one of these feature is present, all positively connected are likely to be so as well.\"</em> </li></ul></li>\n<li>Double doted line means that there is a negative connections between the two words (inhibition).</li>\n</ul>\n<p>![[2.4 Hopfield Model.jpeg]]</p>\n<p><em>Active</em> detector means that the feature it is supposed to detect exists in the environment. </p>\n<p>We can iteratively calculate the energy state between two positions : </p>\n<ol>\n<li>Calculate the activaiton flowing into detector $k$ (i.e., the weigthed sum of activation of other units)</li>\n<li>Check if this activation is larger than a treshold value $\\theta_k$ : <ol>\n<li>If it is larger, then set the unit $k$ to 1 (Because then $E<em>1 < E</em>0$, implying that $E_1$ is an energetically better state)</li>\n<li>Otherwise, set it to 0 (because then $E<em>0 < E</em>1$)</li></ol></li>\n</ol>\n<p>Repeated application of this update rule will lead to an activation pattern that is a local minimum of the energy function. Such a local minimum corresponds to a [[Memory]] stored in the weigths $w_{i,j}$. </p>","Words":"Hopfield Model"},{"Category":"Neuroscience","Definition":"<p>Also known as <strong>Non-Declarative Memory</strong>.  An [[Unconscious]] [[Memory]]</p>\n<h2 id=\"types\">Types</h2>\n<ul>\n<li><p>[[Procedural Memory]]</p></li>\n<li><p>[[Priming Memory]]</p></li>\n</ul>","Words":"Implicit Memory"},{"Category":"Neuroscience","Definition":"<p>If [[Agent]] $A$ acts altruistically toward $B$, and $C$ notices this fact. If the latter increases the probability of a cooperative act of $C$ toward $A$, then $A$ may benefit from being cooperative toward $B$.</p>\n<p>If the probability of knowing the reputation of the other agent is deoted as $p$, then cooperation is valuable if $p \\times b - c &gt; 0$ (Nowal, 2006).</p>","Words":"Indirect Reciprocity"},{"Category":"Neuroscience","Definition":"<p>One of the 6 [[Brain]] Lobes</p>\n<h2 id=\"area\">Area</h2>\n<ul>\n<li>[[Insula Lobe]] (aka Island Lobe)</li>\n</ul>\n<p>![[Brain Inner Lobes.png]]</p>\n<h2 id=\"functions\">Functions</h2>\n<p>[[Pain]] (especially Visceral Pain)</p>","Words":"Insula Lobe"},{"Category":"Neuroscience","Definition":"<ul>\n<li>![[Spinal Cord - Intermediolateral Cell Column (IML).png]]</li>\n</ul>","Words":"Intermediolateral Cell Column (IML)"},{"Category":"Neuroscience","Definition":"<p>Where the [[Neuron]] [[Axon]] travels through the [[Brain]] in the [[Direct Motor Pathway]].</p>\n<p>Composed of 3 main sections : </p>\n<ul>\n<li>Anterior limb<ul>\n<li>[[Sensory Information]]</li></ul></li>\n<li>Genu<ul>\n<li>[[Motor Information]]</li></ul></li>\n<li>Posterior limb<ul>\n<li>[[Motor Information]]</li></ul></li>\n</ul>\n<p>![[Sucortical White Matter - Internal Capsule.png]]</p>\n<p>![[Direct Motor Pathways - Internal Capsule.png]]</p>","Words":"Internal Capsule"},{"Category":"Neuroscience","Definition":"<p>[[Model]]s where the output/responses interact with each other (Inhibiting or activating the other one).</p>\n<p>An particularly influential one was the <a href=\"https://psychologyconcepts.com/interactive-activation-model/\">model from McClelland and Rumelhard (1981)</a>. The central feature of this model assumes that the processing of information during reading consists of series of levels corresponding to visual features, letters and words. This model is used to explain the [[Word Superiority Effect (WSE)]].</p>\n<p>![[2.3 Part of the IAM of letter perception.jpeg]]</p>","Words":"Interactive Activation Model (IAM)"},{"Category":"Neuroscience","Definition":"<p>Selecting an [[Agent]] which benefits is shared with the deciding agent. The more agents are connected, the more they will cooperate.</p>\n<p>E.g. Genetic relatedness; getting $b$ of my genes into the next generation is equivalent to bringing the genes of two of my brothers (both which have 50% genetic similarity) into the next generation because $2 \\times \\frac{1}{2} \\times b = b$.</p>\n<p>More generally, if the other player has a relatedbess of $r$, then each benefit $b$ also leads to a benefit $r \\times b$ to the original agent.\nNowak and collegues showed that cooperation can spread throughout a population if $r\\times b - c &gt; 0$. (similar to [[Reinforcement Learning (RL)]] equations where $\\text{gain} - \\text{loss} &gt; 0$).</p>\n<hr />\n<p>It has been used to explain [[Eusociality]] in some insect species.</p>","Words":"Kin Selection"},{"Category":"Neuroscience","Definition":"<p>Visual relay nucleus of the [[Diencephalon]].</p>","Words":"Lateral Geniculate Nucleus"},{"Category":"Neuroscience","Definition":"<p>A soft variant of [[Competitive Learning]] where one defines a distance function in the output space. Some cells are therefore more or less distant from each other.</p>\n<p>Each ouput unit $i$ computes input in the usual linear way. This is followed by a competition between the ouput units. Once a unit wins (called $i<em>{\\max}$), all units are allowed to change their weights as follows : $$\\Delta w</em>{ij} = \\beta(n) e^{-\\tau d (i, i<em>{\\max})} (x</em>j, w_{ij})$$\nwhere : </p>\n<ul>\n<li>$n$ is the trial number and $d(i, i<em>{\\max})$ is the distance between unit $i$ and the winning unit $i</em>{\\max}$. The more distant the cell, the less important the update it receives.</li>\n<li>$\\tau$ is another scaling parameter, scaling the effect of distance between two output units.</li>\n</ul>\n<p>Outputs that are closer undergo similar weight changes, they will tend to code for similar input vectors.</p>\n<p>Original example uses [[Kohonen Maps]].</p>","Words":"Kohonen Learning"},{"Category":"Neuroscience","Definition":"<p>One fo the first to study the [[Cerebral Cortex]] layers, composiitons etc.</p>\n<p>Studied and wrote the [[Brodmann's map]]</p>\n<p>![[Brodmann's map.png]]</p>","Words":"Korbinian Brodmann"},{"Category":"Neuroscience","Definition":"<p>A subdivision of the [[Diencephalon]]. Separated from the [[Dorsal Thalamus]] by the Hypothelamic sulcus. Weighs around ~4 grams (Brain is around 1,500 grams). Is continuous with the [[Midbrain]] and [[Ventral Thalamus]].</p>\n<h2 id=\"signals\">Signals</h2>\n<ul>\n<li>Sends and receives #hormonal signals via the [[Vasculature]].</li>\n<li>Sends and reveives neural signals via it's connection to the : <ul>\n<li>[[Brain Stem]]</li>\n<li>[[Thalamus]]</li>\n<li>[[Amygdala]]</li></ul></li>\n</ul>\n<h2 id=\"functions\">Functions</h2>\n<p>3 major functions</p>\n<ul>\n<li>Control of the [[Pituitary Gland]] (interior and posterior)<ul>\n<li>Hypothalamus =&gt; Circulation =&gt; Affect endocrine organs</li></ul></li>\n<li>Control of the [[Autonomic Nervous System]]<ul>\n<li>Connexion to [[Amygdala]] and [[Thalamus]]</li>\n<li>Relays to [[Brain Stem]] and [[Spinal Cord (SC)]]</li></ul></li>\n<li>Control of necessary [[Survival Behavior]] (individual and species)<ul>\n<li>Mating behaviors</li>\n<li>Body Temperature</li>\n<li>Parenting</li>\n<li>Hunger</li>\n<li>Thirst</li>\n<li>Circadian Rythms</li></ul></li>\n</ul>\n<p>![[Diencephalon - Hypothalamus.png]]</p>","Words":"Hypothalamus"},{"Category":"Neuroscience","Definition":"<p>Modeling can be done at high (interaction between units) or at a \"low\" level (interaction between smaller units)</p>\n<ul>\n<li>Divided in a concept called [[Spacial Scale]] and [[Temporal Scale]]</li>\n</ul>\n<p>| <em>Spatial Scale</em> |                                                 |                         |                                     |                  |\n|-----------------|:-----------------------------------------------:|:-----------------------:|-------------------------------------|------------------|\n| <strong>Social</strong>      | Cooperation and competition between individuals |                         | Development of the english language |                  |\n| <strong>Individual</strong>  |          Response times in Stroop task          | Learning a book chapter | Learning to read                    |                  |\n| <strong>[[Brain]]</strong>       |         Neural correlate of Stroop task         |                         |                                     |                  |\n| <strong>[[Neuron]]</strong>      |         [[Neuralspiking Activity]]              |                         |                                     |                  |\n| <strong>Molecule</strong>    |                                                 |                         |                                     |                  |\n| |<strong><em><em></em></strong><strong></em></strong>_ |                  <strong>Processing</strong>                 |     <strong>Acquisition</strong>     | <strong>Cultural Change</strong>                 | <strong><em>Temporal Scale</em></strong> |</p>\n<p>The spatiotemporal scale of several real-world phenomenathat can be modeled are indicated on the graph.</p>\n<p>Time scales details :</p>\n<ul>\n<li><strong>Cognitive Processing and Human Behavior</strong><ul>\n<li>short term memory, working memory, learning</li></ul></li>\n<li><strong>Knowledge Acquisition</strong><ul>\n<li>Learning a book chapter, learning a new skill, …</li></ul></li>\n<li><strong>Cultural Change</strong><ul>\n<li>human languages, cultural knowledge, …</li></ul></li>\n</ul>\n<p>![[Figure 1.1 Levels of Modeling.jpeg]]\nNote : An even slower one could be genetic information change. not discussed in this book.</p>","Words":"Levels of Modeling"},{"Category":"Neuroscience","Definition":"<p>Used in several branches of science to visualize high-dimensional input structures.\nInput patterns that receive more space in the output map can be repsented with more precision.</p>\n<p>E.g.</p>\n<ul>\n<li>Visualize the difference between genes</li>\n<li>2D or 3D brain structures maps representation with high-dimensional input structure.</li>\n</ul>","Words":"Kohonen Maps"},{"Category":"Neuroscience","Definition":"<p>A&nbsp;muscle&nbsp;on the lateral side of the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Eye\" title=\"Eye\">eye</a>&nbsp;in the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Orbit_(anatomy)\" title=\"Orbit (anatomy)\">orbit</a>. Part of the [[Extraocular Muscles]].</p>\n<p>![[Lateral Rectus.png]]</p>","Words":"Lateral Rectus"},{"Category":"Neuroscience","Definition":"<p>One minimum solution when using [[Backpropagation]] on [[Neural Network]]. May be a maximum as well. \nIf the network always start with the same configuration, it may always end up at the same minimum. May not necessarly be the best solution of a function.</p>\n<p>![[Slide31.jpeg]]\n![[local minima.png]]</p>","Words":"Local Minima"},{"Category":"Neuroscience","Definition":"<p>Emotional responses to the environment and how your internal emotions then affect your behavior.</p>","Words":"Limbic System"},{"Category":"Neuroscience","Definition":"<p>One the 6 [[Brain]] lobes.</p>\n<h2 id=\"area\">Area</h2>\n<ul>\n<li>[[Limbic Lobe]] visible after removing the [[Brain Stem]] and the [[Cerebellum]]. <ul>\n<li>In Latin <em>Limbic</em> means \"Circle\" which is kind of the shape of this lobe hence the name.</li>\n<li>The [[Paraphippocampal Gyrus]] combined with the [[Cingulate Gyrus]] forms the [[Limbic Lobe]].</li></ul></li>\n</ul>\n<p>![[Limbic Lobe.png]]</p>\n<h2 id=\"functions\">Functions</h2>\n<p>Emotion, Arousal, Motivation, Memory</p>\n<p>[[Emotion]], [[Arousal]], [[Motivation]], [[Memory]]</p>","Words":"Limbic Lobe"},{"Category":"Neuroscience","Definition":"<p>A popular [[Activation function]] defined as $$y<em>i = \\frac{1}{1 + \\exp{(-\\gamma \\times (in</em>i - \\theta) )}}$$</p>\n<ul>\n<li>$\\theta$ is a threshold value, if $in<em>i$ exceeds this threshold, the value of $y</em>i$ becomes lager than 0.5.</li>\n<li>$\\gamma$ is a slpe parameter : The larger it is, the steeper the logistic function.</li>\n</ul>","Words":"Logistic function"},{"Category":"Neuroscience","Definition":"<p>In <a href=\"https://en.wikipedia.org/wiki/Neurophysiology\" title=\"Neurophysiology\">neurophysiology</a>, <strong>long-term depression</strong> (<strong>LTD</strong>) is an activity-dep</p>","Words":"Long-term Depression (LTD)"},{"Category":"Neuroscience","Definition":"<p>a persistent strengthening of <a href=\"https://en.wikipedia.org/wiki/Synapse\" title=\"Synapse\">synapses</a> based on recent patterns of activity. These are patterns of synaptic activity that produce a long-lasting increase in signal transmission between two <a href=\"https://en.wikipedia.org/wiki/Neuron\" title=\"Neuron\">neurons</a>.<a href=\"https://en.wikipedia.org/wiki/Long-term_potentiation#cite_note-cooke-2\">[2]</a> The opposite of LTP is <a href=\"https://en.wikipedia.org/wiki/Long-term_depression\" title=\"Long-term depression\">long-term depression</a>, which produces a long-lasting decrease in synaptic strength.</p>\n<p>[[Synapse]] [[Neuron]] [[Long-term Depression (LTD)]] #Synaptic_activity</p>","Words":"Long-term Potentation (LTP)"},{"Category":"Neuroscience","Definition":"<h2 id=\"types\">Types</h2>\n<ul>\n<li>[[Explicit Memory]]</li>\n<li>[[Implicit Memory]]</li>\n</ul>","Words":"Long-term Memory"},{"Category":"Neuroscience","Definition":"<p>A complex network of [[Plexuses Nerves]] that innervates the lower abdomen </p>\n<p>Provides : </p>\n<ul>\n<li>[[Motor Innervation]] and [[Sensory Innervation]] to the lower abdomen, anterior and medial thigh</li>\n</ul>\n<p>![[Lumbar Plexus - Peripheral.png]]</p>","Words":"Lumbar Plexus"},{"Category":"Neuroscience","Definition":"<p>A [[Process]] with the property that its [[Probability Distribution]] at time step $t$ only depends on the state of that process at time step $t-1$.</p>\n<p>More formally : \nA process ${X<em>t}$ where $$\\Pr (X</em>t = x<em>t | X</em>1 = x<em>1, … \\ , X</em>{t-1} = x<em>{t-1}) = \\Pr(X</em>t = x<em>t | X</em>{t-1} = x={t-1})$$</p>","Words":"Markov Process"},{"Category":"Neuroscience","Definition":"<p>A process including an <strong><em>agent</em></strong> interacting in an <strong><em>environment</em></strong>.</p>\n<p>The agent receives <strong><em>states</em></strong> and a <strong><em>reward</em></strong> from the environment.</p>\n<p>Time is divided into discrete time steps indexed $t$, and so states and rewards are provided as $s<em>t$ and $r</em>t$.\nIn thus, agents provide and <strong><em>action</em></strong> $a_t$ to the environment in the hopes of changing the environment to maximize the agent's reward provision.</p>\n<p>The Markov designation is given by the formalization of : </p>\n<ol>\n<li>![[Process]]</li>\n<li>![[Markov Process]]\n=&gt; If states are intermixed with actions (from the agent), hence the name.</li>\n</ol>\n<h2 id=\"policy\">Policy</h2>\n<p>Because of the [[Markov Process]] property, we can specify an agent's <strong>policy</strong> as a function of the current state $s$ and action $a$ as $$\\Pr(A = a|S = s) = \\pi (s,a)$$\n-&gt; The is the probability of choosing action $a$ when one is in state $s$.</p>\n<p>We can represent a policy as a table where rows represents states, columns represents actions, and cells of the table contrain the probability of emmitiing action $a$ when one is in state $s$.</p>\n<p>![[Slide49.jpeg]]</p>\n<h3 id=\"value\">Value</h3>\n<p>To find an optimal policy, this approach uses <strong><em>value</em></strong>. \nThe value of a state $s$ in policy $\\pi$ is defined to be the average reward that one would obtain if one starts in state $s$ at time $t$ and then follows policy $\\pi$ thereafter. </p>\n<h4 id=\"statevaluedvsd\">State Value - $V(s)$</h4>\n<p>Mathematically formalized as $$V<em>{\\pi}(s) = E(\\ \\sum</em>{k=0}^{+∞} \\eta^k r_{t+k+1} | s,\\pi \\ ) $$</p>\n<h4 id=\"actionvaluedq_pisad\">Action Value - $Q_{\\pi}(s, a)$</h4>\n<p>We here consider the value of choosing action $a$, given that one in state $s$ and one follows policy $\\pi$.</p>\n<p>Mathematically formalized as $$Q<em>{\\pi}(s,a) = E ( \\sum^{+∞}</em>{k=0} \\eta^k r_{t+k+1} | s,a,\\pi )$$Note : </p>\n<ul>\n<li>$\\eta$ is called the <strong><em>discount factor</em></strong>, allowing to differentiate the rewards by importance.</li>\n<li>$V(.)$ for any policy is most naturally represented as a vector, with the number of elements equal to the number of states</li>\n<li>$Q(.)$ is represented as a matrix (or table) where rows represent state $(s)$ and columns represent actions $(a)$ </li>\n</ul>\n<p>The point is to evaluate $Q$ and $V$ to find a better policy $\\pi$. This can be done with [[Value Estimation]] and [[Policy Updating]].</p>\n<p><strong>Note</strong> : \nThe concept of agent and environement are deliberately very general so that one has significant freedom to apply it's own context.</p>","Words":"Markov Decision Process (MDP)"},{"Category":"Neuroscience","Definition":"<p>A framework for explaining [[Cognition]], where all three levels must be studied to understand a system in its entieriety. </p>\n<p>3 levels to explain : </p>\n<ol>\n<li><p>Top level : <strong>Computation</strong>\nThe goal of the system.</p></li>\n<li><p>Middle level : <strong>Algorithms and Representations</strong></p></li>\n<li><p>Bottom level : <strong>Implementation</strong>\nThe hardware/materials of the system.</p></li>\n</ol>","Words":"Marr's Levels"},{"Category":"Neuroscience","Definition":"<p>Auditory relay nucleus of the [[Diencephalon]].</p>","Words":"Medial Geniculate Nucleus"},{"Category":"Neuroscience","Definition":"<h2 id=\"types\">Types</h2>\n<ul>\n<li>[[Sensory Memory]]</li>\n<li>[[Short-term Memory]] (or Working Memory)</li>\n<li>[[Long-term Memory]]</li>\n</ul>","Words":"Memory"},{"Category":"Neuroscience","Definition":"<p>Most inferior pieces of the [[Brain Stem]]. It is continuous with the [[Spinal Cord (SC)]].</p>\n<p>It has <strong>prominent features</strong> such as : </p>\n<ul>\n<li>[[Pyramids]]</li>\n<li>[[Olivary Eminence]]</li>\n</ul>\n<p>![[Medulla Oblongata - Pyramids and Olivary Eminence.png]]</p>\n<p>It has two [[Decussation]] : </p>\n<ul>\n<li>Motor</li>\n<li>Sensory</li>\n</ul>\n<p>Four [[Cranial Nerve]] : </p>\n<ul>\n<li>[[IX Glossopharyngeal]]</li>\n<li>[[X Vagus]]</li>\n<li>[[XI Spinal Accessory]]</li>\n<li>[[XII Hypoglossal]]</li>\n</ul>","Words":"Medulla Oblongata"},{"Category":"Neuroscience","Definition":"<p>An optimization function , also known as [[Cost function]] in [[Machine Learning]] : $$E = \\frac{1}{I}\\sum^{I}<em>{i=1} (t</em>i - y_i)^2$$</p>\n<ul>\n<li>$t_i$ are the target values</li>\n<li>The minimization goal can only be attained by making the predicted values ($y<em>i$) as similar as possible to the required values ($t</em>i$).</li>\n</ul>","Words":"Mean Squared Error (MSE)"},{"Category":"Neuroscience","Definition":"<p>Coverings that surround the entire [[Central Nervous System (CNS)]]</p>\n<h2 id=\"functions\">Functions</h2>\n<ul>\n<li>Protect</li>\n<li>Support vascular elements (blodd veessels, arteries, veins, …) </li>\n<li>Enclose the Subarachnoid space</li>\n</ul>\n<h2 id=\"layers\">Layers</h2>\n<ul>\n<li><a href=\"D\">[Dura Mater]</a></li>\n<li><a href=\"A\">[Arachnoid Mater]</a></li>\n<li><a href=\"*wiggles*\">[Subarachnoid Space]</a></li>\n<li><a href=\"P\">[Pia Mater]</a></li>\n</ul>\n<p>![[Meninges - Schema.png]]</p>","Words":"Meninges"},{"Category":"Neuroscience","Definition":"<p>Third and most cranial zone of the [[Brain Stem]]. Continuous with [[Diencephalon]].</p>\n<h2 id=\"zones\">Zones</h2>\n<p>2 main zones : </p>\n<ul>\n<li>Ventral side : [[Crus Cerebri]]</li>\n<li>Dorsal Side : [[Tectum]]</li>\n</ul>\n<p>IT is where the cerebral aqueduct passes through.</p>\n<h2 id=\"cranialnerves\">Cranial Nerves</h2>\n<p>2 [[Cranial Nerve]] : </p>\n<ul>\n<li>[[III Oculomotor]]</li>\n<li>[[IV Trochlear]]</li>\n</ul>","Words":"Midbrain"},{"Category":"Neuroscience","Definition":"<p>Metaplasticity refers to adjustment in the requirements for induction of synaptic [[Plasticity]] based on the prior history of activity.</p>\n<p><em>or</em></p>\n<p>Metaplasticity refers to neural changes that are induced by activity at one point in time and that persist and affect subsequently induced LTP or LTD.</p>\n<p>[[Synapse]]</p>\n<p>Reading : </p>\n<ul>\n<li>[[Multiple<em>forms</em>of<em>metaplasticity</em>at<em>a</em>single_hippo.pdf]]</li>\n</ul>","Words":"Metaplasticity"},{"Category":"Neuroscience","Definition":"<p>Involves the entire [[Central Nervous System (CNS)]]</p>\n<ul>\n<li>[[Brain]]</li>\n<li>[[Brain Stem]]</li>\n<li>[[Spinal Cord (SC)]]</li>\n</ul>","Words":"Motor Behavior"},{"Category":"Neuroscience","Definition":"<p>Testing if the model is appropriate for the data.</p>","Words":"Model Evaluation"},{"Category":"Neuroscience","Definition":"<h1 id=\"informationconcerningmovementgoingtothemuscles\">Information concerning movement going to the muscles</h1>\n<ul>\n<li>[[Cranial Nerve]]</li>\n<li>[[Spinal Nerve]]</li>\n</ul>\n<p>The ventral horn is really the motor relay</p>\n<p>![[Motor Information - Ventral Horn.png]]</p>\n<p>Two types of information : </p>\n<ul>\n<li>[[Visceral]] [[Efferent]]<ul>\n<li>[[Intermediolateral Cell Column (IML)]]</li></ul></li>\n<li>[[Somatic]] [[Efferent]]</li>\n</ul>","Words":"Motor Information"},{"Category":"Neuroscience","Definition":"<p>A hierarchy of three differnet levels of generality of [[Model]]s. </p>\n<p>Lowest level : <strong>Descriptive - \"what?\"</strong>\n    - Compact summary of large amounts of data\n    - [[What Model]]\nMiddle level : <strong>Mechanistic - \"How?\"</strong>\n    - Shows how neural circuits perform complex functions\n    - [[How Model]]\nTop level : <strong>Interpretive/Explanatory \"Why?\"</strong>\n    - Explain why the [[Brain]] does something\n    - [[Why Model]]</p>\n<p>Pretty similar to [[Marr's Levels]]</p>","Words":"Model Universe"},{"Category":"Neuroscience","Definition":"<p>Special [[Reflex]], often refered as the <em>tendon reflex</em> </p>\n<ul>\n<li>Muslce Spindle detects muscle length</li>\n<li>When distortion is detected, a signal is sent</li>\n</ul>\n<p>Stimulus -&gt; [[Dorsal Root Ganglion (DRG)]] -&gt; Direct Connexion to the [[Motor Neuron]] -&gt; Contraction !\n(No [[Interneuron]]) \n![[Monosynpatic Reflexes - Tendon.png]]</p>","Words":"Monosynaptic Reflex"},{"Category":"Neuroscience","Definition":"<p><strong>To supply with [[Nerves]]</strong>. \nFor example, how [[Motor Unit]] do with the skeletal muscle to cause movement.</p>","Words":"Motor Innervation"},{"Category":"Neuroscience","Definition":"<p>Testing [[Model]]s by assuming certain properties in its distribution.</p>\n<p>E.g. Assuming [[Independence]] and/or [[Additivity]].</p>","Words":"Model Assumption Tests"},{"Category":"Neuroscience","Definition":"<p>The set of central and peripheral structures in the [[Central Nervous System (CNS)]] that support [[Motor Behavior]], i.e. movement.\n Composed of [[Upper Motor Neurons]] and [[Lower Motor Neuron]] </p>\n<ul>\n<li>[[Peripheral Nerves]] may include skeletal muscles and neural connections with muscle tissues.</li>\n</ul>","Words":"Motor System"},{"Category":"Neuroscience","Definition":"<p>Similar to Dorsal Root Ganglion in [[Spinal Segment]], a Motor unit  is the number of muscle fibers innervated by one [[Alpha Motor Neuron]].</p>\n<p>Done via a  [[Neuromusclar Junction]].</p>\n<p>A ration can be calculated for the number of muscles fibers controlled by one alpha motor neuron. The bigger the ratio, the more meticulated a control is </p>\n<p>Example : </p>\n<ul>\n<li>fingers : 1:10 <ul>\n<li>1 alpha motor neuron for 10 muscle fibers</li></ul></li>\n<li>cuisse : 1:1000 <ul>\n<li>1 alpha motor neuron for 1000 muscle fibers</li></ul></li>\n</ul>","Words":"Motor Unit"},{"Category":"Neuroscience","Definition":"<p>Dumping myelin, a lipid rich coating, surrounding all the axons to keep cross talk from happening.  The stain is on [[Brain]] tissues that fills [[Neuron]]s body and axon. </p>\n<p>This allows to insulate canals of communication and to see big columns of cells, which are the functional unit of the [[Cerebral Cortex]].</p>","Words":"Myel Stain"},{"Category":"Neuroscience","Definition":"<p>A continuous performance task that is commonly used as an assessment in [[Psychology]] and&nbsp;[[Cognitive Neuroscience]]&nbsp;to measure a part of&nbsp;[[Short-term Memory]]&nbsp;and working memory capacity. </p>\n<p>Introduced by [[Wayne Kirchner]] in 1958.<strong>N-Back</strong>&nbsp;can also be used as a&nbsp;<strong>training method</strong>&nbsp;to improve&nbsp;[[Short-term Memory]]&nbsp;and [[Working Memory Capacity]] and also increase&nbsp;[[Fluid Intelligence]].</p>","Words":"N-Back Task"},{"Category":"Neuroscience","Definition":"<p>A bundle of [[Axon]]s (plus associated connective tissue and blood vessels) located outside the [[Brain]] and [[Spinal Cord (SC)]].</p>\n<p>Similar to a [[Tract]] except it is outside the [[Central Nervous System (CNS)]]</p>","Words":"Nerves"},{"Category":"Neuroscience","Definition":"<p>Layers of the [[Brain]] that only mammals have. \nIt is not filled the same way everywhere.</p>\n<p>Can pretty much 'override' [[Autonomic Nervous System]] controlled by the [[Hypothalamus]]</p>\n<h2 id=\"composition\">Composition</h2>\n<p>Different cell types in different layers. The different composiitons are called [[Cytoarchitectonic]].</p>\n<p>6 layers : </p>\n<ul>\n<li>Superficial to deep</li>\n<li>Some layers receive #Information <ul>\n<li>Layers with dense amounts of neurons</li></ul></li>\n<li>Some layers send #Information <ul>\n<li>Layers with big neurons</li></ul></li>\n<li>[[Neuron]]s are organized in columns.</li>\n</ul>\n<p>Studied via [[Brodmann's map]]\n![[Neocortex.png]]</p>","Words":"Neocortex"},{"Category":"Neuroscience","Definition":"<p>When [[Neuron]] and [[Hormone]] are part of the system.</p>","Words":"Neuroendocrine"},{"Category":"Neuroscience","Definition":"<p>Study of [[Neuron]] activity and correlates the signal pattern with a [[Behavior]] or [[Cognitive Model]]. </p>\n<p>\"How many spikes at a time\"</p>\n<h2 id=\"frameworks\">Frameworks</h2>\n<h3 id=\"ratebased\">Rate-based</h3>\n<p>A rate based framework. How many spikes in a given time.</p>\n<p>![[Neuralspiking Activity - Rate-based.png]]</p>\n<h3 id=\"spikebased\">Spike-based</h3>\n<p>What is the time in between spikes (short time, long time).</p>\n<p>![[Neuralspiking activity - Spike-based.png]]</p>","Words":"Neuralspiking Activity"},{"Category":"Neuroscience","Definition":"<p>Discipline which aims to fill gaps in understanding between [[Artificial Intelligence]] and [[Neuroscience]].</p>","Words":"Neuro-AI"},{"Category":"Neuroscience","Definition":"<p>[[Glia]] cellls that are acting on [[Cognitive Model]] such as the [[Central Nervous System (CNS)]] or the [[Peripheral Nervous System (PNS)]]</p>\n<p>![[Types of Neuroglia.png]]</p>","Words":"Neuroglia"},{"Category":"Neuroscience","Definition":"<p>The scientific term for a [[Synapse]] connecting a [[Neuron]] with a muscle fiber.</p>","Words":"Neuromusclar Junction"},{"Category":"Neuroscience","Definition":"<p>If an [[Agent]] has exactly $k$ with who it can interact, being a cooperator can pay off if $(1/k) \\times b - c &gt; 0$.</p>","Words":"Network Reciprocity"},{"Category":"Neuroscience","Definition":"<p>The idea that the [[Neuron]] is the unit of [[Cognition]] in the [[Brain]].</p>","Words":"Neuron Doctrine"},{"Category":"Neuroscience","Definition":"<p>The time-lag between the [[presynaptic]] stimulation and the [[postsynaptic]] [spike].</p>","Words":"Neuron Response Latency"},{"Category":"Neuroscience","Definition":"<p>Goal of Neuroscience : \nExplain how the [[Brain]] produce [[Behavior]] and [[Mind]]</p>","Words":"Neuroscience"},{"Category":"Neuroscience","Definition":"<p>Plop</p>","Words":"Neurotransmitter"},{"Category":"Neuroscience","Definition":"<p>[[Brain]] component, composed of [[Dendrites]] and un[[Myelination]] [[Axon]].</p>","Words":"Neuropil"},{"Category":"Neuroscience","Definition":"<p>Using Nissl substance (a big stack of rough endoplasmic reticulum), which are responsible for making proteins. Staining of [[Brain]] tissues that fills [[Neuron]]s body and axon.</p>\n<p>Fills mostly every cell roughly, so we don't really see the processes but wee see mostly every cells.</p>","Words":"Nissl Stain"},{"Category":"Neuroscience","Definition":"<p>This [[Neuron]] sen [[Axon]]s our through the Olfactory tract.</p>\n<p>![[Olfactory - Olfactory Bulb.png]]</p>","Words":"Olfactory Bulb"},{"Category":"Neuroscience","Definition":"<p>A group of [[Neuron]] within the [[Central Nervous System (CNS)]] with similar function, connectivity and [[Neurotransmitter]].</p>","Words":"Nucleus"},{"Category":"Neuroscience","Definition":"<p>A prominent feature of the [[Medulla Oblongata]]</p>","Words":"Olivary Eminence"},{"Category":"Neuroscience","Definition":"<p>One of the 6 [[Brain]] Lobes</p>\n<h2 id=\"area\">Area</h2>\n<p>[[Parietal Lobe]] and [[Occipital Lobe]]. \nNo clear landmark to between parietal and occipital lobe but there is a clearer landmark on the lateral surface.</p>\n<p>![[Brain Exterior Lobes.png]]</p>","Words":"Occipital Lobe"},{"Category":"Neuroscience","Definition":"<p>A [[Reinforcement Learning (RL)]] method to solve  [[Exploration-Exploitation Dilemma]].</p>\n<p>Policy's estimates starts with a high (i.e. optimistic) value in order to guarantee that all actions are initially sampled frequently. The unfavorable options are then gradually reduced in value.</p>\n<p>A compatible algorithm would be the [[Upper Confidence ]]</p>","Words":"Optimistic Initial Values"},{"Category":"Neuroscience","Definition":"<p>Responsible for division the two types of [[Visual Fields]].</p>\n<p>![[Optic Chiasm.excalidraw]]</p>","Words":"Optic Chiasm"},{"Category":"Neuroscience","Definition":"<p>Comparing real life data from a [[Model]]'s prediciton form a statistical way.</p>\n<p>E.g. Adding the square difference between simulated and real data for each decile of a distribution. (A decile is like a quartile but where 10% of the distribution is present)</p>","Words":"Omnibus Tests"},{"Category":"Neuroscience","Definition":"<p>A two chain system, similar to the [[Sympathetic Nervous System]].\nCarries [[Parasympathetic Information]].</p>\n<h2 id=\"composition\">Composition</h2>\n<ul>\n<li>Preganglionic [[Neuron]] in the [[Central Nervous System (CNS)]]<ul>\n<li>[[Brain Stem]]</li>\n<li>Short [[Axon]]</li>\n<li>[[Neurotransmitter]] : Acetylcholine</li></ul></li>\n<li>Ganglionic [[Neuron]]<ul>\n<li>Ganglia associated with [[Cranial Nerve]]</li>\n<li>Within the wall of the organ, neurons are embedded within the smooth muscles</li>\n<li>Long [[Axon]]</li>\n<li>[[Neurotransmitter]] : Acetylcholine</li></ul></li>\n</ul>\n<h2 id=\"areas\">Areas</h2>\n<p>![[Parasympathetic Nervous System - Composition.png]]</p>\n<h3 id=\"cranialnerveandbrainstem\">[[Cranial Nerve]] and [[Brain Stem]]</h3>\n<ul>\n<li>Oculomotor (Nerve 3)</li>\n<li>Facial (Nerve 7)</li>\n<li>Glosspharyngeal (Nerve 9)</li>\n<li>Vagus (Nerve 10)</li>\n</ul>\n<h3 id=\"spinalcordsc\">[[Spinal Cord (SC)]]</h3>\n<ul>\n<li>S2- S4</li>\n</ul>\n<h3 id=\"distribution\">Distribution</h3>\n<ul>\n<li>Head</li>\n<li>Neck</li>\n<li>Thorax</li>\n<li>Abdomen</li>\n<li>Pelvis</li>\n</ul>","Words":"Parasympathetic Nervous System"},{"Category":"Neuroscience","Definition":"<p>A [[Brain]] zone where the [[Precentral Gyrus]] and [[Postcentral Gyrus]] kinda come together. If damaged, can cause paralysis of one side of the body ([[Hemiplegia]]).</p>\n<p>![[Medial Brain Cut Landmarks.png]]</p>","Words":"Paracentral Lobe"},{"Category":"Neuroscience","Definition":"<p>One of the 6 [[Brain]] Lobes</p>\n<h2 id=\"area\">Area</h2>\n<p>[[Parietal Lobe]] and [[Occipital Lobe]]. \nNo clear landmark to between parietal and occipital lobe but there is a clearer landmark on the lateral surface.</p>\n<p>![[Brain Parietal and Occipital Lobe.png]]</p>\n<h2 id=\"functions\">Functions</h2>\n<p>[[Primary Sensory Cortex]], [[Association Cortex]]</p>","Words":"Parietal Lobe"},{"Category":"Neuroscience","Definition":"<p>Similar to [[Drift-Diffusion Model]].</p>","Words":"Ornstein-Uhlenbeck Process (OU)"},{"Category":"Neuroscience","Definition":"<p>[[Cranial Nerve]] and [[Peripheral Nerves]].</p>\n<p>[[Nerves]]</p>","Words":"Peripheral Nervous System (PNS)"},{"Category":"Neuroscience","Definition":"<p>A clear landmark separating the [[Parietal Lobe]] and [[Occipital Lobe]].</p>\n<p>![[Medial Brain Cut Landmarks.png]]</p>","Words":"Parietooccipital Sulcus"},{"Category":"Neuroscience","Definition":"<p>Last layer of the [[Meninges]].</p>\n<p>So adherent to the surface of the brain that it can't be peelen off.\nUnder the Pia is the brain matter itself called the <em>Brain Parenchyma</em>.</p>\n<p>Pia means \"<em>Delicate</em>\" -&gt; \"Delicate Mother\".\nOnly two of three cell layer thick.</p>\n<p>![[Meninges - Layers.png]]</p>","Words":"Pia Mater"},{"Category":"Neuroscience","Definition":"<p><strong>Neuroplasticity</strong>, also known as <strong>neural plasticity</strong>, or <strong>brain plasticity</strong>, is the ability of <a href=\"https://en.wikipedia.org/wiki/Neural_circuit\" title=\"Neural circuit\">neural networks</a> in the <a href=\"https://en.wikipedia.org/wiki/Brain\" title=\"Brain\">brain</a> to change through growth and reorganization. These changes range from individual <a href=\"https://en.wikipedia.org/wiki/Neuron_pathways\" title=\"Neuron pathways\">neuron pathways</a> making new connections, to systematic adjustments like <a href=\"https://en.wikipedia.org/wiki/Cortical_remapping\" title=\"Cortical remapping\">cortical remapping</a>. Examples of neuroplasticity include circuit and network changes that result from <a href=\"https://en.wikipedia.org/wiki/Learning\" title=\"Learning\">learning</a> a new ability, environmental influences, practice, and <a href=\"https://en.wikipedia.org/wiki/Psychological_stress\" title=\"Psychological stress\">psychological stress</a>.<a href=\"https://en.wikipedia.org/wiki/Neuroplasticity#cite_note-Fuchs2014-1\">[1]</a><a href=\"https://en.wikipedia.org/wiki/Neuroplasticity#cite_note-Reznikov_2012-2\">[2]</a><a href=\"https://en.wikipedia.org/wiki/Neuroplasticity#cite_note-Davidson2012-3\">[3]</a><a href=\"https://en.wikipedia.org/wiki/Neuroplasticity#cite_note-Park2010-4\">[4]</a><a href=\"https://en.wikipedia.org/wiki/Neuroplasticity#cite_note-Shaffer2016-5\">[5]</a><a href=\"https://en.wikipedia.org/wiki/Neuroplasticity#cite_note-McEwen2018-6\">[6]</a></p>\n<p>Neuroplasticity was once thought by <a href=\"https://en.wikipedia.org/wiki/Neuroscientist\" title=\"Neuroscientist\">neuroscientists</a> to manifest only during childhood,<a href=\"https://en.wikipedia.org/wiki/Neuroplasticity#cite_note-7\">[7]</a><a href=\"https://en.wikipedia.org/wiki/Neuroplasticity#cite_note-8\">[8]</a> but research in the latter half of the 20th century showed that many aspects of the brain can be altered (or are \"plastic\") even through adulthood.<a href=\"https://en.wikipedia.org/wiki/Neuroplasticity#cite_note-livingston-9\">[9]</a><a href=\"https://en.wikipedia.org/wiki/Neuroplasticity#cite_note-Rakic_2002-10\">[10]</a> However, the developing brain exhibits a higher degree of plasticity than the adult brain.<a href=\"https://en.wikipedia.org/wiki/Neuroplasticity#cite_note-11\">[11]</a> [Activity-dependent]</p>","Words":"Plasticity"},{"Category":"Neuroscience","Definition":"<p>A net of [[Spinal Nerve]], main component of a complex [[Spinal Segment]].</p>\n<p>![[Spinal Nerves - Plexus.png]]</p>\n<p>4 main plexuses : </p>\n<ul>\n<li>[[Cervical Plexus]]<ul>\n<li>Upper cervical (C1-C4)</li></ul></li>\n<li>[[Brachical Plexus]]<ul>\n<li>A bit of the Cs and the Ts</li></ul></li>\n<li>[[Lumbar Plexus]]</li>\n<li>[[Sacral Plexus]]</li>\n</ul>","Words":"Plexuses Nerves"},{"Category":"Neuroscience","Definition":"<p>A vector of activations ($\\textbf{x}$) to which an item in [[Short-term Memory]] can be bound.</p>\n<p>e.g. \nTo remember a list of items : apple, wine, pasta, carrots, .. \nThe items are bound to subsequent points : </p>\n<ul>\n<li>$\\textbf{x}<em>{pointer1}$ is bound to $\\textbf{x}</em>{apples}$</li>\n<li>$\\textbf{x}<em>{pointer2}$ is bound to $\\textbf{x}</em>{wine}$</li>\n<li>…</li>\n</ul>\n<p>we can just consider each pointer vector to have a $1$ at its corresponding place : </p>\n<ul>\n<li>$\\textbf{x}_{pointer1} = (1, 0, 0, …, 0)$</li>\n<li>$\\textbf{x}_{pointer2} = (0, 1, 0, …, 0)$</li>\n<li>…</li>\n</ul>","Words":"Pointer-item association"},{"Category":"Neuroscience","Definition":"<p>Used to [[Model]] the number of events occuring within a given time interval.</p>\n<p>The [[Probability Mass Distribution (PMF)]] is : $$\\log P(\\mathbf{y} \\mid \\mathbf{X}, \\theta) = \\sum<em>t \\log P(y</em>t \\mathbf{x_t},\\theta)$$</p>","Words":"Poisson Distribution"},{"Category":"Neuroscience","Definition":"<ul>\n<li>Pain [[Reflex]]</li>\n<li>Flexor [[Reflex]]</li>\n</ul>\n<p>Chain of neurons\nStimulus -&gt; [[Dorsal Root Ganglion (DRG)]] -&gt; [[Interneuron]] -&gt; [[Motor Neuron]] -&gt; Contraction !</p>\n<p>![[Polysynaptic Reflexes - Synaptic Chain.png]]</p>","Words":"Polysynaptic Reflex"},{"Category":"Neuroscience","Definition":"<p>A region of the [[Brain]] controlled by the [[Hypothalamus]], called [[Neuroendocrine]].</p>\n<ul>\n<li>Is stimulated via the <strong>anterior pituitary</strong></li>\n<li>Produces and secretes [[Hormone]] via the posterior pituitary</li>\n</ul>","Words":"Pituitary Gland"},{"Category":"Neuroscience","Definition":"<p>A new policy is constructed based on the newly minted $Q$ matrix or $V$ vector. </p>\n<ul>\n<li>For $Q$ values : $$\\pi (s, a) = \\arg \\max_a {Q(s,a)}$$\nThis means that in the new policy, in state $s$, the action $a$ leading to the highest estimated value ($Q(s,a)$) is chosen.</li>\n<li>For $V$ values, it can be a bit more difficult and may require several updating steps. </li>\n</ul>","Words":"Policy Updating"},{"Category":"Neuroscience","Definition":"<p>Repeated alternation between [[Value Estimation]] and the [[Policy Updating]].</p>","Words":"Policy Iteration"},{"Category":"Neuroscience","Definition":"<p>[[Brain Stem]] zone in between the [[Medulla Oblongata]] and the [[Midbrain]].\nLatin for \"<em>bridge</em>\"</p>\n<p>[[Gray Matter]] where [[Motor Neuron]] are not a solid structure anymore.</p>\n<p>4th step of the [[Direct Motor Pathway]]</p>\n<p>![[Direct Motor Pathways - Pons.png]]</p>\n<h2 id=\"features\">Features</h2>\n<p>It has 3 features : </p>\n<ul>\n<li>[[Pontine Fiber]]</li>\n<li>Middle [[Cerebellar Peduncle]]</li>\n<li>Floor of 4th [[Ventricles]]</li>\n</ul>\n<p>![[Pons - Features.png]]</p>\n<h2 id=\"cranialnerves\">Cranial Nerves</h2>\n<p>4 [[Cranial Nerve]] : </p>\n<ul>\n<li>[[V Trigeminal]]</li>\n<li>[[VI Abducens]]</li>\n<li>[[VII Facial]]</li>\n<li>[[VIII Vestibulo-cochlear]]</li>\n</ul>","Words":"Pons"},{"Category":"Neuroscience","Definition":"<p>Items near the start of the learning sequence are remembered better than later items.</p>\n<p>[[Memory]] property when [[Learning]].</p>","Words":"Primacy Effect"},{"Category":"Neuroscience","Definition":"<p>Where [[Sensory Information]] comes to perception.</p>\n<p>![[brodmann's map - Sensory Cortex.png]]</p>","Words":"Primary Sensory Cortex"},{"Category":"Neuroscience","Definition":"<p>The difference between what is obtained (the target : $t$) and what is predicted (the prediction : $y$).\nThis difference is the <em>delta</em> (as in the [[Delta Rule]]).</p>","Words":"Prediction Error"},{"Category":"Neuroscience","Definition":"<p>Distribution built after the data are collected and accounted for.</p>","Words":"Posterior Distribution"},{"Category":"Neuroscience","Definition":"<p>Refers to the memory via repetitions.</p>\n<p>Related to [[Motor System]]</p>","Words":"Priming Memory"},{"Category":"Neuroscience","Definition":"<p>Refers to \"<em>how to do something</em>\".</p>\n<p>Related to [[Motor System]]</p>","Words":"Procedural Memory"},{"Category":"Neuroscience","Definition":"<p>Distribution prior to data collection and accounted for.</p>","Words":"Prior Distribution"},{"Category":"Neuroscience","Definition":"<p>A statistical collection of variables ${X_t}$  indexed by time $t$.</p>\n<p>-&gt; E.g. A collection of weather across different days could be a process  {Rainy, Sunny, Sunny, Rainy, Sunny, … }, the tosses of coins {H, T, H, H, H, … } or the turns taken in a labyrinth {Straight, Left, Left, … }</p>","Words":"Process"},{"Category":"Neuroscience","Definition":"<p>Learning from a number of stimuli (the $N$-armed bandits), each of which provides a probabilitisc reward.</p>\n<p>One stimulus is chosen for each trial, the notions of stimulus and actions becoming indistinguishable, making $V$ and $Q$  the same. The subject chooses a stimulus on each trial according to the following softmax rule : $$\\Pr (s<em>i) = \\frac{\\exp(\\gamma V</em>i)}{\\sum<em>j \\exp( \\gamma V</em>j)}$$\nThis model has been used extensively in recent years as a vehicle to understand healthy and imparied [[Decision Making]].</p>\n<p>[[Multi-Armed Bandit (MAB)]]</p>","Words":"Probabilistic Decision Making"},{"Category":"Neuroscience","Definition":"<p>[[Axon]]s that project out of the [[Neocortex]] towards : </p>\n<ul>\n<li>[[Deep Gray Matter]]</li>\n<li>[[Brain Stem]]</li>\n<li>[[Spinal Cord (SC)]]</li>\n</ul>\n<p>When all put together these fibers, it can be called the [[Internal Capsule]].</p>\n<p>![[Sucortical White Matter - Internal Capsule.png]]</p>","Words":"Projection fibers"},{"Category":"Neuroscience","Definition":"<p>The subfield of [[Psychology]] devoted to <strong>the study of physical stimuli and their interaction with [[Sensory Information]] processing</strong>.\nIts tasks have been extensively used to draw conclusions on how #Information  is processed by the visual and other sensory systems.</p>","Words":"Psychophysics"},{"Category":"Neuroscience","Definition":"<p>The [[Neural Network]] weights that are used in task A are protected from being overwritten while task B is being learned.\nA method the [[Brain]] could use against [[Catastrophic Interference]], allowing to learn many different tasks.</p>","Words":"Protection"},{"Category":"Neuroscience","Definition":"<p>Defines the border between the [[Brain Stem]] and the [[Spinal Cord (SC)]]</p>\n<blockquote>\n  <p><em>Decussation</em> means \"cross\". The fibers cross the midline </p>\n</blockquote>\n<p>6th part of the [[Direct Motor Pathway]].</p>\n<p>![[Direct Motor Pathways - Pyramidal Decussation.png]]</p>","Words":"Pyramidal Decussation"},{"Category":"Neuroscience","Definition":"<p>Cell presents in the one dimensional layer (no depth), part of the [[Cerebellum]] layers, in between the molecular layer and the Granule cell layer.</p>\n<p>Via their orientation of their [[Dendrites]] arborescence, determines which of the [[Granule Cell]] is gonna synapse.</p>","Words":"Purkinje Cell"},{"Category":"Neuroscience","Definition":"<p>Items that are presented the most recently are remembered better.</p>\n<p>[[Memory]] property when [[Learning]].</p>","Words":"Recency Effect"},{"Category":"Neuroscience","Definition":"<p>A prominent feature of the [[Medulla Oblongata]]</p>\n<p>Has the shape of a pyramid.</p>\n<p>![[Direct Motor Pathways - Pyramids.png]]</p>\n<p>5th Part of the [[Direct Motor Pathway]].</p>","Words":"Pyramids"},{"Category":"Neuroscience","Definition":"<p>A method for [[Value Estimation]] where one estimates the values for a policy other than the policy that one is currently following. (called an <em>off-policy RL algorithm</em>)</p>\n<p>A $Q$-value is updated based not on the action taken but on the <em>best possible</em> action that could have been taken at time $t+1$ : $$Q<em>{\\pi} (s</em>t, a<em>t) \\leftarrow Q</em>{\\pi} (s<em>t, a</em>t) + \\beta (r<em>{t+1} + \\eta \\max</em>a {Q<em>n (s</em>{t+1}, a<em>{t+1})} - Q</em>{\\pi}(s<em>t, a</em>t))$$</p>","Words":"Q-Learning"},{"Category":"Neuroscience","Definition":"<p>A [[Neural Network]] with an [[Activation function]] that is not logistic but rather takes a radial form for each unit $i$ : $$f(\\textbf{x}) = \\exp(-||\\textbf{x} - \\textbf{p}<em>i ||)$$\nwhere $\\textbf{p}</em>i$ is the \"codebook vector\" for hidden unit $i$ =&gt; The vector that the unit responds most vigorously to.\nOne can consider the vector $\\textbf{p}<em>i$ as the vector of axons feeding into unit $i$, just as we did for vector $\\textbf{w}</em>i$. The further away from the input pattern, the less it responds.</p>\n<p>Used in [[Cognitive Neuroscience]] in [[Coordinate Transformation]] allowing to easily transform visual information to movements ([[Spatial Reference Frames of Visual, Vestibular, and Multimodal Heading Signals in the Dorsal Subdivision of the Medial Superior Temporal Area.pdf]])</p>\n<p>![[Slide34.jpeg]]</p>","Words":"Radial Basis Function Network (RBF)"},{"Category":"Neuroscience","Definition":"<p>A type of local processing occuring in the [[Spinal Cord (SC)]].\nInfluenced by the [[Brain]] but does not require the Brain's permission.</p>\n<h2 id=\"components\">Components</h2>\n<ul>\n<li>Receptor <ul>\n<li>In skin, muscle, joint or viscera</li></ul></li>\n<li>[[Afferent]] ([[Sensory Information]]) fiber<ul>\n<li>Process of a [[Dorsal Root Ganglion (DRG)]] [[Neuron]]</li></ul></li>\n<li>[[Interneuron]] in [[Spinal Cord (SC)]]<ul>\n<li>Distinguishes a [[Polysynaptic Reflex]] from a [[Monosynaptic Reflex]]</li></ul></li>\n<li>[[Efferent]] ([[Motor Information]]) fiber<ul>\n<li>[[Axon]] of [[Motor Neuron]] in the ventral horn</li></ul></li>\n<li>Effector<ul>\n<li>Muscle (Striated or smooth) or gland.</li></ul></li>\n</ul>","Words":"Reflex"},{"Category":"Neuroscience","Definition":"<p>A consequence following a behavior that <strong>increases</strong> the probability that the behavior will increase in the future.</p>","Words":"Reinforcement"},{"Category":"Neuroscience","Definition":"<p>The [[Information]] from task A is re-learned when/after task B is being learned during awake/asleep/rest periods.\nA method the [[Brain]] could use against [[Catastrophic Interference]], allowing to learn many different tasks.</p>","Words":"Replay"},{"Category":"Neuroscience","Definition":"<p>Augmenting distributions under assumptions. Can be use for statistical testing.</p>\n<p>General Logic : </p>\n<ol>\n<li>Calculate the observed $T$ statistic, $T^{\\text{obs}}$.</li>\n<li>Simulate new data that is ocnsistent with the model in the [[Null Hypothesis]] (but not consistent with the alternative hypothesis).</li>\n<li>Calculate a new statistic based on the simulated data, $T^{\\text{sim}}$. </li>\n<li>Repeat steps 2 and 3 as many times as computationally feasible (e.g. 100,00 times).</li>\n<li>Based on the many samples, construct the distribution of $T^{\\text{sim}}$.</li>\n<li>Compare $T^{\\text{obs}}$  with the distribution of T^{\\text{sim}} in order to calculate a $p$-value. If $T^{\\text{obs}}$ is in the tail of the $T^{\\text{sim}}$ distribution (i.e., $T^{\\text{obs}}$ has a low $p$-value), this suggests a bad model fit.</li>\n</ol>\n<p>Often used in [[Cognitive Neuroscience]] because it obviates the need to derive exact distributions.</p>","Words":"Resampling"},{"Category":"Neuroscience","Definition":"<p>A #matrix that represents the similarities between specific stimuli or conditions.</p>","Words":"Representational Dissimilarity Matrix (RDM)"},{"Category":"Neuroscience","Definition":"<p>A popular method for [[Value Estimation]], more feasible approach than [[Dynamic Programming]] based on the [[Monte Carlo sampling]].</p>\n<p>Here the agends interacts with the environment to obtain samples $(s,a,r)$ from the environment.</p>\n<blockquote>\n  <p>\"If I perform action $a$ in stuation $s$, what reward $r$ do I receive?\"</p>\n</blockquote>\n<p>With this information, $Q$-values can be updated on each trial $t$ as follows : $$Q<em>{\\pi} (s</em>t, a<em>t) \\leftarrow Q</em>{\\pi}(s<em>t, a</em>t) + \\beta(r<em>{t+1} - Q</em>{\\pi}(s<em>t, a</em>t))$$\nPretty similar to the [[Delta Rule]], where $r$ can be considered as the target value for the system to learn, and based on the delta error, the $Q$-value is updated.\nThis ressemblances doesn't mean that [[Markov Decision Process (MDP)]] [[Reinforcement Learning (RL)]] is a form of [[Supervised Learning]], because RL final goal is finding a good/optimal policy.</p>\n<p>Because if doesn't need the full sate of the <em>Model</em> around it, this method is called a <em>Model-free approach</em>. The learning is less efficient because everything is done from the perspective of the agent. There is also a strong problem of [[Credit Assignment]] because the reward can come very late in the agent progress. (e.g. winning a game of chess and trying to find out which move to assign positif or negative value.)</p>\n<p>Named after two psychologist who emphasized the role of prediction error in learning : [[Robert Rescorla]] and [[Allan Wagner]].</p>","Words":"Rescorla-Wagner Model"},{"Category":"Neuroscience","Definition":"<p>The time (or number of steps) a [[Model]] takes to find a minimum value.</p>","Words":"Response Time (RT)"},{"Category":"Neuroscience","Definition":"<p>A diffuse group of [[Neuron]] that lives inside the [[Medulla Oblongata]] and the [[Pons]]. </p>\n<p>A sort of center of general [[Awareness]] idea. It helps in aroussness sensation. It is responsible for you ot being in a coma. </p>\n<blockquote>\n  <p>brain stem damage causes the reticular system not sending information up to the thalamus (and therefor the cortex) and causes vegetative state.</p>\n</blockquote>\n<p>They receive both [[Sensory Information]] both [[Somatic]] (from the surface) and [[Visceral]] from the internal organs.\n<em>No specific sensation but general awarness</em></p>\n<ul>\n<li>Ascending projects to the [[Thalamus]] =&gt; To the [[Hypothalamus]] =&gt; To the [[Cerebral Cortex]]</li>\n<li>Descending projections to the [[Spinal Cord (SC)]]</li>\n</ul>\n<p>Contains respiratory and cardiovascular \"centers\" that regulates breathing and heart rate.</p>\n<p>Participates in ascending reticular activating system.</p>","Words":"Reticular Formation"},{"Category":"Neuroscience","Definition":"<p>A [[Boltzmann Machines]], connections are symmetric and only go <strong>between</strong> layers (from visibile to hidden units and vice versa), but not <strong>within</strong> layers.</p>\n<p>In such a restrited model, the learning rule can be approximated by a single sample from the relevant $\\Pr (\\textbf{x})$ and $\\Pr_w (\\textbf{x})$ distributions, or just a few $k$-steps with an algorithm called the [[k-step contrastive divergence]]. </p>\n<h2 id=\"generativemodels\">[[Generative Models]]</h2>\n<p>The function of a higher-level is to generate a hypothesis about what goes on in the world. </p>","Words":"Restricted Boltzmann Machines (RBM)"},{"Category":"Neuroscience","Definition":"<p>Canal responsible for the [[Sensory Information]] of acceleration and head tilt.</p>","Words":"Saccule Canal"},{"Category":"Neuroscience","Definition":"<p>The precise spike timing dependence</p>","Words":"STDP"},{"Category":"Neuroscience","Definition":"<p>Where [[Sensory Information]] is processed.</p>\n<p>![[brodmann's map - Sensory Cortex.png]]</p>","Words":"Secondary Sensory Cortex"},{"Category":"Neuroscience","Definition":"<p>\"semantic\" here refers to <em>meaning</em>. It is a field that studies how humans learn, store, and process such meanings.</p>\n<p>Two broad theoretical views : </p>\n<ul>\n<li><strong>Similarity based perspective</strong><ul>\n<li><em>Objects are sementically categorized depending on their feature-based similarity to each other.</em></li>\n<li>Any objects consist of a feature bundle, and the more similar the two bundles the higher is the probability that the two objects are categorized as belonging to the same semantic category.</li></ul></li>\n<li><strong>Theory-theory approach</strong><ul>\n<li><em>Similarty does not determine category membership. Categories are bound together by a theory that the subject holds about the category.</em></li>\n<li>e.g. A category of <em>bird</em> consisting of dissimilar entities such as eagles, robins, penguins or chickens, … is enough to be a category. The theory is that \"they fly, have light bones, feathers, …\"</li></ul></li>\n</ul>","Words":"Semantic Cognition"},{"Category":"Neuroscience","Definition":"<p>A complex network of [[Plexuses Nerves]] that innervates the posterior thigh</p>\n<p>Provides : </p>\n<ul>\n<li>[[Motor Innervation]] and [[Sensory Innervation]] to the posterior thigh, leg and pelvis</li>\n</ul>\n<p>![[Sacral Plexus - Peripheral.png]]</p>","Words":"Sacral Plexus"},{"Category":"Neuroscience","Definition":"<p>A measure of&nbsp;membrane potential&nbsp;excitability. </p>\n<p>In&nbsp;[[Neuroscience]], it is the minimal current&nbsp;amplitude&nbsp;of infinite duration (in a practical sense, about 300 milliseconds) that results in the&nbsp;depolarization&nbsp;threshold of the cell membranes being reached, such as an&nbsp;[[Action Potential]]&nbsp;or the&nbsp;contraction&nbsp;of a muscle ([[Motor Innervation]]).</p>","Words":"Rheobase"},{"Category":"Neuroscience","Definition":"<p><strong>To supply with nerves</strong>. \nFor example, sensory [[Nerves]] innervate information for sensations.</p>","Words":"Sensory Innervation"},{"Category":"Neuroscience","Definition":"<p>in seconds.</p>","Words":"Sensory Memory"},{"Category":"Neuroscience","Definition":"<p>[[Information]] concerning the external and internal environment going to the [[Central Nervous System (CNS)]]. Mainly relayed through [[Primary Sensory Neurons]] residing in the [[Dorsal Root Ganglion (DRG)]].</p>\n<p>![[Sensory Information - Neurons.png]]</p>\n<p>There are different modalities of sensations (hot/cold, pressure, gross/fine touch, …) that can be found in the skin. All those endings in the skin are connected to [[Dorsal Root Ganglion (DRG)]].</p>\n<p>![[Sensory Information - Skin Receptors.png]]</p>\n<h2 id=\"sensations\">Sensations</h2>\n<h3 id=\"grosstouchvsfinetouch\">Gross Touch VS Fine Touch</h3>\n<ul>\n<li>[[Somatic]] [[Afferent]]</li>\n<li>Gross Touch : <ul>\n<li>Pain &amp; Temperature</li>\n<li>Ascend in [[AnteroLateral System (ALS)]]</li></ul></li>\n<li>Fine Touch :<ul>\n<li>Proprioception (knowing where your body is in space) &amp; Vibration</li>\n<li>Ascend in [[Dorsal Column]]</li></ul></li>\n</ul>\n<p>![[Sensory Information - Gross Touch vs Fine Touch.png]]</p>\n<p>![[Pasted image 20220511143906.png]]</p>\n<h4 id=\"grosstouchpainandtemperature\">Gross Touch, Pain and Temperature</h4>\n<ul>\n<li>Sensory receptors in the periphery (skin, organs, muscles, …) </li>\n<li>[[Dorsal Root Ganglion (DRG)]] [[Primary Sensory Neurons]]</li>\n<li>Central process of [[Dorsal Root Ganglion (DRG)]]</li>\n<li>Synapse on [[Neuron]] os [[Spinal Cord (SC)]]</li>\n</ul>\n<p><strong>3 Neuron chain</strong>\nDRG (Skin) =&gt; Dorsal Horn ([[Spinal Cord (SC)]]) =&gt; Thalamic Neuron (in the [[Thalamus]])</p>\n<p>Chain 1 : </p>\n<ul>\n<li>Skin</li>\n<li>[[Dorsal Root Ganglion (DRG)]]</li>\n<li>Carries signal to the [[Spinal Cord (SC)]]</li>\n</ul>\n<p>Chain 2 : </p>\n<ul>\n<li>Dorsal Horn<ul>\n<li>Axon crosses the midline (between gray and white matter)</li>\n<li>Ascneds to [[Thalamus]] via [[Spinal Cord (SC)]] and [[Brain Stem]] via the [[AnteroLateral System (ALS)]]</li></ul></li>\n</ul>\n<p>Chain 3 : </p>\n<ul>\n<li>The [[Neuron]] in the [[Thalamus]] projects into the [[Primary Sensory Cortex]] (in the [[Postcentral Gyrus]], where we actually \"feel\" it).</li>\n</ul>\n<p>![[Sensory Information - Gross Touch chain.png]]</p>\n<h4 id=\"finetouchvibrationandproprioception\">Fine Touch, vibration and Proprioception</h4>\n<ul>\n<li>Sensory receptors in the periphery (skin, organs, muscles, …) </li>\n<li>[[Dorsal Root Ganglion (DRG)]] [[Primary Sensory Neurons]]</li>\n<li>Central process of [[Dorsal Root Ganglion (DRG)]]</li>\n<li>Synapse on [[Neuron]] on the Medulla Oblongata\n(No synapse in the spinal cord compared to gross touch, pain and temperature)</li>\n</ul>\n<p><strong>3 Neuron chain</strong>\nDRG (Skin) =&gt; [[Medulla Oblongata]] =&gt; Thalamic Neuron (in the [[Thalamus]])</p>\n<p>Chain 1 : </p>\n<ul>\n<li>Skin</li>\n<li>[[Dorsal Root Ganglion (DRG)]]</li>\n<li>No [[Synapse]] in the [[Spinal Cord (SC)]]!</li>\n<li>Ascends directly in the [[Dorsal Column]]</li>\n</ul>\n<p>Chain 2 : </p>\n<ul>\n<li>[[Medulla Oblongata]]<ul>\n<li>Two neurons (for legs and arms) that synapses here.</li></ul></li>\n<li>Its [[Axon]] crosses the midline </li>\n<li>Then ascends to the [[Thalamus]] via a channel called the [[Aled Lemniscus]] </li>\n</ul>\n<p>Chain 3 : </p>\n<ul>\n<li>The [[Neuron]] in the [[Thalamus]] projects into the [[Primary Sensory Cortex]] (in the [[Postcentral Gyrus]], where we actually \"feel\" it).</li>\n</ul>\n<p>![[Sensory Information - Fine Touch Neuron chain.png]]</p>","Words":"Sensory Information"},{"Category":"Neuroscience","Definition":"<p>Canal responsible for the [[Sensory Information]] of rotation.</p>\n<p>![[Semi Circular Canals - Internal Ear.png]]</p>","Words":"Semi-circular Canal"},{"Category":"Neuroscience","Definition":"<p>in minutes.</p>\n<p>[[Associative-Chain Model]]</p>","Words":"Short-term Memory"},{"Category":"Neuroscience","Definition":"<p>Comparing larger single-digit numbers is harder. </p>\n<p>e.g. easier to compare 2 and 3 than 8 and 9.</p>","Words":"Size Effect"},{"Category":"Neuroscience","Definition":"<p>Similar to [[Competitive Learning]] but where other non-winning weigths that are sufficiently close to the input pattern were allowed to change weights.</p>\n<p>This allows for some cells to develop broad tuning curves.</p>","Words":"Soft Competitive Learning"},{"Category":"Neuroscience","Definition":"<p>[[Afferent]] and [[Efferent]] systems that regulate [[Motor Innervation]] of <strong>skeletal muscle and sensory information from the external environment</strong> .</p>\n<p>Example : </p>\n<ul>\n<li>Knowing where a mosquito bite you </li>\n<li>Being able to jump up or down (volontary actions)</li>\n</ul>","Words":"Somatic Nervous System"},{"Category":"Neuroscience","Definition":"<p>'Voluntary' actions/signals/informations</p>","Words":"Somatic"},{"Category":"Neuroscience","Definition":"<p>Senses all located in the head.</p>\n<h2 id=\"olfaction\">Olfaction</h2>\n<h3 id=\"cranialnerves\">Cranial Nerves</h3>\n<ul>\n<li>[[I Olfactory]]</li>\n</ul>\n<h2 id=\"optic\">Optic</h2>\n<h3 id=\"cranialnerves-1\">Cranial Nerves</h3>\n<ul>\n<li>[[II Optic]]</li>\n</ul>\n<h2 id=\"hearingandbalance\">Hearing and Balance</h2>\n<h3 id=\"cranialnerves-2\">Cranial Nerves</h3>\n<ul>\n<li>[[VIII Vestibulo-cochlear]]</li>\n</ul>\n<h2 id=\"taste\">Taste</h2>\n<h3 id=\"cranialnerves-3\">Cranial Nerves</h3>\n<ul>\n<li>[[VII Facial]] </li>\n<li>[[IX Glossopharyngeal]]</li>\n<li>[[X Vagus]]</li>\n</ul>\n<h3 id=\"path\">Path</h3>\n<p>Tongue Receptors =&gt; cell bodies =&gt; [[Brain Stem]] =&gt; [[Thalamus]] =&gt; [[Insular Cortex]] </p>\n<p>![[Taste - Tongue Separation.png]]</p>","Words":"Special Senses"},{"Category":"Neuroscience","Definition":"<p>A [[Reinforcement Learning (RL)]] method to solve  [[Exploration-Exploitation Dilemma]].</p>\n<p>The agent samples each actions with a probability proportional to its exponentialted value.\nThus, actions with higher estimated value are sampled more often (exploitation) but other actions are sometimes sampled as well (exploration).</p>\n<p>Specifically, an action $i$ is sampled according to $$\\Pr(\\text{action} \\ i) = \\frac{\\exp (\\gamma Q<em>i)}{\\sum</em>k \\exp ( \\gamma Q_k)}$$</p>\n<p>Often used in [[Cognitive Neuroscience]] [[Reinforcement Learning (RL)]] applications.</p>","Words":"Softmax Sampling Procedure"},{"Category":"Neuroscience","Definition":"<p>A constraint not dictacted by the rules, but that would be better if obeyed.</p>","Words":"Soft Constraint"},{"Category":"Neuroscience","Definition":"<p>Connected to a [[Spinal Segment]]. Each is connected to a specific part of the body. The connexion map is visible on a [[Dermatome]].</p>\n<h2 id=\"functionalcomponents\">Functional Components</h2>\n<ul>\n<li>[[Somatic]] [[Afferent]]</li>\n<li>[[Somatic]] [[Efferent]]</li>\n<li>[[Visceral]] [[Afferent]]</li>\n<li>[[Visceral]] [[Efferent]]</li>\n</ul>\n<p>![[Spinal Cord - Somatic and Visceral Columns.png]]</p>\n<h2 id=\"compositions\">Compositions</h2>\n<p>Some are simple : </p>\n<ul>\n<li>Inercostal nerves</li>\n</ul>\n<p>Some are complex and form [[Plexuses Nerves]]</p>\n<p>![[Spinal Nerves - Simple and Complex.png]]</p>\n<ul>\n<li>31 pairs<ul>\n<li>8 Cervical</li>\n<li>12 Thoracic</li>\n<li>5 Lumbar</li>\n<li>5 Sacral</li>\n<li>1 Coccygeal</li></ul></li>\n</ul>\n<p>![[Spinal Nerves - 31 Pairs (2).png]]</p>\n<h2 id=\"dermatome\">Dermatome</h2>\n<p>![[Dermatome Map.png]]</p>","Words":"Spinal Nerve"},{"Category":"Neuroscience","Definition":"<h2 id=\"basics\">Basics</h2>\n<ul>\n<li>Relays [[Sensory Information]] from [[Peripheral Nervous System (PNS)]] to the [[Brain]] ([[Somatic Nervous System]] and [[Visceral Nervous System]])</li>\n<li>Contains [[Motor Neuron]] (somatic and visceral)</li>\n<li>Direct (local) connextions between [[Motor Information]] and [[Sensory Information]] -&gt; <strong>Reflexes</strong> !</li>\n<li>Relays [[Motor Information]] form brain to muscles. ([[Somatic Nervous System]] and [[Visceral Nervous System]])</li>\n<li>Thickness of a thumb.</li>\n<li>Part of the [[Central Nervous System (CNS)]].</li>\n</ul>\n<h2 id=\"compositions\">Compositions</h2>\n<h3 id=\"grayandwhitematter\">Gray and White Matter</h3>\n<p>The spinal cord is made of [[Gray Matter]] and [[White Matter]].\n-&gt; The Grey Mater in the spinal cord si called the <strong>Gray Butterfly</strong> because of its shape.</p>\n<p>![[Spinal Cord - Composition.png]]</p>\n<h3 id=\"meninges\">Meninges</h3>\n<ul>\n<li>All 3 layers of the [[Meninges]] surround the spinal cord.</li>\n<li>Covers the initial part of spinal nerves then fuse with [[Epineureum]].</li>\n</ul>\n<p>![[Spinal Cord - Meninges.png]]</p>\n<ul>\n<li>The Dura fuses with the spinal nerves that will eventually be covered by [[Epineureum]].</li>\n</ul>\n<h3 id=\"ventralanddorsal\">Ventral and Dorsal</h3>\n<ul>\n<li><p>The ventral part of the spinal cord is [[Motor Information]]</p></li>\n<li><p>The dorsal part of the spinal cord is [[Sensory Information]]\n![[Spinal Cord - Ventral and Dorsal Information.png]]</p></li>\n<li><p>There is one blood supply for the Ventral part : Ventral Spinal Artery</p></li>\n<li><p>There are two blood supply for the Dorsal part : Dorsal Spinal Artery\n![[Spinal Cord - Artery.png]]</p></li>\n</ul>\n<h2 id=\"areas\">Areas</h2>\n<p>![[Spinal Cord - Regions.png]]</p>\n<p>There are lots of fibers and neurons for the legs and arms so they need an enlargement in the spinal cord.</p>\n<p>As you go down the spinal cord, there is less and less [[White Matter]] and more and more [[Gray Matter]]. This is because the fibers coming from the white matter travels down the spinal cord and most of them leave along the way, connexting to the various entities along the body (arms, hollow muscles, etc).</p>\n<p>![[Spinal Cord - Regions - Cross Section.png]]</p>\n<ul>\n<li>The Dura continues beyond the spinal cord, covering <em>cauda equina</em> (The Dural Sac)</li>\n<li>In between the Dura and the Bones around it, there is the [[Epidural Fat]].</li>\n</ul>","Words":"Spinal Cord (SC)"},{"Category":"Neuroscience","Definition":"<p>A piece of the [[Spinal Cord (SC)]], considered as the functional unit of the Spinal Cord.</p>\n<p>It is the are to/from the which on set of [[Spinal Nerve]] is connected.</p>\n<p>![[Spinal Segment - Definition.png]]</p>\n<p>One spinal segment will compose all the dorsal and ventral root, root ganglions and rootlets</p>\n<p>![[Spinal Segment - Ventral and Dorsal Details.png]]</p>\n<p><strong>Spinal Segments Map to the Body Surface</strong></p>\n<ul>\n<li>Each Dorsal Root Ganglion (DRG) neuron innvervates an area of skin called a cutaneous field.</li>\n<li>Each DRG contains hundreds of neurons</li>\n<li>Skin gather information, sends it to the DRG which relays it to the connected spinal segment.</li>\n</ul>","Words":"Spinal Segment"},{"Category":"Neuroscience","Definition":"<p>Two experiments : </p>\n<ol>\n<li>Finding a model to fit agent's money payoff game decision</li>\n</ol>\n<p>Hutcherson et al. (2015) presented repeated option choices to their participants, with one fixed options (both get 50€) and a variable option (ranging from 10€ to 100€) to both the agent (named €Self) and the other (denoted €Other).</p>\n<p>The authors next assumed that the relative value $d(t)$ of the two options changes across time steps $t$ (within a trial) as follows : $$d(t) = d(t-1) + \\beta<em>{\\text{Self}}(\\text{€Self} - 50) + \\beta</em>{\\text{Other}} (\\text{€Other} - 50) + N(t)$$\nWhen the relative value of $d(t)$ reaches an upper bound, the variable option is chosen. When it reaches a lower bound, the fixed option is chosen.\nThe data collected from participantsallowed the authors to fit an accumlation-to-bound model to both choice and response time (RT) data.</p>\n<p>=&gt; Trying to find why are generous choices slower than selfish ones. </p>\n<ol start=\"2\">\n<li>Money vs. Shock received</li>\n</ol>\n<p>Crockett et al. (2014) presented to subjects two options : A monetary reward but at a physical cost (an electric shock). In some trials, the shock was received by the decision maker, in others, the shock was received by another agent instead.</p>\n<p>The following model was proposed for acceptance of the shock option : $$\\Pr (\\text{Shock}) = \\frac{\\exp ( \\gamma ((1 - \\kappa) \\Delta m - \\kappa \\Delta s))}{1 + \\exp ( \\gamma ((1 - \\kappa) \\Delta m - \\kappa \\Delta s))}$$\nwhere : </p>\n<ul>\n<li>$\\Delta m$ is the difference in monetary reward of the two options.</li>\n<li>$\\Delta s$ the difference in shock between the two options.</li>\n<li>$\\kappa$ indicates how sensitive the participant is for shock versus reward (larger $\\kappa$, stronger shock-sensitivity)\nThe authors observed that on average harms to others outweights harm to self (at least in this experimental paradigm).</li>\n</ul>","Words":"Social Decision Making"},{"Category":"Neuroscience","Definition":"<blockquote>\n  <p>Spiral Ganglion is for the [[Cochlea]], what the [[Dorsal Root Ganglion (DRG)]] is for the [[Peripheral Nerves]]</p>\n</blockquote>","Words":"Spiral Ganglion"},{"Category":"Neuroscience","Definition":"<p>Related to [[Synapse]] and [[Memory]] in the [[Brain]]. </p>\n<p>Dilema focused around the right balance of Stability and Plasticity in synaptic connections and [[Neuron Circuit]].</p>","Words":"Stability Plasticity Dilema"},{"Category":"Neuroscience","Definition":"<p>Muscle that allow to turn the head in left and right rotation.</p>","Words":"Sternocleidomastoid"},{"Category":"Neuroscience","Definition":"<p>a [[Psychology]] experiment proving the link between the cognitive processes of prononciation, words and colors.\nPeople have to name the color with which the word is written but not the word itself. </p>\n<p>![[Stroop Task - YB.png]]\nMy record : </p>\n<p>![[Stroop Task - Results.png]]</p>","Words":"Stroop Task"},{"Category":"Neuroscience","Definition":"<p>Between the [[Arachnoid Mater]] and the [[Pia Mater]] in the [[Meninges]].</p>\n<p>Contains the [[Cerebrospinal fluid (CSF)]], floating so that your [[Brain]] doesn't squish your brain stem.</p>","Words":"Subarachnoid Space"},{"Category":"Neuroscience","Definition":"<p>[[Gradient Descent]] where on stochastically samples just one stimulus-category pair on each trial.</p>","Words":"Stochastic Gradient Descent"},{"Category":"Neuroscience","Definition":"<p>One of the [[Extraocular Muscles]] hooked at the back of the eyeball.</p>","Words":"Superior Oblique"},{"Category":"Neuroscience","Definition":"<p>The [[White Matter]], [[Myelination]] [[Axon]] that can connect all the [[Gray Matter]] within our [[Brain]] and [[Deep Gray Matter]]. </p>\n<h2 id=\"connectiontypes\">Connection types</h2>\n<p>3 main types of connections.</p>\n<h3 id=\"commissuralfibers\">[[Commissural Fibers]]</h3>\n<h3 id=\"projectionfibers\">[[Projection fibers]]</h3>\n<h3 id=\"associationfibers\">[[Association Fibers]]</h3>","Words":"Subcortical White Matter"},{"Category":"Neuroscience","Definition":"<p>\"Fight or Flight\"</p>\n<p>A two [[Neuron]]-Chain with targets all over the body.</p>\n<h2 id=\"composition\">Composition</h2>\n<ul>\n<li><p>Preganglion [[Neuron]]</p>\n<ul>\n<li>[[Intermediolateral Cell Column (IML)]]<ul>\n<li>![[Spinal Cord - Intermediolateral Cell Column (IML).png]]</li></ul></li>\n<li>Short [[Axon]]</li>\n<li>[[Neurotransmitter]] : Acetylcholine</li></ul></li>\n<li><p>Ganglionic [[Neuron]]</p>\n<ul>\n<li>Sympathetic Chain</li>\n<li>Long [[Axon]]<ul>\n<li>Same can even travel down the chain many levels before reaching their target ganglion</li></ul></li>\n<li>[[Neurotransmitter]] : Norepinephrine</li></ul></li>\n<li><p>Target</p>\n<ul>\n<li>Thoracic<ul>\n<li>Increased respiratory rate</li>\n<li>Increased heart rate</li>\n<li>Increased blood glucose</li>\n<li>Dilated pupils</li>\n<li>Relaxed gut</li></ul></li>\n<li>Cranial Sacral <ul>\n<li>Decreased respiratory rate</li>\n<li>Decreased heart rate</li>\n<li>Decreased blood glucose</li>\n<li>Constricted pupils</li>\n<li>Busy gut</li></ul></li></ul></li>\n</ul>\n<h2 id=\"areas\">Areas</h2>\n<ul>\n<li>[[Spinal Cord (SC)]]<ul>\n<li>T1 - L2</li></ul></li>\n</ul>\n<h2 id=\"distribution\">Distribution</h2>\n<ul>\n<li>Head</li>\n<li>Neck </li>\n<li>Thorax</li>\n<li>Abdomen</li>\n<li>Pelvis</li>\n<li>Limbs</li>\n</ul>","Words":"Sympathetic Nervous System"},{"Category":"Neuroscience","Definition":"<p>A point of connection/communication between [[Neuron]]</p>","Words":"Synapse"},{"Category":"Neuroscience","Definition":"<p>Describes the induction rules for plasticity as a relationship between neural activity patterns and the resulting change in synapse strength. \nThey are determined by the underlying cellular mechanisms for [[Plasticity]]. \nThey predict.</p>","Words":"Synaptic learning rule"},{"Category":"Neuroscience","Definition":"<p>A popular method for [[Value Estimation]], combining the advantages of of the [[Rescorla-Wagner Model]] and [[Dynamic Programming]] methods.</p>\n<p>In the [[Dynamic Programming]] case : </p>\n<ul>\n<li>Does not require actual rewards from every trial in order to learn. </li>\n</ul>\n<p>In the [[Rescorla-Wagner Model]] case : </p>\n<ul>\n<li>Does not require complicated updating algorithms.</li>\n<li>The target for Q-Values is the next-time step reward $r_{t+1}$.</li>\n</ul>\n<p>Here the target is the current reward <strong>plus the (discounted) value of the next state</strong>. In particular, the temporal difference learning rule for $V$ values is written as $$V<em>{\\pi} (s</em>t) \\leftarrow V<em>{\\pi} (s</em>t) + \\beta ( r<em>{t+1} + \\eta V</em>{\\pi} (s<em>{t+1}) - V</em>{\\pi} (s<em>t))$$\n=> The value of the state that was active at time step $t$ (i.e., $s</em>t$), is updated using the reward at the next time step ($r<em>{t+1}$), <strong>but also</strong>, using the estimate of the value of the subsequent state, the organism finds itself in ($V(s</em>{t+1})$).\nAlthough the value at the next time step ($t+1$) may not yet be well known, its estimate is nevertheless used as a target for updating the value of the previous state ($s_t$). This procedure is called [[Bootstrapping]].</p>\n<p>The learning rule becomes : $$Q<em>{\\pi} (s</em>t, a<em>t) \\leftarrow Q</em>{\\pi} (s<em>t, a</em>t) + \\beta (r<em>{t+1} + \\eta Q</em>n (s<em>{t+1}, a</em>{t+1}) - Q<em>{\\pi}(s</em>t, a_t))$$</p>\n<p>Also known as the [[SARSA Rule]] because of the sequence of the elemts on the right side of the equation.</p>","Words":"Temporal Differences"},{"Category":"Neuroscience","Definition":"<p>One of the 6 [[Brain]] Lobes</p>\n<h2 id=\"area\">Area</h2>\n<p>Separated from the [[Temporal Lobe]] by the [[Lateral Sulcus]]</p>\n<p>![[Brain Lateral Fissure.png]]</p>\n<h2 id=\"functions\">Functions</h2>\n<p>[[Primary Auditory Cortex]] [[Audition]]</p>","Words":"Temporal Lobe"},{"Category":"Neuroscience","Definition":"<p>Refers to a process occurring at nerve terminals in which the arrival of a presynaptic impulse evokes exocytosis followed by a postsynaptic response within a millisecond time scale.</p>\n<p>[[Synapse]]</p>","Words":"Synaptic Neurotransmission"},{"Category":"Neuroscience","Definition":"<p>Muscle that allows to shrug shoulders</p>","Words":"Trapezius"},{"Category":"Neuroscience","Definition":"<p>One of the first model to combine [[Gradient Ascent]] and [[Markov Decision Process (MDP)]] in [[Reinforcement Learning (RL)]].</p>\n<p>The model's goal was to compute the value (probability of winning) for each possible state of the game of backgammon. </p>\n<p>Because there are too many states, they were approximated by a multilayer [[Neural Network]] that projected to an output layer that represented the value of the state.</p>\n<p>All weights were trained by a variant of [[Temporal Differences]] that [[Backpropagation]] the value from the output layers to the deeper layers.</p>\n<p><a href=\"https://en.wikipedia.org/wiki/TD-Gammon\">Wikipedia Article</a></p>","Words":"TD-Gammon Program"},{"Category":"Neuroscience","Definition":"<p>[[Motor Neuron]] activated in the [[Premotor Cortex]] as a result of [[Somatic]] movement.</p>\n<p>The very top of the chain for [[Direct Motor Pathway]]</p>\n<p>![[Direct Motor Pathways - Upper Motor Neuron.png]]</p>","Words":"Upper Motor Neurons"},{"Category":"Neuroscience","Definition":"<p>In [[Reinforcement Learning (RL)]], one would calculate not only the value, but also the uncertainty (inverse confidence; denoted $U$) of each action, and also deterministically chooses the option that has the highest quantity $Q+U$.\nIf an action action has high value ($Q$) or high uncertainty ($U$), that option is chosen more often.</p>\n<p>Recent computational model comparisons demonstrate that this algorithm is a plausible human [[Learning]] and [[Decision Making]] [[Model]].</p>","Words":"Upper Confidence Bound Method (UCB)"},{"Category":"Neuroscience","Definition":"<p>Canal responsible for the [[Sensory Information]] of gravity.</p>","Words":"Utricle Canal"},{"Category":"Neuroscience","Definition":"<p>A Bundle of [[Axon]]s traveling together within the [[Central Nervous System (CNS)]].</p>\n<p>Similar to a [[Nerves]] except it is inside the [[Central Nervous System (CNS)]]</p>","Words":"Tract"},{"Category":"Neuroscience","Definition":"<p>An action should be reinforced by connecting the representation of the action to the representation of the stimulus/state (<strong>factor 1</strong>) that led to that action (<strong>factor 2</strong>), but only when a reward is present (<strong>factor 3</strong>).</p>\n<p>[[Reinforcement Learning (RL)]]</p>\n<p>Used for example in the [[Striatum]] where reward is signaled by [[Neurotransmitter]] such as [[Dopamine]]</p>","Words":"Three-Factor Rule of Reinforcement Learning"},{"Category":"Neuroscience","Definition":"<p>Both [[Sensory Innervation]] and [[Motor Innervation]], reponsible for innervating the muscle of mastication, and providing sensory information from the face and the inside of the oral cavities.</p>\n<p>Called \"trigeminal\" because it posseses 3 major branches : </p>\n<ul>\n<li><strong>V1 - Opthalmic</strong> ([[Sensory Innervation]])</li>\n<li><strong>V2 - Maxillary</strong> ([[Sensory Innervation]])</li>\n<li><strong>V3 - Mandibular</strong> ([[Sensory Innervation]] and [[Motor Innervation]])</li>\n</ul>\n<p>This is a lot of [[Sensory Information]], which requires a very large [[Trigeminal Ganglia]]</p>\n<h2 id=\"motor\">Motor</h2>\n<ul>\n<li>Muscles of mastication</li>\n</ul>\n<h2 id=\"sensory\">Sensory</h2>\n<ul>\n<li>Face, forehead, part of external ear, oral cavity, tongue and teeth</li>\n</ul>\n<p>![[V Trigeminal - Zones.png]]</p>","Words":"V Trigeminal"},{"Category":"Neuroscience","Definition":"<p>Both [[Sensory Innervation]] and [[Motor Innervation]], responsible for the sense of taste and the muscles of facial expression.\n[[Geniculate Ganglion]]</p>\n<h2 id=\"motor\">Motor</h2>\n<ul>\n<li>[[Somatic]]<ul>\n<li>Muscles of facial expression</li></ul></li>\n<li>[[Visceral]] ([[Parasympathetic Information]])<ul>\n<li>Submandibular and sublingual glands (one of the salivory gland)</li></ul></li>\n</ul>\n<h2 id=\"sensory\">Sensory</h2>\n<ul>\n<li>[[Special Senses]] of taste for the anterior 2/3 of the tongue</li>\n</ul>","Words":"VII Facial"},{"Category":"Neuroscience","Definition":"<p>[[Sensory Innervation]], reponsible for the information from the zone of the ear, both the [[Cochlea]] and the [[Vestibular Apparatus]].</p>\n<h2 id=\"hearing\">Hearing</h2>\n<h3 id=\"path\">Path</h3>\n<p>Soud waves =&gt; Converted in electrical signal in the [[Cochlea]] =&gt; [[Spiral Ganglion]] =&gt; [[Brain Stem]] =&gt; [[Thalamus]] =&gt; [[Temporal Lobe]]</p>\n<h2 id=\"balance\">Balance</h2>\n<h3 id=\"canals\">Canals</h3>\n<ul>\n<li>[[Utricle Canal]]</li>\n<li>[[Saccule Canal]]</li>\n<li>[[Semi-circular Canal]]</li>\n</ul>\n<h3 id=\"path-1\">Path</h3>\n<p>[[Sensory Information]] comes from the 3 canals ([[Utricle Canal]], [[Saccule Canal]], [[Semi-circular Canal]]) =&gt; [[Vestibular Ganglion]] =&gt; [[Brain Stem]] =&gt; [[Thalamus]] =&gt; [[Parietal Lobe]]</p>","Words":"VIII Vestibulo-cochlear"},{"Category":"Neuroscience","Definition":"<p>[[Motor Innervation]], reponsible for the innervation of one specific muscle, the [[Lateral Rectus]].\nThe abduction of the muscle takes the eye \"away\" from its midline, the nasal view.</p>\n<h2 id=\"muscles\">Muscles</h2>\n<p>Innervates the muscle : </p>\n<ul>\n<li>[[Lateral Rectus]]</li>\n</ul>","Words":"VI Abducens"},{"Category":"Neuroscience","Definition":"<p>One of the steps in finding better policies for [[Reinforcement Learning (RL)]] agents.\nEstimating the corresponding value function $V<em>{\\pi} (s)$ (for stimuli) or $Q</em>{\\pi} (s,a)$ (for actions) for a policy $\\pi$.</p>\n<p>Three popular methods : </p>\n<ul>\n<li>[[Dynamic Programming]]</li>\n<li>[[Rescorla-Wagner Model]]</li>\n<li>[[Temporal Differences]]</li>\n</ul>\n<p>and [[Q-Learning]]</p>","Words":"Value Estimation"},{"Category":"Neuroscience","Definition":"<p>Prediction errors tend to either exponentially vanish or explode when they are [[Backpropagation]] to deeper [[Hidden Layer]].\nWhen the weights of a [[Neural Network]] converge to 0/+$∞$ and are hard to reactivate.</p>","Words":"Vanishing and Exploding Gradient Problem"},{"Category":"Neuroscience","Definition":"<p>Capturing variability in predictions from models trained on different datasets, high model complexity</p>","Words":"Variance"},{"Category":"Neuroscience","Definition":"<p>Primary somatosensory information <strong>below</strong> the neck. Related to [[AnteroLateral System (ALS)]] #Information .</p>","Words":"Ventral Posterior Lateral"},{"Category":"Neuroscience","Definition":"<p>Primary somatosensory information <strong>above</strong> the neck. Related to [[AnteroLateral System (ALS)]] #Information .</p>","Words":"Ventral Posterior Medial"},{"Category":"Neuroscience","Definition":"<p>[[Sensory Information]] Relay nucleus of the [[Diencephalon]] before reaching the [[Cerebral Cortex]].</p>\n<p>Composed of : </p>\n<ul>\n<li>[[Ventral Posterior Medial]]</li>\n<li>[[Ventral Posterior Lateral]]</li>\n</ul>","Words":"Ventral Posterior Nucleus"},{"Category":"Neuroscience","Definition":"<p>Home of the [[Chloroid plexus]].\nThe [[Cerebrospinal fluid (CSF)]] is produced in all lateral Ventricles horns, it then exists through the third ventricle to the cerebral aqueduct into the fourth and then it goes into the [[Subarachnoid Space]].</p>\n<h2 id=\"locations\">Locations</h2>\n<ul>\n<li>Lateral Ventericles : Located on each side of the [[Brain]].</li>\n<li>3rd : Midline of the brain.</li>\n<li>4th : Underneath the [[Cerebellum]] and also on the midline.</li>\n</ul>\n<p>![[Ventricles.png]]</p>\n<p>![[Ventricles Cast.png]]</p>\n<h3 id=\"lateralventricles\">Lateral Ventricles</h3>\n<p>One in each of our cerebral hemisphere, spanned in the entire range of our cerebral hemispheres.</p>\n<p>The <em>Septum Pellucidum</em> separates your lateral ventricles from the other.</p>\n<p>![[Lateral Ventricles.png]]</p>\n<h3 id=\"thirdventricle\">Third Ventricle</h3>\n<ul>\n<li>On the midline</li>\n<li>Very thin</li>\n<li>Lateral Walls are formed by the diencephalon</li>\n<li>It empties into the fourth ventricle via the cerebral aqueduct</li>\n<li>The <em>Massa Intermedia</em> is a lump of neurons that holds the two hemispheres of the [[Thalamus]] together.</li>\n</ul>\n<p>![[Third Ventricles.png]]</p>","Words":"Ventricles"},{"Category":"Neuroscience","Definition":"<p>Part&nbsp;of&nbsp;the [[Central Nervous System (CNS)]]&nbsp;that&nbsp;represents&nbsp;the&nbsp;[[Motor Innervation]]&nbsp;of&nbsp;<strong>smooth&nbsp;muscle</strong>,&nbsp;<strong>cardiac&nbsp;muscle</strong>, and&nbsp;gland&nbsp;cells.&nbsp;It&nbsp;consists&nbsp;of&nbsp;two&nbsp;physiologically&nbsp;and&nbsp;anatomically&nbsp;distinct,&nbsp;mutually&nbsp;antagonistic&nbsp;components:&nbsp;the&nbsp;sympathetic&nbsp;and&nbsp;parasympathetic&nbsp;parts.</p>","Words":"Visceral Nervous System"},{"Category":"Neuroscience","Definition":"<p>The input flowing in a single ouput unit is $$y = \\sum^J<em>{j=1} w</em>j x_j$$ which doesn't have any external feedback (because no supervisor). The goal here is to compress as much information as possible from the original $J$ dimension input.</p>\n<p>Similar in statistics as [[Principale component Analysis (PCA)]], it can be iteratively implemented, giving the following [[Learning Rule]] : $$\\Delta w<em>j = \\beta x</em>j y$$</p>\n<p>![[Slide53.jpeg]]</p>\n<p>But this model has stability problem, small pertubations in input can cause large weight changes. One of the solutions is the [[Oja's Learning Rule]] with the weigth update being $$\\Delta w<em>j = \\beta (x</em>j y - y^2 w_j)$$</p>\n<p>A mix of [[Unsupervised Learning]] and [[Hebbian Learning]].</p>","Words":"Unsupervised Hebbian Learning"},{"Category":"Neuroscience","Definition":"<p>'Autonomic' actions/signals/informations\n[[Autonomic Nervous System]]</p>","Words":"Visceral"},{"Category":"Neuroscience","Definition":"<p>[[Brain]] section under the [[Gray Matter]].\nIn the [[Spinal Cord (SC)]], it is the inverse, the [[White Matter]] is in the outside and the [[Gray Matter]] is in the inside.</p>\n<hr />\n<p>All the fiber [[Tract]].  Made up of [[Myelination]] [[Axon]].</p>\n<p>It is \"white\" because myelin is highly enriched in  #Lipids.</p>","Words":"White Matter"},{"Category":"Neuroscience","Definition":"<p>Alternating between a <em>wake</em> and a <em>sleep</em> phase until convergence is reached : </p>\n<p><strong>Wake phase</strong> : </p>\n<ul>\n<li>a data pattern $\\textbf{x}$ is sent bottom-up to the hidden layers</li>\n<li>based on the resulting activation pattern across data and hidden layers, the top-down weights are updated in a [[Gradient Descent]] step.</li>\n</ul>\n<p><strong>Sleep phase</strong> : </p>\n<ul>\n<li>Activation starts from the hidden layers, sent top-down to the data layers (as in a dream), and based on the resulting activation pattern in data and hidden layers, bottom-up weigths are updated in a [[Gradient Descent]] step.</li>\n</ul>","Words":"Wake-sleep Algorithm"},{"Category":"Neuroscience","Definition":"<p>Organ responsible inducing signals for balancing, acceleration (circular and directional), gravity.</p>","Words":"Vestibular Apparatus"},{"Category":"Neuroscience","Definition":"<p>Both [[Sensory Innervation]] and [[Motor Innervation]].\n[[Inferior Ganglion]]</p>\n<p>Also called the \"wanderer nerve\" because it goes down to all smooth organs below the lungs.</p>\n<p>Carries [[Parasympathetic Information]].</p>\n<h2 id=\"motor\">Motor</h2>\n<ul>\n<li>[[Somatic]]<ul>\n<li>Striated muscles of Pharynx</li>\n<li>[[Branchial Motor]]</li></ul></li>\n<li>[[Visceral]] ([[Parasympathetic Information]])<ul>\n<li>Smooth muscle and glands of pharynx</li>\n<li>Thoracic</li>\n<li>Abdominal viscera</li></ul></li>\n</ul>\n<h2 id=\"sensory\">Sensory</h2>\n<ul>\n<li>[[Somatic]]<ul>\n<li>External acoustic meatus</li>\n<li>External surface of tympanic membrane</li>\n<li>Pharynx</li></ul></li>\n<li>[[Special Senses]]<ul>\n<li>Taste</li>\n<li>Epiglottis</li></ul></li>\n<li>[[Visceral]]<ul>\n<li>Larynx</li>\n<li>Trachea</li>\n<li>Thoracic</li>\n<li>Abdominal viscera</li>\n<li>Aorta</li></ul></li>\n</ul>","Words":"X Vagus"},{"Category":"Neuroscience","Definition":"<p>[[Motor Innervation]], reponsible for the innervation of specific muscles.</p>\n<h2 id=\"motor\">Motor</h2>\n<ul>\n<li>The [[Trapezius]] muscle</li>\n<li>The [[Sternocleidomastoid]] muscle</li>\n</ul>\n<p>The muscles come from the [[Spinal Cord (SC)]]</p>","Words":"XI Spinal Accessory"},{"Category":"Neuroscience","Definition":"<p>[[Motor Innervation]], responsible for the innervation of the muscles of the tongue.</p>\n<h2 id=\"motor\">Motor</h2>\n<ul>\n<li><strong>Intrinsic</strong> muscle of the tongue :<ul>\n<li>Allows the tongue to change shape, roll up, inflate/deflate, …</li></ul></li>\n<li><strong>Extrinsic</strong> muscle of the tongue : <ul>\n<li>Allow to move the tongue around in the oral cavity</li></ul></li>\n</ul>\n<p>Making those two work together allows us to speak, eat, drink, etc …</p>","Words":"XII Hypoglossal"},{"Category":"Neuroscience","Definition":"<ol>\n<li>[[Model]] parameters are first estimated (typically based on behavioral data)</li>\n<li>Based on those parameters, trial-by-trial model-based [[Regression Model]] are constructed to be used in the [[functional Magnetic Resonance Imaging (fMRI)]] analysis.</li>\n<li>[[Voxels]] are then sought across the [[Brain]] that correlate with the model-based regressors. </li>\n<li>[[Voxels]] that survives statistical thresholding, and thus correlate sufficiently strongly with the regressors, are interpreted to implement at least part of the model that generated the regressor.</li>\n</ol>","Words":"fMRI-based Model"},{"Category":"Philosophy of Science","Definition":"<p>The study of the nature of knowledge and the processes that create it.</p>\n<p>[[Nature]] [[Knowledge]] #creation</p>","Words":"Epistemology"},{"Category":"Philosophy of Science","Definition":"<p>Rational criticism compares rival theories with the aim of finding which of them offers the best explanations according to the criteria inherent in the problem.</p>","Words":"Critism"},{"Category":"Philosophy of Science","Definition":"<p>An experiement whose outcome may falsify one or more of a set of rival theories.</p>","Words":"Experimental test"},{"Category":"Philosophy of Science","Definition":"<p>An emergent phenomenon is one (such as life, thought of computation) about which there are comprehensible facts or explanations that are not simply deducible from lower-level theories, but which may be explicable or predictable by highe-level theories referring directly to that phenomenon.</p>","Words":"Emergence"},{"Category":"Philosophy of Science","Definition":"<p>The idea that the only legitimate explanations are in terms of higher-level systems; the opposite of [[Reductionism]].</p>","Words":"Holism"},{"Category":"Philosophy of Science","Definition":"<p>A fictious process by which general theories were supposed to be obtained from, or justified by, accumulated observations.</p>","Words":"Induction"},{"Category":"Philosophy of Science","Definition":"<p>(roughly) A statement about the nature of things and the reasons of things.</p>","Words":"Explanation"},{"Category":"Philosophy of Science","Definition":"<p>The view that the purpose of a scientific theory is to predict the outcomes of experiments.</p>\n<p>[[Philosophy of Science]]</p>","Words":"Instrumentalism"},{"Category":"Philosophy of Science","Definition":"<p>The effect of a particle in one universe on its couterpart in another. [[Photon]] interference can cause shadows to be muc more complicated than mere silhouettes of the obstacles causing them.</p>\n<p>[[Multiverse]]</p>","Words":"Interference"},{"Category":"Philosophy of Science","Definition":"<p>An extreme form of [[Instrumentalism]] which holds that all statements other than those describing or predicting observations are meaningless. (This view is itself meaningless according to its own criterion).</p>","Words":"Positivism"},{"Category":"Philosophy of Science","Definition":"<p>They are 'parallel' in the sense that within each universe particles interact with each other just as they in the [[Tangible vs Shadow]] universe, but each universe affects the others only weakly, through interference phenomena.</p>","Words":"Parallel universes"},{"Category":"Philosophy of Science","Definition":"<p>A particle of light.</p>","Words":"Photon"},{"Category":"Philosophy of Science","Definition":"<p>It exists when it seems that some of our theories, especially the explanations they contain, seem inadequate and worth trying to improve.</p>","Words":"Problem"},{"Category":"Philosophy of Science","Definition":"<p>Since scientific theory cannot be logically justified by observation, what does justifiy them?</p>","Words":"Problem of induction"},{"Category":"Philosophy of Science","Definition":"<p>The view that scientific explanation are inherenthly [[Reductive]].</p>","Words":"Reductionism"},{"Category":"Philosophy of Science","Definition":"<p>An explanation that works by analysing things into lower-level components.</p>","Words":"Reductive"},{"Category":"Philosophy of Science","Definition":"<p>The <em>purpose</em> of science is to understand reality through explanations. The characteristic (though not the only) <em>method of [[Critism]]</em> used in science is [[Experimental test]].</p>","Words":"Science"},{"Category":"Philosophy of Science","Definition":"<p>The theory that only one [[Mind]] exists and that what appears to external reality is only a dream taking place in that mind. </p>","Words":"Solipsism"},{"Category":"Philosophy of Science","Definition":"<p>From the book [The fabric of reality], particles in this universe are called <em>tangible</em>, and particles in other universes <em>shadow particles</em>.</p>","Words":"Tangible vs Shadow"},{"Category":"Physics","Definition":"<p>The random motion made by a particle submerged in water. [[Physics]]</p>","Words":"Brownian Motion"},{"Category":"Psychology","Definition":"<p>Abstract construct (based on theory and statistical phenomena) as to a directly measurable, objective property of an individual mind (such as a score on a specific test).</p>\n<p>[[Abstract Concepts]] [[Mind]] [[Measure]]</p>","Words":"Ability"},{"Category":"Psychology","Definition":"<p>Adaptation to unknown unknowns across a broad category of related tasks. (self-driving vehicles)</p>\n<p>[[Adaptability]] [[Task]] [[Generalization]]</p>","Words":"Broad Generalization"},{"Category":"Psychology","Definition":"<p>\"Knowledge that accumulates over time about particular states of affairs such as what we might learn about a friend</p>","Words":"Cognitive Model"},{"Category":"Psychology","Definition":"<p>Cognitive abilities that lead to broad or extreme generalization. Often meant in opposition to \"local generalization\".</p>\n<p>[[Generalization]] [[Cognitive Neuroscience]] [[Local generalization]] [[Broad Generalization]]</p>","Words":"Broad abilities"},{"Category":"Psychology","Definition":"<p>Adaptation to unknown unknowns across an unknown range of tasks and domains. (Humans and some species)</p>\n<p>[[Adaptability]] [[Task]] [[Domain]] [[Human]] [[Generalization]]</p>","Words":"Extreme generalization"},{"Category":"Psychology","Definition":"<p>Also called [[G Factor]], a construct that is made up of different [[Cognition]] abilities, allowing [[Agent]]s to acquire [[Knowledge]] and solve [[Problem]].</p>\n<p>e.g. \nGeneral intelligence can be compared to athleticism. A person might be a very skilled runner, but this does not necessarily mean that they will also be an excellent figure skater.</p>\n<p>However, because this person is athletic and fit, they will probably perform much better on other physical tasks than an individual who is less coordinated and more sedentary.</p>","Words":"General Intelligence"},{"Category":"Psychology","Definition":"<p>The ability to handle situations (or tasks) that differ from previously encountered situations.</p>\n<p>Two types of generalization:</p>\n<ul>\n<li><strong>[[System-centric generalization]]</strong></li>\n<li><strong>[[Developer-aware generalization]]</strong></li>\n</ul>\n<p>[[Task]] [[Generalization]]</p>","Words":"Generalization"},{"Category":"Psychology","Definition":"<p>A hypothetic single factor of general intelligence.</p>\n<p>[[Intelligence]] [[General Intelligence]]</p>","Words":"G Factor"},{"Category":"Psychology","Definition":"<p>The idea that some \"knowledge\" is innate. (not learned but there at the beginning)</p>\n<p>[[Knowledge]] [[Innate Knowledge]]</p>","Words":"Nativism"},{"Category":"Psychology","Definition":"<p>the field of study concerned with the theory and technique of psychological measurement, which includes the measurement of knowledge, abilities, attitudes, and personality traits. The field is primarily concerned with the study of differences between individuals.</p>\n<p>[[Psychology]] [[Measure]] [[Knowledge]] [[Ability]] [[Personality]] [[Individual]]</p>","Words":"Psychometrics"},{"Category":"Psychology","Definition":"<p>The quality of being able to be trusted to do what somebody wants or needs.</p>\n<p>[[Task]] [[Trust]]</p>","Words":"Reliability"},{"Category":"Psychology","Definition":"<p>Associated with fast, \"pattern matching\", reactive inference that doesn't scale with compute time. \nOften opposed to [[System 2]].</p>\n<ul>\n<li>Fast Thinking</li>\n<li>[[Procedural Knowledge]]</li>\n<li>[[Awareness]]</li>\n</ul>\n<p>[[Cognitive Neuroscience]]</p>","Words":"System 1"},{"Category":"Psychology","Definition":"<p>Associated with slower, resource intensive sequential inference that scales with compute time.\nOften opposed to [[System 1]]</p>\n<ul>\n<li>Slow Thinking</li>\n<li>[[Declarative Knowledge]]</li>\n<li>[[Attention]]</li>\n</ul>\n<p>[[Cognitive Neuroscience]]</p>","Words":"System 2"},{"Category":"Psychology","Definition":"<p>The study, using computational [[Model]], of how [[Learning]] and [[Decision Making]] are impaired in clinical conditions.</p>","Words":"Computational Psychiatry"},{"Category":"Psychology","Definition":"<p>\"Intelligence measures an agent's ability to achieve goals in a wide range of environments.\" [[Legg]] and [[Hutter]], summarizing 70 scientists in the context of AI research.</p>\n<p>\"Skill acquisition efficiency\" by <a href=\"2019\">[Francois Chollet]</a></p>\n<p>[[Artificial Intelligence]] [[Psychometrics]]</p>","Words":"Intelligence"},{"Category":"Psychology","Definition":"<p>Refers to a&nbsp;phenomenon where people recognize letters more easily if&nbsp;presented within words as compared to isolated letters, and to letters presented within non-word (orthographically illegal, unpronounceable letter array) strings. The effect was first described by Cattell (1886), and important contributions came from Reicher (1969) and Wheeler (1970).</p>\n<p><strong>Example</strong> : \nIt is easier to find the first letter of the \"SHIP\" than a non word contexts with \"SXWX\".\nThis is partially explained by the [[Interactive Activation Model (IAM)]], where pronouncable words are more easly activated by feature detectors than non pronouncable words.</p>\n<p>[[Psychology]]</p>","Words":"Word Superiority Effect (WSE)"},{"Category":"Psychology","Definition":"<p>Ability of a learning system to handle situations it has not itself encountered before.</p>\n<p>[[Learning]] [[Task]] [[Generalization]]</p>","Words":"System-centric generalization"},{"Category":"Psychology","Definition":"<p>A fmous patient wichi was surgically been removed 2/3 of his [[Hippocampus]], his [[Amygdala]], and other parts in order to cure his epilepsy. He was then unable to form new [[Memory]] (apart from his [[Short-term Memory]]).</p>","Words":"Patient H.M."},{"Category":"Groups","Definition":"<p>Difficulties in evaluating and pooling information.</p>\n<p>[[Information]] [[Evaluation]]</p>","Words":"Antagonism"},{"Category":"Groups","Definition":"<p>[[Group]] #Psychology #Pressure</p>\n<p><strong>Conformity</strong> is the process of giving in to real or imagined pressure from a group. In the 1950s, the psychologist <strong>[[Solomon Asch]]</strong> did a famous study that demonstrated that people often conform.</p>\n<ul>\n<li><p><strong>Group #Size:</strong> Asch found that group size influenced whether subjects conformed. The bigger the group, the more people conformed, up to a certain point. After group size <strong>reached a certain limit</strong>, conformity <strong>didn’t increase any further</strong>.</p></li>\n<li><p>[ ] What size groups did Asch study? Anything about groups of Three?</p></li>\n<li><p><strong>Group #Unanimity:</strong> Asch also found that subjects were much more likely to conform when a group agreed unanimously. If even one other person in the group disagreed with the group, a subject was much less likely to conform. This was true even when the other dissenter disagreed with the subject as well as the group.</p></li>\n</ul>\n<p>Researchers have found that conformity also increases when:</p>\n<ul>\n<li>A person feels Incompetent or Insecure #Incompetence #Insecure</li>\n<li>The person Admires the group #Admiration</li>\n<li>The group can see how the person behaves. #Behavior</li>\n</ul>\n<h4 id=\"reasonsforconforming\">Reasons for Conforming</h4>\n<p>People have many reasons for conforming:</p>\n<ul>\n<li>They want to be accepted by the group, or they fear rejection by the group. In this case, the group is exerting <strong>Normative Social Influence</strong>. #Acceptance #Normative<em>Social</em>Influence </li>\n<li>The group provides them with information. In this case, the group is exerting <strong>Informational Social Influence</strong>. #Informational<em>Social</em>Influence</li>\n<li>They want a material or social reward, such as a pay raise or votes. #Reward</li>\n<li>They admire the group and want to be like other group members. #Admiration #Conformity</li>\n</ul>\n<h4 id=\"majoritysize\">Majority size</h4>\n<p>Asch also examined whether decreasing or increasing the majority size had an influence on participants' level of conformity.\nIt was discovered that very small-size opposing groups (actors) were associated with low levels of yielding. Increasing the opposing group to two or three persons increased conformity substantially. Increases beyond three persons (e.g., four, five, six, etc.) did not further-increase conformity.\n<a href=\"https://en.wikipedia.org/wiki/Asch_conformity_experiments#cite_note-Asch1951-1\">[1]</a><a href=\"https://en.wikipedia.org/wiki/Asch_conformity_experiments#cite_note-Asch1952b-2\">[2]</a><a href=\"https://en.wikipedia.org/wiki/Asch_conformity_experiments#cite_note-Asch1955-3\">[3]</a> </p>","Words":"Conformity"},{"Category":"Groups","Definition":"<p>[[Group]]</p>\n<p>[[Bruce Tuckman]]’s (<a href=\"https://nobaproject.com/modules/the-psychology-of-groups#reference-50\">1965</a>) theory of group development</p>\n<h2 id=\"stagesandcharacteristics\">Stages and Characteristics</h2>\n<p><strong>Stage 1 – “Forming”.</strong> \nMembers expose information about themselves in polite but tentative interactions. They explore the purposes of the group and gather information about each other’s interests, skills, and personal t</p>","Words":"Group Development"},{"Category":"Groups","Definition":"<p>[[Psychology]]</p>\n<h3 id=\"features\">Features</h3>\n<p>Groups usually have the following features:</p>\n<ul>\n<li>[Norm] that determine appropriate behavior</li>\n<li>[Role] that are assigned to people that determine what behaviors and responsibilities people should take on</li>\n<li>A [Communication] structure that determines who talks to whom within the group</li>\n<li>A Power structure that determines how much [Authority] and [Influence] its members have</li>\n</ul>\n<blockquote>\n  <p><strong>Example:</strong> A college psychology class has norms, such as when people should arrive for class. The professor’s role includes teaching, inviting discussion, and administering exams. The students’ role is to attend the class.</p>\n</blockquote>","Words":"Group"},{"Category":"Groups","Definition":"<p>The solidarity or unity of a group resulting from the development of strong and mutual interpersonal bonds among members and group-level forces that unify the group, such as shared commitment to group goals.</p>\n<p>[[Group]] #Solidarity #Commitiment</p>","Words":"Group Cohesion"},{"Category":"Groups","Definition":"<p>Members of a [[Group]] are often required to make decisions together. Three concepts impact this making : </p>\n<ul>\n<li>[[Groupthink]]</li>\n<li>[[Group Polarization]]</li>\n<li>[[Minority Influence]]</li>\n</ul>","Words":"Group Decision-Making"},{"Category":"Groups","Definition":"<p>The tendency for [[Group]]s to show a shift towards the extremes of [[Group Decision-Making]] when compared to decisions made by individuals.</p>","Words":"Group Polarization"},{"Category":"Groups","Definition":"<p>A phenomenon that occurs when a [[Group]] of well-intentioned people makes irrational or non-optimal decisions spurred by the urge of [[Conformity]]&nbsp;or the belief that dissent is impossible.</p>","Words":"Groupthink"},{"Category":"Groups","Definition":"<p>Refers to the finding that people sometimes show an increased level of effort as a result of the real, imagined, or implied presence of others.</p>\n<ul>\n<li>The concept was first identified by [[Norman Triplett]] in 1898, when he noticed that cyclist’s performance was facilitated (helped) when training as a group.</li>\n<li>Psychologist [[Floyd Allport]] labeled it social facilitation in 1920.</li>\n<li>There are two types of social facilitation: <strong>co-action</strong> effects and <strong>audience</strong> effect.</li>\n<li>Subsequent researchers found that performance improved as a result of the presence of others whilst others found that it was impaired (<strong>[[Social Inhibition]]</strong>).</li>\n</ul>\n<p>[[Group]] [[Co-action Effect]] [[Audience Effect]] [[Psychology]]</p>","Words":"Social Facilitation"},{"Category":"Groups","Definition":"<p>Knowledge, expectations, conceptualizations, and other cognitive representations that members of a group have in common pertaining to the group and its members, tasks, procedures, and resources. </p>\n<p>[[Knowledge]] [[Expectation]] [[Group]] [[Task]]</p>","Words":"Shared Mental Model"},{"Category":"Groups","Definition":"<p>Three level of influence : </p>\n<ul>\n<li>The individual </li>\n<li>The group </li>\n<li>The organization</li>\n</ul>\n<p>[[Influence]] [[Group]] [[Organisation]] [[Individual]]</p>","Words":"Three Levels of Learning"},{"Category":"Groups","Definition":"<p>[[Group]] #Productivity</p>\n<h3 id=\"productivityingroups\">Productivity in Groups</h3>\n<p>Research shows that productivity t</p>","Words":"Productivity"},{"Category":"Groups","Definition":"<p>A form of social influence that is attributed to exposure to a consistent minority position in a [[Group]].</p>\n<p>Generally felt only after a period of time, and tends to produce private acceptance of the views expressed by the minority.</p>","Words":"Minority Influence"},{"Category":"Groups","Definition":"<p>Inverse of [[Social Facilitation]].\nDecrease in effort in the presence of others.</p>\n<p>[[Group]] #Effort</p>","Words":"Social Inhibition"},{"Category":"Quantum Computers","Definition":"<p>The whole of physical reality, It contains many parallel universes.</p>","Words":"Multiverse"},{"Category":"Quantum Computers","Definition":"<p><strong>Theorem 3</strong> ([[Optimal Sparse Hamiltonian Simulation]])</p>\n<p>A d-sparse [[Hamiltonian]] $\\widehat{H}$ on $n$ qubits with matrix elements specified to $m$ bits of precision can be simulated for time-interval $t$, error $\\epsilon$, and sucess probability at least $1-2\\epsilon$ with $\\mathcal{O}(td ||\\widehat{H}||_{max} + \\frac{\\log (1/\\epsilon)}{\\log \\log (1/\\epsilon)} )$ queries and a factor $\\mathcal{O}((n + m poly \\log(m)))$ additional [[Quantum Gates]]</p>\n<p>[[Quantum Machine Learning]][[Quantum Computers]]</p>","Words":"Optimal Sparse Hamiltonian Simulation"},{"Category":"Quantum Computers","Definition":"<p>In <a href=\"https://en.wikipedia.org/wiki/Mathematics\" title=\"Mathematics\">mathematics</a>, <strong>Hilbert spaces</strong> (named for <a href=\"https://en.wikipedia.org/wiki/David_Hilbert\" title=\"David Hilbert\">David Hilbert</a>) allow generalizing the methods of <a href=\"https://en.wikipedia.org/wiki/Linear_algebra\" title=\"Linear algebra\">linear algebra</a> and <a href=\"https://en.wikipedia.org/wiki/Calculus\" title=\"Calculus\">calculus</a> from the two-dimensional and three dimensional <a href=\"https://en.wikipedia.org/wiki/Euclidean_space\" title=\"Euclidean space\">Euclidean spaces</a> to spaces that may have an infinite <a href=\"https://en.wikipedia.org/wiki/Dimension\" title=\"Dimension\">dimension</a>. A Hilbert space is a <a href=\"https://en.wikipedia.org/wiki/Vector_space\" title=\"Vector space\">vector space</a> equipped with an <a href=\"https://en.wikipedia.org/wiki/Inner_product\" title=\"Inner product\">inner product</a> operation, which allows defining a <a href=\"https://en.wikipedia.org/wiki/Distance_function\" title=\"Distance function\">distance function</a> and [perpendicular].</p>","Words":"Hilbert Space"},{"Category":"Quantum Computers","Definition":"<p>Information processing using the laws of quantum mechanics.</p>","Words":"Quantum Computing"},{"Category":"Quantum Computers","Definition":"<p>In <a href=\"https://en.wikipedia.org/wiki/Quantum_computing\" title=\"Quantum computing\">quantum computing</a> and specifically the <a href=\"https://en.wikipedia.org/wiki/Quantum_circuit\" title=\"Quantum circuit\">quantum circuit</a> <a href=\"https://en.wikipedia.org/wiki/Model_of_computation\" title=\"Model of computation\">model of computation</a>, a <strong>quantum logic gate</strong> (or simply <strong>quantum gate</strong>) is a basic quantum circuit operating on a small number of <a href=\"https://en.wikipedia.org/wiki/Qubit\" title=\"Qubit\">qubits</a>. They are the building blocks of quantum circuits, like classical <a href=\"https://en.wikipedia.org/wiki/Logic_gate\" title=\"Logic gate\">logic gates</a> are for conventional digital circuits.</p>\n<p>Unlike many classical logic gates, quantum logic gates are <a href=\"https://en.wikipedia.org/wiki/Reversible_computing\" title=\"Reversible computing\">reversible</a>. However, it is possible to perform classical computing using only reversible gates. For example, the reversible <a href=\"https://en.wikipedia.org/wiki/Toffoli_gate\" title=\"Toffoli gate\">Toffoli gate</a> can implement all Boolean functions, often at the cost of having to use <a href=\"https://en.wikipedia.org/wiki/Ancilla_bit\" title=\"Ancilla bit\">ancilla bits</a>. The Toffoli gate has a direct quantum equivalent, showing that quantum circuits can perform all operations performed by classical circuits.</p>\n<p>Quantum gates are <a href=\"https://en.wikipedia.org/wiki/Unitary_operators\" title=\"Unitary operators\">unitary operators</a>, and are described as <a href=\"https://en.wikipedia.org/wiki/Unitary_matrix\" title=\"Unitary matrix\">unitary matrices</a> relative to some <a href=\"https://en.wikipedia.org/wiki/Basis_(linear_algebra)\" title=\"Basis (linear algebra)\">basis</a>. Usually we use the <em>computational basis</em>, which unless we compare it with something, just means that for a <em>d</em>-level quantum system (such as a <a href=\"https://en.wikipedia.org/wiki/Qubit\" title=\"Qubit\">qubit</a>, a <a href=\"https://en.wikipedia.org/wiki/Quantum_register\" title=\"Quantum register\">quantum register</a>, or <a href=\"https://en.wikipedia.org/wiki/Qutrit\" title=\"Qutrit\">qutrits</a> and <a href=\"https://en.wikipedia.org/wiki/Qudit\" title=\"Qudit\">qudits</a><a href=\"https://en.wikipedia.org/wiki/Quantum_logic_gate#cite_note-Williams-1\">[1]</a>: 22–23 ) we have labeled the orthogonal basis vectors {\\displaystyle |0\\rangle ,|1\\rangle ,\\dots ,|d-1\\rangle } <img src=\"https://wikimedia.org/api/rest_v1/media/math/r\" alt=\"{\\displaystyle |0\\rangle ,|1\\rangle ,\\dots ,|d-1\\rangle }\" /></p>","Words":"Quantum Gates"},{"Category":"Quantum Computers","Definition":"<p>The property of having a discrete (rather than continuous) set of possible values. [[Quantum Theory]] gets its name from its assertion that all measurable quantities are quantizied. However, the most significant quantum effect is not quantization but [[Interference]].</p>","Words":"Quantization"},{"Category":"Quantum Computers","Definition":"<p>$$\nf(x, \\theta) = tr { \\ \\rho(x) \\mathcal{M}_{\\theta}\\ } \\ \\widehat= \\  \\langle \\phi(x), w\\rangle \n$$\n$$\n\\kappa(x, x') = tr { \\ \\rho(x) \\rho(x')\\ } \\ \\widehat= \\  \\langle \\phi(x), \\phi(x')\\rangle \n$$</p>\n<blockquote>\n  <p>See some explanations with [[Kernel Methods]] also explained a bit in the notes [[What are Quantum Models]].</p>\n</blockquote>","Words":"Quantum Kernel"},{"Category":"Quantum Computers","Definition":"<p>Solving [[Machine Learning]] #ML problems with the help of [[Quantum Computing]].</p>\n<p>[[Quantum Computers]] [[Artificial Intelligence]]</p>","Words":"Quantum Machine Learning"},{"Category":"Quantum Computers","Definition":"<p>Physical Theory that allows us to predict observations when measuring very small systems.</p>","Words":"Quantum Mechanics"},{"Category":"Quantum Computers","Definition":"<p>Gates are physical operations where we can use the parameters of the gate (example, tuning a laser with intensity, frequency, etc …) to change the type of algorithms. That allows us to create a \"family\" of algorithms from one circuit.</p>\n<p>![[Pasted image 20211223115446.png]]</p>\n<p>Helping to find efficient circuits by setting a [[Cost function]] and optimizing it on parameters.</p>\n<p>Example : </p>\n<p>![[Pasted image 20211223115659.png]]</p>\n<ul>\n<li>$S(x)$ is used to prepare the input data.</li>\n<li>$W(\\theta)$ is used to process with weights able to be tuned. </li>\n</ul>\n<p>Comparable to [[Machine Learning]] in the sense of \"finding the best parameters for your circuit to model properly a distribution function\"</p>","Words":"Variationnal Circuits"},{"Category":"Quantum Computers","Definition":"<p>[[Stochastic]] exploration of most important regions of the gigantic state space using [[Markov Chain Monte Carlo]] of the exact same flavours encountered in [[Machine Learning]].</p>","Words":"Quantum Monte Carlo"},{"Category":"Quantum Computers","Definition":"<p>The theory of the physics of the multiverse. </p>\n<p>[[Quantum Mechanics]] </p>","Words":"Quantum Theory"}]

export default def;